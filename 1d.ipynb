{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7283d10d-aa63-41e6-83f1-4a4f9ca49301",
   "metadata": {
    "id": "7283d10d-aa63-41e6-83f1-4a4f9ca49301"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shutil\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPooling1D,\n",
    ")\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.math import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "yF0tjyleTO_L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yF0tjyleTO_L",
    "outputId": "0776634e-dbe2-48dd-8d89-0d20d9223915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount(\"/content/drive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "LI_AhuEqrvie",
   "metadata": {
    "id": "LI_AhuEqrvie"
   },
   "outputs": [],
   "source": [
    "#!unzip -qq /content/drive/MyDrive/data/images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962b0dee-391d-4c85-8880-3ff01e5b2938",
   "metadata": {
    "id": "962b0dee-391d-4c85-8880-3ff01e5b2938"
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "# DATA_DIR = Path(\"/content/drive/MyDrive/data\")\n",
    "# IMG_DIR = Path(\"/content/images\")\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "IMG_DIR = DATA_DIR / \"images\"\n",
    "TRAIN_DIR = IMG_DIR / \"train\"\n",
    "TEST_DIR = IMG_DIR / \"test\"\n",
    "US8K_DIR = DATA_DIR / \"UrbanSound8K\"\n",
    "AUDIO_DIR = US8K_DIR / \"audio\"\n",
    "META_CSV = US8K_DIR / \"metadata\" / \"UrbanSound8K.csv\"\n",
    "LOG_DIR = DATA_DIR / \"logs\"\n",
    "NUM_CLASSES = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a70e99-aa4a-436c-b34d-a01c71400f11",
   "metadata": {
    "id": "94a70e99-aa4a-436c-b34d-a01c71400f11"
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "SAMPLING_RATE = 16000  # paper: 16000, other values: 22050, 44100\n",
    "CHUNK_SIZE = int(1 * SAMPLING_RATE)  # paper: 16000 (i.e. 1 second), others: 0.1 second\n",
    "OVERLAP_PERCENT = 75  # paper: 75%\n",
    "\n",
    "# model related\n",
    "BATCH_SIZE = 100  # paper: 100\n",
    "EPOCHS = 100  # paper: 100\n",
    "EARLY_STOP_PATIENCE = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ec4311",
   "metadata": {
    "id": "99ec4311"
   },
   "outputs": [],
   "source": [
    "# calculated constants\n",
    "STRIDE = int((1 - OVERLAP_PERCENT / 100) * CHUNK_SIZE)\n",
    "MODEL_ID = f\"Sr{SAMPLING_RATE}Cs{CHUNK_SIZE}Ol{OVERLAP_PERCENT}\"\n",
    "FOLD_DATA_DIR = DATA_DIR / f\"foldData.{MODEL_ID}.pickle\"\n",
    "FOLD_DATA = DATA_DIR / f\"foldData.{MODEL_ID}.pickle\"\n",
    "MODEL_FILE = DATA_DIR / \"saved_models\" / f\"model.{MODEL_ID}\"\n",
    "MODEL_FILE_2D = DATA_DIR / \"2d_saved_models\" / f\"model.{MODEL_ID}\"\n",
    "VGG_MODEL_FILE = DATA_DIR / \"vgg_saved_models\" / f\"model.{MODEL_ID}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c319ef-b123-403c-b391-80a904e84771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9c319ef-b123-403c-b391-80a904e84771",
    "outputId": "c9fc5104-985a-4b12-929c-cc7c97fe989c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,\n",
       " 16000,\n",
       " 4000,\n",
       " PosixPath('data/foldData.Sr16000Cs16000Ol75.pickle'),\n",
       " PosixPath('data/saved_models/model.Sr16000Cs16000Ol75'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLING_RATE, CHUNK_SIZE, STRIDE, FOLD_DATA, MODEL_FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c72c4e6-8932-4823-a5cb-ad5240e416d7",
   "metadata": {
    "id": "4c72c4e6-8932-4823-a5cb-ad5240e416d7"
   },
   "outputs": [],
   "source": [
    "def to_chunks(X, y, chunk_size, stride):\n",
    "    \"\"\"Split a numpy array into chunks of given size jumping stride indices each time.\n",
    "    Any chunks of smaller size are padded with 0 at the end.\"\"\"\n",
    "    chunks = []\n",
    "    for start in range(0, len(X), stride):\n",
    "        chunk = X[start : start + chunk_size]\n",
    "        if len(chunk) == chunk_size:\n",
    "            chunks.append(chunk)\n",
    "        # take a partially filled chunk only if its size is >= 50% of chunk_size\n",
    "        # or it is the only chunk present for this input\n",
    "        # elif (len(chunk) >= 0.5 * chunk_size) or len(chunks) == 0:\n",
    "        # elif len(chunks) == 0:\n",
    "        #    chunk = np.pad(chunk, (0, chunk_size - len(chunk)))\n",
    "        #    chunks.append(chunk)\n",
    "        #    break\n",
    "        else:\n",
    "            break\n",
    "    if len(chunks) == 0:\n",
    "        return None\n",
    "    y = np.repeat(y, len(chunks))\n",
    "    return np.array(chunks), y, len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c721b452-492e-4e19-9dcb-95efa016c4b0",
   "metadata": {
    "id": "c721b452-492e-4e19-9dcb-95efa016c4b0"
   },
   "outputs": [],
   "source": [
    "def load_and_save_fold_data(meta, fold, sr, chunk_size, stride):\n",
    "    \"\"\"Load the audio and label data for given fold\"\"\"\n",
    "    entries = meta[meta[\"fold\"] == fold]\n",
    "    fold_dir = AUDIO_DIR / f\"fold{fold}\"\n",
    "    filenames = [fold_dir / filename for filename in entries[\"slice_file_name\"]]\n",
    "    audio = [librosa.load(filename, sr=sr)[0] for filename in filenames]\n",
    "    classes = entries[\"classID\"]\n",
    "\n",
    "    data = [to_chunks(x, y, chunk_size, stride) for x, y in zip(audio, classes)]\n",
    "    X, y, chunk_lens = zip(*[d for d in data if d is not None])\n",
    "    X, y = np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "    X = X[..., np.newaxis]  # add new axis required by tensorflow\n",
    "    # convert to one-hot encoding\n",
    "    y = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "    data = X, y, np.array(chunk_lens)\n",
    "    filepath = FOLD_DATA_DIR / f\"{fold}\"\n",
    "    with filepath.open(\"bw\") as f:\n",
    "        pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53271a5-00df-418f-83b0-0af54eceb852",
   "metadata": {
    "id": "e53271a5-00df-418f-83b0-0af54eceb852"
   },
   "outputs": [],
   "source": [
    "def read_chunks():\n",
    "    fold_Xs, fold_ys, fold_chunk_lens = [], [], []\n",
    "    for fold in range(1, 11):\n",
    "        print(f\"reading fold{fold}\")\n",
    "        with (FOLD_DATA_DIR / f\"{fold}\").open(\"br\") as f:\n",
    "            X, y, chunk_lens = pickle.load(f)\n",
    "            fold_Xs.append(X)\n",
    "            fold_ys.append(y)\n",
    "            fold_chunk_lens.append(chunk_lens)\n",
    "    return fold_Xs, fold_ys, fold_chunk_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b173fcc4",
   "metadata": {
    "id": "b173fcc4"
   },
   "outputs": [],
   "source": [
    "def create_model_from_paper(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # CONV1\n",
    "    model.add(\n",
    "        Conv1D(\n",
    "            16, kernel_size=64, strides=2, activation=\"relu\", input_shape=input_shape\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=8, strides=8))\n",
    "\n",
    "    # CONV2\n",
    "    model.add(Conv1D(32, kernel_size=32, strides=2, activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=8, strides=8))\n",
    "\n",
    "    # CONV3\n",
    "    model.add(Conv1D(64, kernel_size=16, strides=2, activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # CONV4\n",
    "    model.add(Conv1D(128, kernel_size=8, strides=2, activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # FC\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        # optimizer=Adadelta(learning_rate=1.0),\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss=MeanSquaredLogarithmicError(),\n",
    "        # loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "zA5J-LzzgRRF",
   "metadata": {
    "id": "zA5J-LzzgRRF"
   },
   "outputs": [],
   "source": [
    "# copy data from folds except test_fold to train directory and others to test directory\n",
    "def copy_to_train_test_dir(test_fold, test_only=False):\n",
    "    shutil.rmtree(TRAIN_DIR, ignore_errors=True)\n",
    "    shutil.rmtree(TEST_DIR, ignore_errors=True)\n",
    "    for fold in range(1, 11):\n",
    "        if test_only and fold != test_fold:\n",
    "            continue\n",
    "        fold_dir = IMG_DIR / f\"fold{fold}\"\n",
    "        for classno in range(NUM_CLASSES):\n",
    "            src_dir = fold_dir / f\"{classno}\"\n",
    "            dst_dir = (TEST_DIR if fold == test_fold else TRAIN_DIR) / f\"{classno}\"\n",
    "            dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for file in src_dir.iterdir():\n",
    "                shutil.copy(file, dst_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "WOEwx8vwmBVW",
   "metadata": {
    "id": "WOEwx8vwmBVW"
   },
   "outputs": [],
   "source": [
    "def reorder_2d_results(y, idxarr, chunk_lens):\n",
    "    # res = np.split(np.arange(len(X_test)), chunk_lens.cumsum()[:-1])\n",
    "    res = np.split(np.arange(len(y)), chunk_lens.cumsum()[:-1])\n",
    "    final = []\n",
    "    for r in res:\n",
    "        indices = np.array([np.where(idxarr == e)[0][0] for e in r])\n",
    "        final.append(y[indices])\n",
    "    return np.concatenate(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ea446ec",
   "metadata": {
    "id": "0ea446ec"
   },
   "outputs": [],
   "source": [
    "def sum_rule_agg(y, chunk_lens):\n",
    "    return np.array(\n",
    "        [res.mean(axis=0).argmax() for res in np.split(y, chunk_lens.cumsum()[:-1])]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d958a298",
   "metadata": {
    "id": "d958a298",
    "outputId": "37be608c-7ff1-48bf-e87f-1c3c61718752"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import logging\n",
    "\n",
    "# nblog = open(\"/content/data/nb.log\", \"a+\")\n",
    "# sys.stdout.echo = nblog\n",
    "# sys.stderr.echo = nblog\n",
    "\n",
    "# get_ipython().log.handlers[0].stream = nblog\n",
    "# get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "# %autosave 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c2cd19-b1e6-4230-9a66-9f874c715e27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b2c2cd19-b1e6-4230-9a66-9f874c715e27",
    "outputId": "4a53626d-3faa-4f3a-b739-70abca9fdfd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         slice_file_name    fsID       start         end  salience  fold  \\\n",
       "0       100032-3-0-0.wav  100032    0.000000    0.317551         1     5   \n",
       "1     100263-2-0-117.wav  100263   58.500000   62.500000         1     5   \n",
       "2     100263-2-0-121.wav  100263   60.500000   64.500000         1     5   \n",
       "3     100263-2-0-126.wav  100263   63.000000   67.000000         1     5   \n",
       "4     100263-2-0-137.wav  100263   68.500000   72.500000         1     5   \n",
       "...                  ...     ...         ...         ...       ...   ...   \n",
       "8727     99812-1-2-0.wav   99812  159.522205  163.522205         2     7   \n",
       "8728     99812-1-3-0.wav   99812  181.142431  183.284976         2     7   \n",
       "8729     99812-1-4-0.wav   99812  242.691902  246.197885         2     7   \n",
       "8730     99812-1-5-0.wav   99812  253.209850  255.741948         2     7   \n",
       "8731     99812-1-6-0.wav   99812  332.289233  334.821332         2     7   \n",
       "\n",
       "      classID             class  \n",
       "0           3          dog_bark  \n",
       "1           2  children_playing  \n",
       "2           2  children_playing  \n",
       "3           2  children_playing  \n",
       "4           2  children_playing  \n",
       "...       ...               ...  \n",
       "8727        1          car_horn  \n",
       "8728        1          car_horn  \n",
       "8729        1          car_horn  \n",
       "8730        1          car_horn  \n",
       "8731        1          car_horn  \n",
       "\n",
       "[8732 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(META_CSV)\n",
    "meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d610f8cb-6c6f-45ef-b1b6-8a574c2dad95",
   "metadata": {
    "id": "d610f8cb-6c6f-45ef-b1b6-8a574c2dad95"
   },
   "outputs": [],
   "source": [
    "if not FOLD_DATA_DIR.exists():\n",
    "    FOLD_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    with ProcessPoolExecutor() as e:\n",
    "        for fold in range(1, 11):\n",
    "            e.submit(\n",
    "                load_and_save_fold_data, meta, fold, SAMPLING_RATE, CHUNK_SIZE, STRIDE\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43322acd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43322acd",
    "outputId": "44945b32-7f93-4af1-fb30-9d51a127e79d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure GPUs are available\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "gpus\n",
    "# tf.config.set_visible_devices(gpus[2:], \"GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491c73c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "491c73c9",
    "outputId": "d1506acc-09ce-4853-d0cb-5bdbe4ed523e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading fold1\n",
      "reading fold2\n",
      "reading fold3\n",
      "reading fold4\n",
      "reading fold5\n",
      "reading fold6\n",
      "reading fold7\n",
      "reading fold8\n",
      "reading fold9\n",
      "reading fold10\n"
     ]
    }
   ],
   "source": [
    "# read pre-processed fold data\n",
    "fold_Xs, fold_ys, fold_chunk_lens = read_chunks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264dee4b",
   "metadata": {
    "id": "264dee4b",
    "outputId": "28721c8b-e70d-4ec3-f879-36c294f3bf16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_28 (Conv1D)          (None, 7969, 16)          1040      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 7969, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 996, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 483, 32)           16416     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 483, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 60, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_30 (Conv1D)          (None, 23, 64)            32832     \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 23, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 8, 128)            65664     \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 8, 128)           512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 257,018\n",
      "Trainable params: 256,538\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model_from_paper(input_shape=(CHUNK_SIZE, 1))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5a7cd",
   "metadata": {
    "id": "9cc5a7cd"
   },
   "outputs": [],
   "source": [
    "# callbacks to save, stop early and visualize\n",
    "cpcallback = ModelCheckpoint(\n",
    "    # monitor=\"val_loss\", filepath=MODEL_FILE, save_best_only=True, verbose=1\n",
    "    monitor=\"val_accuracy\",\n",
    "    filepath=MODEL_FILE,\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "escallback = EarlyStopping(\n",
    "    # monitor=\"val_loss\", min_delta=0, patience=EARLY_STOP_PATIENCE, verbose=1\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=EARLY_STOP_PATIENCE,\n",
    "    verbose=1,\n",
    ")\n",
    "tbcallback = TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "callbacks = [cpcallback, escallback, tbcallback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391787d",
   "metadata": {
    "id": "6391787d"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = np.concatenate(fold_Xs[:9]), np.concatenate(fold_ys[:9])\n",
    "X_test, y_test = fold_Xs[9], fold_ys[9]\n",
    "del fold_Xs, fold_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021a482",
   "metadata": {
    "id": "a021a482",
    "outputId": "fc79699f-f681-4526-e0c5-601ac0fb4998"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90030, 16000, 1), (90030, 10), (9612, 16000, 1), (9612, 10))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaef62a",
   "metadata": {
    "id": "beaef62a",
    "outputId": "1bb02591-4d1f-4fe7-d970-f86b27ab22ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.4297\n",
      "Epoch 00001: val_loss improved from inf to 0.03238, saving model to data/saved_models/model.Sr16000Cs16000Ol75\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75/assets\n",
      "901/901 [==============================] - 22s 23ms/step - loss: 0.0348 - accuracy: 0.4297 - val_loss: 0.0324 - val_accuracy: 0.5158\n",
      "Epoch 2/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.6133\n",
      "Epoch 00002: val_loss improved from 0.03238 to 0.03050, saving model to data/saved_models/model.Sr16000Cs16000Ol75\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75/assets\n",
      "901/901 [==============================] - 20s 22ms/step - loss: 0.0255 - accuracy: 0.6133 - val_loss: 0.0305 - val_accuracy: 0.5523\n",
      "Epoch 3/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.6819\n",
      "Epoch 00003: val_loss improved from 0.03050 to 0.02796, saving model to data/saved_models/model.Sr16000Cs16000Ol75\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75/assets\n",
      "901/901 [==============================] - 20s 22ms/step - loss: 0.0215 - accuracy: 0.6820 - val_loss: 0.0280 - val_accuracy: 0.5836\n",
      "Epoch 4/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.7220\n",
      "Epoch 00004: val_loss improved from 0.02796 to 0.02633, saving model to data/saved_models/model.Sr16000Cs16000Ol75\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75/assets\n",
      "901/901 [==============================] - 20s 22ms/step - loss: 0.0190 - accuracy: 0.7220 - val_loss: 0.0263 - val_accuracy: 0.6174\n",
      "Epoch 5/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.7496\n",
      "Epoch 00005: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0174 - accuracy: 0.7496 - val_loss: 0.0274 - val_accuracy: 0.6002\n",
      "Epoch 6/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.7674\n",
      "Epoch 00006: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0162 - accuracy: 0.7674 - val_loss: 0.0269 - val_accuracy: 0.5976\n",
      "Epoch 7/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.7834\n",
      "Epoch 00007: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0152 - accuracy: 0.7834 - val_loss: 0.0277 - val_accuracy: 0.6017\n",
      "Epoch 8/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.7957\n",
      "Epoch 00008: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0143 - accuracy: 0.7957 - val_loss: 0.0280 - val_accuracy: 0.5905\n",
      "Epoch 9/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.8068\n",
      "Epoch 00009: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0136 - accuracy: 0.8068 - val_loss: 0.0286 - val_accuracy: 0.5795\n",
      "Epoch 10/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.8143\n",
      "Epoch 00010: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0131 - accuracy: 0.8143 - val_loss: 0.0330 - val_accuracy: 0.5394\n",
      "Epoch 11/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.8235\n",
      "Epoch 00011: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0126 - accuracy: 0.8235 - val_loss: 0.0327 - val_accuracy: 0.5386\n",
      "Epoch 12/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.8309\n",
      "Epoch 00012: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0120 - accuracy: 0.8309 - val_loss: 0.0306 - val_accuracy: 0.5586\n",
      "Epoch 13/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.8372\n",
      "Epoch 00013: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0116 - accuracy: 0.8372 - val_loss: 0.0360 - val_accuracy: 0.5214\n",
      "Epoch 14/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.8433\n",
      "Epoch 00014: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0112 - accuracy: 0.8433 - val_loss: 0.0279 - val_accuracy: 0.6036\n",
      "Epoch 15/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.8497\n",
      "Epoch 00015: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0107 - accuracy: 0.8497 - val_loss: 0.0352 - val_accuracy: 0.5350\n",
      "Epoch 16/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.8529\n",
      "Epoch 00016: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0105 - accuracy: 0.8528 - val_loss: 0.0305 - val_accuracy: 0.5752\n",
      "Epoch 17/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.8601\n",
      "Epoch 00017: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0100 - accuracy: 0.8600 - val_loss: 0.0307 - val_accuracy: 0.5655\n",
      "Epoch 18/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.8625\n",
      "Epoch 00018: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0098 - accuracy: 0.8625 - val_loss: 0.0316 - val_accuracy: 0.5574\n",
      "Epoch 19/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.8678\n",
      "Epoch 00019: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0094 - accuracy: 0.8677 - val_loss: 0.0325 - val_accuracy: 0.5446\n",
      "Epoch 20/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.8716\n",
      "Epoch 00020: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0092 - accuracy: 0.8716 - val_loss: 0.0303 - val_accuracy: 0.5798\n",
      "Epoch 21/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.8749\n",
      "Epoch 00021: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0090 - accuracy: 0.8749 - val_loss: 0.0316 - val_accuracy: 0.5575\n",
      "Epoch 22/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.8780\n",
      "Epoch 00022: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0088 - accuracy: 0.8780 - val_loss: 0.0314 - val_accuracy: 0.5765\n",
      "Epoch 23/100\n",
      "899/901 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.8834\n",
      "Epoch 00023: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0084 - accuracy: 0.8834 - val_loss: 0.0323 - val_accuracy: 0.5670\n",
      "Epoch 24/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.8866\n",
      "Epoch 00024: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0082 - accuracy: 0.8867 - val_loss: 0.0352 - val_accuracy: 0.5241\n",
      "Epoch 25/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.8893\n",
      "Epoch 00025: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0080 - accuracy: 0.8893 - val_loss: 0.0314 - val_accuracy: 0.5835\n",
      "Epoch 26/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.8939\n",
      "Epoch 00026: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0077 - accuracy: 0.8940 - val_loss: 0.0347 - val_accuracy: 0.5500\n",
      "Epoch 27/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8956\n",
      "Epoch 00027: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0076 - accuracy: 0.8956 - val_loss: 0.0354 - val_accuracy: 0.5375\n",
      "Epoch 28/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.8986\n",
      "Epoch 00028: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0074 - accuracy: 0.8984 - val_loss: 0.0304 - val_accuracy: 0.5954\n",
      "Epoch 29/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9001\n",
      "Epoch 00029: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0073 - accuracy: 0.9001 - val_loss: 0.0315 - val_accuracy: 0.5822\n",
      "Epoch 30/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9030\n",
      "Epoch 00030: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0070 - accuracy: 0.9030 - val_loss: 0.0351 - val_accuracy: 0.5414\n",
      "Epoch 31/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9051\n",
      "Epoch 00031: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0069 - accuracy: 0.9051 - val_loss: 0.0319 - val_accuracy: 0.5762\n",
      "Epoch 32/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9087\n",
      "Epoch 00032: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0066 - accuracy: 0.9087 - val_loss: 0.0373 - val_accuracy: 0.5364\n",
      "Epoch 33/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9108\n",
      "Epoch 00033: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0065 - accuracy: 0.9108 - val_loss: 0.0347 - val_accuracy: 0.5483\n",
      "Epoch 34/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9121\n",
      "Epoch 00034: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0064 - accuracy: 0.9122 - val_loss: 0.0369 - val_accuracy: 0.5305\n",
      "Epoch 35/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9142\n",
      "Epoch 00035: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0062 - accuracy: 0.9142 - val_loss: 0.0318 - val_accuracy: 0.5902\n",
      "Epoch 36/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9146\n",
      "Epoch 00036: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0062 - accuracy: 0.9146 - val_loss: 0.0380 - val_accuracy: 0.5199\n",
      "Epoch 37/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9186\n",
      "Epoch 00037: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9185 - val_loss: 0.0363 - val_accuracy: 0.5336\n",
      "Epoch 38/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9185\n",
      "Epoch 00038: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9185 - val_loss: 0.0378 - val_accuracy: 0.5298\n",
      "Epoch 39/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9223\n",
      "Epoch 00039: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0057 - accuracy: 0.9223 - val_loss: 0.0377 - val_accuracy: 0.5253\n",
      "Epoch 40/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9229\n",
      "Epoch 00040: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0056 - accuracy: 0.9229 - val_loss: 0.0369 - val_accuracy: 0.5277\n",
      "Epoch 41/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9233\n",
      "Epoch 00041: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0056 - accuracy: 0.9233 - val_loss: 0.0332 - val_accuracy: 0.5704\n",
      "Epoch 42/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9254\n",
      "Epoch 00042: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0054 - accuracy: 0.9254 - val_loss: 0.0359 - val_accuracy: 0.5445\n",
      "Epoch 43/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9285\n",
      "Epoch 00043: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0052 - accuracy: 0.9284 - val_loss: 0.0374 - val_accuracy: 0.5456\n",
      "Epoch 44/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9281\n",
      "Epoch 00044: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0052 - accuracy: 0.9281 - val_loss: 0.0354 - val_accuracy: 0.5625\n",
      "Epoch 45/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9304\n",
      "Epoch 00045: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9304 - val_loss: 0.0386 - val_accuracy: 0.5114\n",
      "Epoch 46/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9320\n",
      "Epoch 00046: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0050 - accuracy: 0.9320 - val_loss: 0.0339 - val_accuracy: 0.5616\n",
      "Epoch 47/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9327\n",
      "Epoch 00047: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0049 - accuracy: 0.9326 - val_loss: 0.0335 - val_accuracy: 0.5787\n",
      "Epoch 48/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9341\n",
      "Epoch 00048: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9341 - val_loss: 0.0314 - val_accuracy: 0.5873\n",
      "Epoch 49/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9349\n",
      "Epoch 00049: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0047 - accuracy: 0.9350 - val_loss: 0.0341 - val_accuracy: 0.5641\n",
      "Epoch 50/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9352\n",
      "Epoch 00050: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0047 - accuracy: 0.9352 - val_loss: 0.0326 - val_accuracy: 0.5749\n",
      "Epoch 51/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9373\n",
      "Epoch 00051: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0046 - accuracy: 0.9372 - val_loss: 0.0338 - val_accuracy: 0.5608\n",
      "Epoch 52/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9380\n",
      "Epoch 00052: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0045 - accuracy: 0.9381 - val_loss: 0.0325 - val_accuracy: 0.5736\n",
      "Epoch 53/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9399\n",
      "Epoch 00053: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0044 - accuracy: 0.9399 - val_loss: 0.0364 - val_accuracy: 0.5508\n",
      "Epoch 54/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9399\n",
      "Epoch 00054: val_loss did not improve from 0.02633\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0044 - accuracy: 0.9399 - val_loss: 0.0378 - val_accuracy: 0.5310\n",
      "Epoch 00054: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    # validation_split=1 / 9,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd9906",
   "metadata": {
    "id": "92dd9906"
   },
   "outputs": [],
   "source": [
    "# load the model with the best weights\n",
    "model = load_model(MODEL_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db16ea",
   "metadata": {
    "id": "24db16ea",
    "outputId": "c2b76ea4-7bec-46e4-a3d7-37a2bad303be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.6174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.026332639157772064, 0.6173533201217651]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5d9f0",
   "metadata": {
    "id": "9ea5d9f0",
    "outputId": "f298a26a-81dd-44b1-f666-21bcafc5014d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6214196762141968, 0.6214196762141968)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_agg = sum_rule_agg(y_pred, fold_chunk_lens[9])\n",
    "y_test_agg = sum_rule_agg(y_test, fold_chunk_lens[9])\n",
    "(y_pred_agg == y_test_agg).sum() / len(y_pred_agg), accuracy_score(\n",
    "    y_test_agg, y_pred_agg\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38b231",
   "metadata": {
    "id": "4c38b231",
    "outputId": "ab64dc25-ee0c-492e-a6ea-85d0c6bbd0d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[68,  0,  8,  0,  0,  5,  0,  4,  4, 11],\n",
       "       [ 2, 15,  2,  2,  0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0, 74,  5,  0,  1,  0,  0, 12,  8],\n",
       "       [ 1,  2, 10, 51,  2,  4,  0,  0,  5,  8],\n",
       "       [ 0,  1,  8,  1, 59,  2,  0, 13,  9,  3],\n",
       "       [ 4,  0,  1,  0,  0, 75,  0,  4,  0,  9],\n",
       "       [ 0,  0,  3, 20,  0,  0,  0,  0,  2,  2],\n",
       "       [ 1,  0,  4,  0, 18,  0,  0, 70,  0,  2],\n",
       "       [ 2,  3, 28,  0,  3,  0,  0,  0, 47,  0],\n",
       "       [ 1,  0, 18,  0,  7,  0,  0,  0,  5, 69]], dtype=int32)>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_agg, y_pred_agg, num_classes=NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99e0f2",
   "metadata": {
    "id": "3e99e0f2",
    "outputId": "b20bcf55-f254-4db3-b6d9-b95eff0808ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop with val_idx=0\n",
      "Epoch 1/100\n",
      "896/896 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.4166\n",
      "Epoch 00001: val_loss improved from inf to 0.03324, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi0\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi0/assets\n",
      "896/896 [==============================] - 21s 22ms/step - loss: 0.0354 - accuracy: 0.4166 - val_loss: 0.0332 - val_accuracy: 0.4812\n",
      "Epoch 2/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.6122\n",
      "Epoch 00002: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0254 - accuracy: 0.6122 - val_loss: 0.0351 - val_accuracy: 0.4875\n",
      "Epoch 3/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.6801\n",
      "Epoch 00003: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0216 - accuracy: 0.6801 - val_loss: 0.0408 - val_accuracy: 0.4471\n",
      "Epoch 4/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.7198\n",
      "Epoch 00004: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0191 - accuracy: 0.7197 - val_loss: 0.0359 - val_accuracy: 0.4915\n",
      "Epoch 5/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.7433\n",
      "Epoch 00005: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0176 - accuracy: 0.7433 - val_loss: 0.0349 - val_accuracy: 0.5079\n",
      "Epoch 6/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.7619\n",
      "Epoch 00006: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0164 - accuracy: 0.7619 - val_loss: 0.0357 - val_accuracy: 0.4908\n",
      "Epoch 7/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.7795\n",
      "Epoch 00007: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0153 - accuracy: 0.7795 - val_loss: 0.0386 - val_accuracy: 0.4470\n",
      "Epoch 8/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.7904\n",
      "Epoch 00008: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0145 - accuracy: 0.7905 - val_loss: 0.0381 - val_accuracy: 0.4875\n",
      "Epoch 9/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.8016\n",
      "Epoch 00009: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0138 - accuracy: 0.8016 - val_loss: 0.0376 - val_accuracy: 0.4888\n",
      "Epoch 10/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.8103\n",
      "Epoch 00010: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0132 - accuracy: 0.8103 - val_loss: 0.0339 - val_accuracy: 0.5468\n",
      "Epoch 11/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.8208\n",
      "Epoch 00011: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0126 - accuracy: 0.8208 - val_loss: 0.0358 - val_accuracy: 0.5251\n",
      "Epoch 12/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.8269\n",
      "Epoch 00012: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0122 - accuracy: 0.8268 - val_loss: 0.0355 - val_accuracy: 0.5304\n",
      "Epoch 13/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.8351\n",
      "Epoch 00013: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0117 - accuracy: 0.8350 - val_loss: 0.0384 - val_accuracy: 0.4906\n",
      "Epoch 14/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.8424\n",
      "Epoch 00014: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0112 - accuracy: 0.8423 - val_loss: 0.0401 - val_accuracy: 0.4632\n",
      "Epoch 15/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.8460\n",
      "Epoch 00015: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0109 - accuracy: 0.8460 - val_loss: 0.0369 - val_accuracy: 0.5268\n",
      "Epoch 16/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.8519\n",
      "Epoch 00016: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0105 - accuracy: 0.8520 - val_loss: 0.0340 - val_accuracy: 0.5505\n",
      "Epoch 17/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.8585\n",
      "Epoch 00017: val_loss did not improve from 0.03324\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0101 - accuracy: 0.8584 - val_loss: 0.0356 - val_accuracy: 0.5193\n",
      "Epoch 18/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.8610\n",
      "Epoch 00018: val_loss improved from 0.03324 to 0.03269, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi0\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi0/assets\n",
      "896/896 [==============================] - 20s 23ms/step - loss: 0.0099 - accuracy: 0.8610 - val_loss: 0.0327 - val_accuracy: 0.5862\n",
      "Epoch 19/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.8671\n",
      "Epoch 00019: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0095 - accuracy: 0.8671 - val_loss: 0.0365 - val_accuracy: 0.5158\n",
      "Epoch 20/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.8701\n",
      "Epoch 00020: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0093 - accuracy: 0.8700 - val_loss: 0.0362 - val_accuracy: 0.5380\n",
      "Epoch 21/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.8732\n",
      "Epoch 00021: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0091 - accuracy: 0.8732 - val_loss: 0.0391 - val_accuracy: 0.5020\n",
      "Epoch 22/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.8786\n",
      "Epoch 00022: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0087 - accuracy: 0.8787 - val_loss: 0.0374 - val_accuracy: 0.5144\n",
      "Epoch 23/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.8820\n",
      "Epoch 00023: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0085 - accuracy: 0.8820 - val_loss: 0.0390 - val_accuracy: 0.4990\n",
      "Epoch 24/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.8858\n",
      "Epoch 00024: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0083 - accuracy: 0.8857 - val_loss: 0.0368 - val_accuracy: 0.5162\n",
      "Epoch 25/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.8890\n",
      "Epoch 00025: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0081 - accuracy: 0.8890 - val_loss: 0.0366 - val_accuracy: 0.5438\n",
      "Epoch 26/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.8903\n",
      "Epoch 00026: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0080 - accuracy: 0.8903 - val_loss: 0.0363 - val_accuracy: 0.5322\n",
      "Epoch 27/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.8928\n",
      "Epoch 00027: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0077 - accuracy: 0.8929 - val_loss: 0.0362 - val_accuracy: 0.5439\n",
      "Epoch 28/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.8958\n",
      "Epoch 00028: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0075 - accuracy: 0.8958 - val_loss: 0.0375 - val_accuracy: 0.5315\n",
      "Epoch 29/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9002\n",
      "Epoch 00029: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0073 - accuracy: 0.9001 - val_loss: 0.0376 - val_accuracy: 0.5189\n",
      "Epoch 30/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.8992\n",
      "Epoch 00030: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0073 - accuracy: 0.8991 - val_loss: 0.0361 - val_accuracy: 0.5317\n",
      "Epoch 31/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9045\n",
      "Epoch 00031: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0069 - accuracy: 0.9045 - val_loss: 0.0411 - val_accuracy: 0.4911\n",
      "Epoch 32/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9072\n",
      "Epoch 00032: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0068 - accuracy: 0.9072 - val_loss: 0.0374 - val_accuracy: 0.5314\n",
      "Epoch 33/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9057\n",
      "Epoch 00033: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0068 - accuracy: 0.9057 - val_loss: 0.0377 - val_accuracy: 0.5271\n",
      "Epoch 34/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9095\n",
      "Epoch 00034: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0065 - accuracy: 0.9095 - val_loss: 0.0371 - val_accuracy: 0.5266\n",
      "Epoch 35/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9121\n",
      "Epoch 00035: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0064 - accuracy: 0.9120 - val_loss: 0.0376 - val_accuracy: 0.5216\n",
      "Epoch 36/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9126\n",
      "Epoch 00036: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0063 - accuracy: 0.9126 - val_loss: 0.0371 - val_accuracy: 0.5324\n",
      "Epoch 37/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9161\n",
      "Epoch 00037: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0061 - accuracy: 0.9161 - val_loss: 0.0397 - val_accuracy: 0.5156\n",
      "Epoch 38/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9174\n",
      "Epoch 00038: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0060 - accuracy: 0.9174 - val_loss: 0.0382 - val_accuracy: 0.5275\n",
      "Epoch 39/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9187\n",
      "Epoch 00039: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9187 - val_loss: 0.0414 - val_accuracy: 0.5039\n",
      "Epoch 40/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9209\n",
      "Epoch 00040: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0058 - accuracy: 0.9209 - val_loss: 0.0379 - val_accuracy: 0.5314\n",
      "Epoch 41/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9224\n",
      "Epoch 00041: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0056 - accuracy: 0.9225 - val_loss: 0.0442 - val_accuracy: 0.4659\n",
      "Epoch 42/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9243\n",
      "Epoch 00042: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9243 - val_loss: 0.0412 - val_accuracy: 0.5102\n",
      "Epoch 43/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9252\n",
      "Epoch 00043: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9252 - val_loss: 0.0414 - val_accuracy: 0.4902\n",
      "Epoch 44/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9275\n",
      "Epoch 00044: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0053 - accuracy: 0.9275 - val_loss: 0.0408 - val_accuracy: 0.5037\n",
      "Epoch 45/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9269\n",
      "Epoch 00045: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0053 - accuracy: 0.9268 - val_loss: 0.0400 - val_accuracy: 0.5095\n",
      "Epoch 46/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9293\n",
      "Epoch 00046: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0051 - accuracy: 0.9293 - val_loss: 0.0396 - val_accuracy: 0.5161\n",
      "Epoch 47/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9324\n",
      "Epoch 00047: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0050 - accuracy: 0.9324 - val_loss: 0.0385 - val_accuracy: 0.5256\n",
      "Epoch 48/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9304\n",
      "Epoch 00048: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0050 - accuracy: 0.9305 - val_loss: 0.0392 - val_accuracy: 0.5230\n",
      "Epoch 49/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9334\n",
      "Epoch 00049: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0049 - accuracy: 0.9334 - val_loss: 0.0381 - val_accuracy: 0.5414\n",
      "Epoch 50/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9355\n",
      "Epoch 00050: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0047 - accuracy: 0.9355 - val_loss: 0.0405 - val_accuracy: 0.5015\n",
      "Epoch 51/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9352\n",
      "Epoch 00051: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0047 - accuracy: 0.9353 - val_loss: 0.0406 - val_accuracy: 0.5056\n",
      "Epoch 52/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9370\n",
      "Epoch 00052: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0046 - accuracy: 0.9370 - val_loss: 0.0405 - val_accuracy: 0.5196\n",
      "Epoch 53/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9361\n",
      "Epoch 00053: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0047 - accuracy: 0.9362 - val_loss: 0.0396 - val_accuracy: 0.5032\n",
      "Epoch 54/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9381\n",
      "Epoch 00054: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0045 - accuracy: 0.9381 - val_loss: 0.0397 - val_accuracy: 0.5159\n",
      "Epoch 55/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9388\n",
      "Epoch 00055: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0044 - accuracy: 0.9387 - val_loss: 0.0406 - val_accuracy: 0.5097\n",
      "Epoch 56/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9405\n",
      "Epoch 00056: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0043 - accuracy: 0.9405 - val_loss: 0.0381 - val_accuracy: 0.5350\n",
      "Epoch 57/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9423\n",
      "Epoch 00057: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0042 - accuracy: 0.9423 - val_loss: 0.0409 - val_accuracy: 0.4969\n",
      "Epoch 58/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9415\n",
      "Epoch 00058: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0042 - accuracy: 0.9415 - val_loss: 0.0402 - val_accuracy: 0.5155\n",
      "Epoch 59/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9445\n",
      "Epoch 00059: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0041 - accuracy: 0.9445 - val_loss: 0.0412 - val_accuracy: 0.5002\n",
      "Epoch 60/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9437\n",
      "Epoch 00060: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 20ms/step - loss: 0.0041 - accuracy: 0.9437 - val_loss: 0.0451 - val_accuracy: 0.4625\n",
      "Epoch 61/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9442\n",
      "Epoch 00061: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0041 - accuracy: 0.9441 - val_loss: 0.0403 - val_accuracy: 0.5177\n",
      "Epoch 62/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9460\n",
      "Epoch 00062: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0039 - accuracy: 0.9460 - val_loss: 0.0453 - val_accuracy: 0.4492\n",
      "Epoch 63/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9467\n",
      "Epoch 00063: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0039 - accuracy: 0.9467 - val_loss: 0.0413 - val_accuracy: 0.5120\n",
      "Epoch 64/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9456\n",
      "Epoch 00064: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0040 - accuracy: 0.9456 - val_loss: 0.0380 - val_accuracy: 0.5372\n",
      "Epoch 65/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9474\n",
      "Epoch 00065: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0039 - accuracy: 0.9474 - val_loss: 0.0419 - val_accuracy: 0.5019\n",
      "Epoch 66/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9484\n",
      "Epoch 00066: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0038 - accuracy: 0.9484 - val_loss: 0.0386 - val_accuracy: 0.5262\n",
      "Epoch 67/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9495\n",
      "Epoch 00067: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0037 - accuracy: 0.9494 - val_loss: 0.0399 - val_accuracy: 0.5176\n",
      "Epoch 68/100\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9488\n",
      "Epoch 00068: val_loss did not improve from 0.03269\n",
      "896/896 [==============================] - 18s 21ms/step - loss: 0.0038 - accuracy: 0.9489 - val_loss: 0.0421 - val_accuracy: 0.4925\n",
      "Epoch 00068: early stopping\n",
      "Starting loop with val_idx=1\n",
      "Epoch 1/100\n",
      "898/898 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.4250\n",
      "Epoch 00001: val_loss improved from inf to 0.03656, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi1\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi1/assets\n",
      "898/898 [==============================] - 22s 23ms/step - loss: 0.0350 - accuracy: 0.4250 - val_loss: 0.0366 - val_accuracy: 0.3826\n",
      "Epoch 2/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.5990\n",
      "Epoch 00002: val_loss improved from 0.03656 to 0.03229, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi1\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi1/assets\n",
      "898/898 [==============================] - 20s 22ms/step - loss: 0.0260 - accuracy: 0.5991 - val_loss: 0.0323 - val_accuracy: 0.4904\n",
      "Epoch 3/100\n",
      "898/898 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.6659\n",
      "Epoch 00003: val_loss did not improve from 0.03229\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0222 - accuracy: 0.6659 - val_loss: 0.0348 - val_accuracy: 0.4440\n",
      "Epoch 4/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.7044\n",
      "Epoch 00004: val_loss did not improve from 0.03229\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0199 - accuracy: 0.7046 - val_loss: 0.0337 - val_accuracy: 0.4564\n",
      "Epoch 5/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.7345\n",
      "Epoch 00005: val_loss did not improve from 0.03229\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0181 - accuracy: 0.7346 - val_loss: 0.0347 - val_accuracy: 0.5023\n",
      "Epoch 6/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.7537\n",
      "Epoch 00006: val_loss improved from 0.03229 to 0.03090, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi1\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi1/assets\n",
      "898/898 [==============================] - 20s 22ms/step - loss: 0.0169 - accuracy: 0.7536 - val_loss: 0.0309 - val_accuracy: 0.5440\n",
      "Epoch 7/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.7693\n",
      "Epoch 00007: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0159 - accuracy: 0.7692 - val_loss: 0.0337 - val_accuracy: 0.4785\n",
      "Epoch 8/100\n",
      "898/898 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.7807\n",
      "Epoch 00008: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0152 - accuracy: 0.7807 - val_loss: 0.0312 - val_accuracy: 0.5324\n",
      "Epoch 9/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.7934\n",
      "Epoch 00009: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0144 - accuracy: 0.7934 - val_loss: 0.0351 - val_accuracy: 0.4862\n",
      "Epoch 10/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.8014\n",
      "Epoch 00010: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0138 - accuracy: 0.8015 - val_loss: 0.0336 - val_accuracy: 0.5185\n",
      "Epoch 11/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.8124\n",
      "Epoch 00011: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0132 - accuracy: 0.8123 - val_loss: 0.0354 - val_accuracy: 0.4840\n",
      "Epoch 12/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.8197\n",
      "Epoch 00012: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0127 - accuracy: 0.8197 - val_loss: 0.0367 - val_accuracy: 0.4751\n",
      "Epoch 13/100\n",
      "898/898 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.8249\n",
      "Epoch 00013: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0123 - accuracy: 0.8249 - val_loss: 0.0353 - val_accuracy: 0.5042\n",
      "Epoch 14/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.8302\n",
      "Epoch 00014: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0119 - accuracy: 0.8301 - val_loss: 0.0347 - val_accuracy: 0.5120\n",
      "Epoch 15/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.8375\n",
      "Epoch 00015: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0115 - accuracy: 0.8375 - val_loss: 0.0354 - val_accuracy: 0.5088\n",
      "Epoch 16/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.8427\n",
      "Epoch 00016: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0111 - accuracy: 0.8427 - val_loss: 0.0383 - val_accuracy: 0.4661\n",
      "Epoch 17/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.8478\n",
      "Epoch 00017: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0108 - accuracy: 0.8477 - val_loss: 0.0351 - val_accuracy: 0.5095\n",
      "Epoch 18/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.8544\n",
      "Epoch 00018: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0103 - accuracy: 0.8544 - val_loss: 0.0350 - val_accuracy: 0.5199\n",
      "Epoch 19/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.8575\n",
      "Epoch 00019: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0101 - accuracy: 0.8575 - val_loss: 0.0347 - val_accuracy: 0.5304\n",
      "Epoch 20/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.8621\n",
      "Epoch 00020: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0099 - accuracy: 0.8620 - val_loss: 0.0383 - val_accuracy: 0.5034\n",
      "Epoch 21/100\n",
      "897/898 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.8637\n",
      "Epoch 00021: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0097 - accuracy: 0.8637 - val_loss: 0.0361 - val_accuracy: 0.4979\n",
      "Epoch 22/100\n",
      "897/898 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.8685\n",
      "Epoch 00022: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0093 - accuracy: 0.8685 - val_loss: 0.0389 - val_accuracy: 0.4602\n",
      "Epoch 23/100\n",
      "896/898 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.8722\n",
      "Epoch 00023: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0092 - accuracy: 0.8722 - val_loss: 0.0371 - val_accuracy: 0.4863\n",
      "Epoch 24/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.8759\n",
      "Epoch 00024: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0089 - accuracy: 0.8758 - val_loss: 0.0349 - val_accuracy: 0.5207\n",
      "Epoch 25/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.8803\n",
      "Epoch 00025: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0086 - accuracy: 0.8804 - val_loss: 0.0364 - val_accuracy: 0.5181\n",
      "Epoch 26/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.8814\n",
      "Epoch 00026: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0085 - accuracy: 0.8813 - val_loss: 0.0379 - val_accuracy: 0.4858\n",
      "Epoch 27/100\n",
      "896/898 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.8856\n",
      "Epoch 00027: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0082 - accuracy: 0.8856 - val_loss: 0.0390 - val_accuracy: 0.4773\n",
      "Epoch 28/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.8862\n",
      "Epoch 00028: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0081 - accuracy: 0.8862 - val_loss: 0.0358 - val_accuracy: 0.5317\n",
      "Epoch 29/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.8894\n",
      "Epoch 00029: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0079 - accuracy: 0.8895 - val_loss: 0.0373 - val_accuracy: 0.5119\n",
      "Epoch 30/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8943\n",
      "Epoch 00030: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0076 - accuracy: 0.8943 - val_loss: 0.0390 - val_accuracy: 0.4595\n",
      "Epoch 31/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.8957\n",
      "Epoch 00031: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0075 - accuracy: 0.8956 - val_loss: 0.0393 - val_accuracy: 0.4761\n",
      "Epoch 32/100\n",
      "898/898 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.8982\n",
      "Epoch 00032: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0073 - accuracy: 0.8982 - val_loss: 0.0386 - val_accuracy: 0.4978\n",
      "Epoch 33/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9005\n",
      "Epoch 00033: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0072 - accuracy: 0.9006 - val_loss: 0.0376 - val_accuracy: 0.5102\n",
      "Epoch 34/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9019\n",
      "Epoch 00034: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0070 - accuracy: 0.9019 - val_loss: 0.0382 - val_accuracy: 0.5103\n",
      "Epoch 35/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9042\n",
      "Epoch 00035: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0069 - accuracy: 0.9041 - val_loss: 0.0387 - val_accuracy: 0.5055\n",
      "Epoch 36/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9066\n",
      "Epoch 00036: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0067 - accuracy: 0.9066 - val_loss: 0.0404 - val_accuracy: 0.4656\n",
      "Epoch 37/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9081\n",
      "Epoch 00037: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0066 - accuracy: 0.9080 - val_loss: 0.0407 - val_accuracy: 0.4686\n",
      "Epoch 38/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9112\n",
      "Epoch 00038: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0064 - accuracy: 0.9112 - val_loss: 0.0370 - val_accuracy: 0.5226\n",
      "Epoch 39/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9124\n",
      "Epoch 00039: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0063 - accuracy: 0.9124 - val_loss: 0.0386 - val_accuracy: 0.5151\n",
      "Epoch 40/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9153\n",
      "Epoch 00040: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0061 - accuracy: 0.9153 - val_loss: 0.0386 - val_accuracy: 0.5152\n",
      "Epoch 41/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9152\n",
      "Epoch 00041: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0061 - accuracy: 0.9152 - val_loss: 0.0373 - val_accuracy: 0.5195\n",
      "Epoch 42/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9185\n",
      "Epoch 00042: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9185 - val_loss: 0.0381 - val_accuracy: 0.5154\n",
      "Epoch 43/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9172\n",
      "Epoch 00043: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9172 - val_loss: 0.0413 - val_accuracy: 0.4526\n",
      "Epoch 44/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9213\n",
      "Epoch 00044: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0057 - accuracy: 0.9213 - val_loss: 0.0379 - val_accuracy: 0.5133\n",
      "Epoch 45/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9226\n",
      "Epoch 00045: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0056 - accuracy: 0.9226 - val_loss: 0.0379 - val_accuracy: 0.5294\n",
      "Epoch 46/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9232\n",
      "Epoch 00046: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9232 - val_loss: 0.0376 - val_accuracy: 0.5184\n",
      "Epoch 47/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9259\n",
      "Epoch 00047: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0054 - accuracy: 0.9259 - val_loss: 0.0402 - val_accuracy: 0.4934\n",
      "Epoch 48/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9265\n",
      "Epoch 00048: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0053 - accuracy: 0.9265 - val_loss: 0.0397 - val_accuracy: 0.5073\n",
      "Epoch 49/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9277\n",
      "Epoch 00049: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0053 - accuracy: 0.9277 - val_loss: 0.0391 - val_accuracy: 0.5230\n",
      "Epoch 50/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9276\n",
      "Epoch 00050: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0052 - accuracy: 0.9276 - val_loss: 0.0377 - val_accuracy: 0.5255\n",
      "Epoch 51/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9296\n",
      "Epoch 00051: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9296 - val_loss: 0.0361 - val_accuracy: 0.5433\n",
      "Epoch 52/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9314\n",
      "Epoch 00052: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0050 - accuracy: 0.9313 - val_loss: 0.0383 - val_accuracy: 0.5198\n",
      "Epoch 53/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9316\n",
      "Epoch 00053: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0050 - accuracy: 0.9317 - val_loss: 0.0384 - val_accuracy: 0.5257\n",
      "Epoch 54/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9333\n",
      "Epoch 00054: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9333 - val_loss: 0.0409 - val_accuracy: 0.5030\n",
      "Epoch 55/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9336\n",
      "Epoch 00055: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9336 - val_loss: 0.0370 - val_accuracy: 0.5315\n",
      "Epoch 56/100\n",
      "895/898 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9351\n",
      "Epoch 00056: val_loss did not improve from 0.03090\n",
      "898/898 [==============================] - 18s 20ms/step - loss: 0.0047 - accuracy: 0.9351 - val_loss: 0.0380 - val_accuracy: 0.5254\n",
      "Epoch 00056: early stopping\n",
      "Starting loop with val_idx=2\n",
      "Epoch 1/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.4336\n",
      "Epoch 00001: val_loss improved from inf to 0.03726, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi2\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi2/assets\n",
      "889/889 [==============================] - 22s 24ms/step - loss: 0.0347 - accuracy: 0.4336 - val_loss: 0.0373 - val_accuracy: 0.3942\n",
      "Epoch 2/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.6117\n",
      "Epoch 00002: val_loss improved from 0.03726 to 0.03683, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi2\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi2/assets\n",
      "889/889 [==============================] - 20s 23ms/step - loss: 0.0257 - accuracy: 0.6117 - val_loss: 0.0368 - val_accuracy: 0.4353\n",
      "Epoch 3/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.6776\n",
      "Epoch 00003: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 20ms/step - loss: 0.0219 - accuracy: 0.6776 - val_loss: 0.0373 - val_accuracy: 0.4402\n",
      "Epoch 4/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.7172\n",
      "Epoch 00004: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 20ms/step - loss: 0.0194 - accuracy: 0.7171 - val_loss: 0.0373 - val_accuracy: 0.4824\n",
      "Epoch 5/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.7448\n",
      "Epoch 00005: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0176 - accuracy: 0.7448 - val_loss: 0.0398 - val_accuracy: 0.4545\n",
      "Epoch 6/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.7641\n",
      "Epoch 00006: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0165 - accuracy: 0.7641 - val_loss: 0.0378 - val_accuracy: 0.4820\n",
      "Epoch 7/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.7759\n",
      "Epoch 00007: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0156 - accuracy: 0.7759 - val_loss: 0.0386 - val_accuracy: 0.4730\n",
      "Epoch 8/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.7880\n",
      "Epoch 00008: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0149 - accuracy: 0.7880 - val_loss: 0.0384 - val_accuracy: 0.4803\n",
      "Epoch 9/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.7996\n",
      "Epoch 00009: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0141 - accuracy: 0.7996 - val_loss: 0.0384 - val_accuracy: 0.4867\n",
      "Epoch 10/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.8091\n",
      "Epoch 00010: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0135 - accuracy: 0.8091 - val_loss: 0.0387 - val_accuracy: 0.4781\n",
      "Epoch 11/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.8163\n",
      "Epoch 00011: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0129 - accuracy: 0.8163 - val_loss: 0.0386 - val_accuracy: 0.4947\n",
      "Epoch 12/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.8241\n",
      "Epoch 00012: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0124 - accuracy: 0.8241 - val_loss: 0.0388 - val_accuracy: 0.4886\n",
      "Epoch 13/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.8302\n",
      "Epoch 00013: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0120 - accuracy: 0.8302 - val_loss: 0.0390 - val_accuracy: 0.4784\n",
      "Epoch 14/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.8360\n",
      "Epoch 00014: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0116 - accuracy: 0.8361 - val_loss: 0.0378 - val_accuracy: 0.5071\n",
      "Epoch 15/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.8416\n",
      "Epoch 00015: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0112 - accuracy: 0.8416 - val_loss: 0.0401 - val_accuracy: 0.4839\n",
      "Epoch 16/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.8474\n",
      "Epoch 00016: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0108 - accuracy: 0.8474 - val_loss: 0.0404 - val_accuracy: 0.4859\n",
      "Epoch 17/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.8556\n",
      "Epoch 00017: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0103 - accuracy: 0.8555 - val_loss: 0.0400 - val_accuracy: 0.4938\n",
      "Epoch 18/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.8573\n",
      "Epoch 00018: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0101 - accuracy: 0.8572 - val_loss: 0.0399 - val_accuracy: 0.4843\n",
      "Epoch 19/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.8634\n",
      "Epoch 00019: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0098 - accuracy: 0.8633 - val_loss: 0.0388 - val_accuracy: 0.5028\n",
      "Epoch 20/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.8669\n",
      "Epoch 00020: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0094 - accuracy: 0.8669 - val_loss: 0.0412 - val_accuracy: 0.4670\n",
      "Epoch 21/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.8706\n",
      "Epoch 00021: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0092 - accuracy: 0.8706 - val_loss: 0.0442 - val_accuracy: 0.4462\n",
      "Epoch 22/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.8753\n",
      "Epoch 00022: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0089 - accuracy: 0.8753 - val_loss: 0.0422 - val_accuracy: 0.4737\n",
      "Epoch 23/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.8779\n",
      "Epoch 00023: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0087 - accuracy: 0.8779 - val_loss: 0.0411 - val_accuracy: 0.4878\n",
      "Epoch 24/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.8812\n",
      "Epoch 00024: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0085 - accuracy: 0.8812 - val_loss: 0.0412 - val_accuracy: 0.4787\n",
      "Epoch 25/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.8850\n",
      "Epoch 00025: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0082 - accuracy: 0.8850 - val_loss: 0.0400 - val_accuracy: 0.4980\n",
      "Epoch 26/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.8898\n",
      "Epoch 00026: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0080 - accuracy: 0.8897 - val_loss: 0.0411 - val_accuracy: 0.4813\n",
      "Epoch 27/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.8899\n",
      "Epoch 00027: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0079 - accuracy: 0.8898 - val_loss: 0.0417 - val_accuracy: 0.4808\n",
      "Epoch 28/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8939\n",
      "Epoch 00028: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0076 - accuracy: 0.8939 - val_loss: 0.0438 - val_accuracy: 0.4607\n",
      "Epoch 29/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9109\n",
      "Epoch 00035: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0065 - accuracy: 0.9109 - val_loss: 0.0459 - val_accuracy: 0.4598\n",
      "Epoch 36/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9117\n",
      "Epoch 00036: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0064 - accuracy: 0.9117 - val_loss: 0.0423 - val_accuracy: 0.4858\n",
      "Epoch 37/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9130\n",
      "Epoch 00037: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0063 - accuracy: 0.9131 - val_loss: 0.0409 - val_accuracy: 0.5038\n",
      "Epoch 38/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9141\n",
      "Epoch 00038: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0062 - accuracy: 0.9141 - val_loss: 0.0441 - val_accuracy: 0.4643\n",
      "Epoch 39/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9188\n",
      "Epoch 00039: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0059 - accuracy: 0.9188 - val_loss: 0.0448 - val_accuracy: 0.4609\n",
      "Epoch 40/100\n",
      "889/889 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9178\n",
      "Epoch 00040: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0059 - accuracy: 0.9178 - val_loss: 0.0439 - val_accuracy: 0.4717\n",
      "Epoch 41/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9190\n",
      "Epoch 00041: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0059 - accuracy: 0.9188 - val_loss: 0.0440 - val_accuracy: 0.4674\n",
      "Epoch 42/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9222\n",
      "Epoch 00042: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0056 - accuracy: 0.9221 - val_loss: 0.0438 - val_accuracy: 0.4738\n",
      "Epoch 43/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9248\n",
      "Epoch 00043: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0055 - accuracy: 0.9248 - val_loss: 0.0443 - val_accuracy: 0.4703\n",
      "Epoch 44/100\n",
      "886/889 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9250\n",
      "Epoch 00044: val_loss did not improve from 0.03683\n",
      "889/889 [==============================] - 18s 21ms/step - loss: 0.0054 - accuracy: 0.9250 - val_loss: 0.0442 - val_accuracy: 0.4619\n",
      "Epoch 45/100\n",
      "667/889 [=====================>........] - ETA: 4s - loss: 0.0053 - accuracy: 0.9269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883/886 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.6595\n",
      "Epoch 00003: val_loss improved from 0.02951 to 0.02599, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi3\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi3/assets\n",
      "886/886 [==============================] - 20s 22ms/step - loss: 0.0227 - accuracy: 0.6595 - val_loss: 0.0260 - val_accuracy: 0.6026\n",
      "Epoch 4/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.7012\n",
      "Epoch 00004: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0202 - accuracy: 0.7012 - val_loss: 0.0284 - val_accuracy: 0.5690\n",
      "Epoch 5/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.7319\n",
      "Epoch 00005: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0183 - accuracy: 0.7320 - val_loss: 0.0269 - val_accuracy: 0.6024\n",
      "Epoch 6/100\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.7503\n",
      "Epoch 00006: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0171 - accuracy: 0.7503 - val_loss: 0.0290 - val_accuracy: 0.5801\n",
      "Epoch 7/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.7678\n",
      "Epoch 00007: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0160 - accuracy: 0.7679 - val_loss: 0.0302 - val_accuracy: 0.5596\n",
      "Epoch 8/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.7819\n",
      "Epoch 00008: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0151 - accuracy: 0.7818 - val_loss: 0.0290 - val_accuracy: 0.5708\n",
      "Epoch 9/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.7916\n",
      "Epoch 00009: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0144 - accuracy: 0.7916 - val_loss: 0.0286 - val_accuracy: 0.5942\n",
      "Epoch 10/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.8006\n",
      "Epoch 00010: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0138 - accuracy: 0.8007 - val_loss: 0.0323 - val_accuracy: 0.5368\n",
      "Epoch 11/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.8101\n",
      "Epoch 00011: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0132 - accuracy: 0.8101 - val_loss: 0.0302 - val_accuracy: 0.5599\n",
      "Epoch 12/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.8197\n",
      "Epoch 00012: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0126 - accuracy: 0.8196 - val_loss: 0.0298 - val_accuracy: 0.5735\n",
      "Epoch 13/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.8260\n",
      "Epoch 00013: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0121 - accuracy: 0.8259 - val_loss: 0.0318 - val_accuracy: 0.5652\n",
      "Epoch 14/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.8321\n",
      "Epoch 00014: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0118 - accuracy: 0.8320 - val_loss: 0.0294 - val_accuracy: 0.5761\n",
      "Epoch 15/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.8369\n",
      "Epoch 00015: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0114 - accuracy: 0.8368 - val_loss: 0.0300 - val_accuracy: 0.5680\n",
      "Epoch 16/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.8428\n",
      "Epoch 00016: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0110 - accuracy: 0.8427 - val_loss: 0.0322 - val_accuracy: 0.5482\n",
      "Epoch 17/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.8491\n",
      "Epoch 00017: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0106 - accuracy: 0.8491 - val_loss: 0.0345 - val_accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.8555\n",
      "Epoch 00018: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0102 - accuracy: 0.8555 - val_loss: 0.0285 - val_accuracy: 0.5955\n",
      "Epoch 19/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.8586\n",
      "Epoch 00019: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0100 - accuracy: 0.8586 - val_loss: 0.0301 - val_accuracy: 0.5882\n",
      "Epoch 20/100\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.8645\n",
      "Epoch 00020: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0096 - accuracy: 0.8645 - val_loss: 0.0306 - val_accuracy: 0.5669\n",
      "Epoch 21/100\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.8681\n",
      "Epoch 00021: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0094 - accuracy: 0.8681 - val_loss: 0.0348 - val_accuracy: 0.5477\n",
      "Epoch 22/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.8708\n",
      "Epoch 00022: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0091 - accuracy: 0.8708 - val_loss: 0.0321 - val_accuracy: 0.5686\n",
      "Epoch 23/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.8748\n",
      "Epoch 00023: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0088 - accuracy: 0.8748 - val_loss: 0.0297 - val_accuracy: 0.5966\n",
      "Epoch 24/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.8794\n",
      "Epoch 00024: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0086 - accuracy: 0.8794 - val_loss: 0.0321 - val_accuracy: 0.5510\n",
      "Epoch 25/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.8818\n",
      "Epoch 00025: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0084 - accuracy: 0.8817 - val_loss: 0.0302 - val_accuracy: 0.5774\n",
      "Epoch 26/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.8849\n",
      "Epoch 00026: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0082 - accuracy: 0.8848 - val_loss: 0.0296 - val_accuracy: 0.6090\n",
      "Epoch 27/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.8872\n",
      "Epoch 00027: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0080 - accuracy: 0.8871 - val_loss: 0.0303 - val_accuracy: 0.5879\n",
      "Epoch 28/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.8893\n",
      "Epoch 00028: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0079 - accuracy: 0.8893 - val_loss: 0.0299 - val_accuracy: 0.5951\n",
      "Epoch 29/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8932\n",
      "Epoch 00029: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0076 - accuracy: 0.8933 - val_loss: 0.0308 - val_accuracy: 0.5890\n",
      "Epoch 30/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.8955\n",
      "Epoch 00030: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0075 - accuracy: 0.8956 - val_loss: 0.0298 - val_accuracy: 0.5945\n",
      "Epoch 31/100\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.8984\n",
      "Epoch 00031: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0073 - accuracy: 0.8984 - val_loss: 0.0318 - val_accuracy: 0.5654\n",
      "Epoch 32/100\n",
      "884/886 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9019\n",
      "Epoch 00032: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0070 - accuracy: 0.9020 - val_loss: 0.0332 - val_accuracy: 0.5657\n",
      "Epoch 33/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9030\n",
      "Epoch 00033: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0070 - accuracy: 0.9029 - val_loss: 0.0323 - val_accuracy: 0.5550\n",
      "Epoch 34/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9047\n",
      "Epoch 00034: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0069 - accuracy: 0.9047 - val_loss: 0.0322 - val_accuracy: 0.5791\n",
      "Epoch 35/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9064\n",
      "Epoch 00035: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0067 - accuracy: 0.9064 - val_loss: 0.0302 - val_accuracy: 0.5938\n",
      "Epoch 36/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9100\n",
      "Epoch 00036: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0065 - accuracy: 0.9100 - val_loss: 0.0324 - val_accuracy: 0.5698\n",
      "Epoch 37/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9107\n",
      "Epoch 00037: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0064 - accuracy: 0.9106 - val_loss: 0.0321 - val_accuracy: 0.5799\n",
      "Epoch 38/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9119\n",
      "Epoch 00038: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0063 - accuracy: 0.9118 - val_loss: 0.0351 - val_accuracy: 0.5490\n",
      "Epoch 39/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9145\n",
      "Epoch 00039: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0062 - accuracy: 0.9146 - val_loss: 0.0341 - val_accuracy: 0.5669\n",
      "Epoch 40/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9162\n",
      "Epoch 00040: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0061 - accuracy: 0.9162 - val_loss: 0.0363 - val_accuracy: 0.5453\n",
      "Epoch 41/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9172\n",
      "Epoch 00041: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9172 - val_loss: 0.0291 - val_accuracy: 0.6161\n",
      "Epoch 42/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9198\n",
      "Epoch 00042: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0058 - accuracy: 0.9197 - val_loss: 0.0338 - val_accuracy: 0.5526\n",
      "Epoch 43/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9213\n",
      "Epoch 00043: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0057 - accuracy: 0.9213 - val_loss: 0.0316 - val_accuracy: 0.5809\n",
      "Epoch 44/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9235\n",
      "Epoch 00044: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9236 - val_loss: 0.0341 - val_accuracy: 0.5599\n",
      "Epoch 45/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9235\n",
      "Epoch 00045: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9235 - val_loss: 0.0357 - val_accuracy: 0.5379\n",
      "Epoch 46/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9260\n",
      "Epoch 00046: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0054 - accuracy: 0.9259 - val_loss: 0.0352 - val_accuracy: 0.5479\n",
      "Epoch 47/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9265\n",
      "Epoch 00047: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0053 - accuracy: 0.9264 - val_loss: 0.0331 - val_accuracy: 0.5729\n",
      "Epoch 48/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9271\n",
      "Epoch 00048: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 21ms/step - loss: 0.0053 - accuracy: 0.9271 - val_loss: 0.0338 - val_accuracy: 0.5715\n",
      "Epoch 49/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9290\n",
      "Epoch 00049: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9290 - val_loss: 0.0353 - val_accuracy: 0.5534\n",
      "Epoch 50/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9307\n",
      "Epoch 00050: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0050 - accuracy: 0.9306 - val_loss: 0.0346 - val_accuracy: 0.5628\n",
      "Epoch 51/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9311\n",
      "Epoch 00051: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0050 - accuracy: 0.9311 - val_loss: 0.0308 - val_accuracy: 0.5981\n",
      "Epoch 52/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9348\n",
      "Epoch 00052: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9348 - val_loss: 0.0336 - val_accuracy: 0.5576\n",
      "Epoch 53/100\n",
      "883/886 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9339\n",
      "Epoch 00053: val_loss did not improve from 0.02599\n",
      "886/886 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9339 - val_loss: 0.0371 - val_accuracy: 0.5418\n",
      "Epoch 00053: early stopping\n",
      "Starting loop with val_idx=4\n",
      "Epoch 1/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.4043\n",
      "Epoch 00001: val_loss improved from inf to 0.03235, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi4\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi4/assets\n",
      "892/892 [==============================] - 22s 23ms/step - loss: 0.0361 - accuracy: 0.4043 - val_loss: 0.0323 - val_accuracy: 0.4795\n",
      "Epoch 2/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.5889\n",
      "Epoch 00002: val_loss improved from 0.03235 to 0.02926, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi4\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi4/assets\n",
      "892/892 [==============================] - 20s 23ms/step - loss: 0.0270 - accuracy: 0.5889 - val_loss: 0.0293 - val_accuracy: 0.5655\n",
      "Epoch 3/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.6565\n",
      "Epoch 00003: val_loss improved from 0.02926 to 0.02864, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi4\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi4/assets\n",
      "892/892 [==============================] - 20s 22ms/step - loss: 0.0230 - accuracy: 0.6565 - val_loss: 0.0286 - val_accuracy: 0.5514\n",
      "Epoch 4/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.7002\n",
      "Epoch 00004: val_loss did not improve from 0.02864\n",
      "892/892 [==============================] - 18s 20ms/step - loss: 0.0203 - accuracy: 0.7002 - val_loss: 0.0287 - val_accuracy: 0.5473\n",
      "Epoch 5/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.7276\n",
      "Epoch 00005: val_loss improved from 0.02864 to 0.02760, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi4\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi4/assets\n",
      "892/892 [==============================] - 20s 22ms/step - loss: 0.0186 - accuracy: 0.7276 - val_loss: 0.0276 - val_accuracy: 0.5797\n",
      "Epoch 6/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.7505\n",
      "Epoch 00006: val_loss improved from 0.02760 to 0.02726, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi4\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi4/assets\n",
      "892/892 [==============================] - 20s 23ms/step - loss: 0.0171 - accuracy: 0.7505 - val_loss: 0.0273 - val_accuracy: 0.5919\n",
      "Epoch 7/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.7645\n",
      "Epoch 00007: val_loss did not improve from 0.02726\n",
      "892/892 [==============================] - 18s 20ms/step - loss: 0.0161 - accuracy: 0.7645 - val_loss: 0.0281 - val_accuracy: 0.5887\n",
      "Epoch 8/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.7801\n",
      "Epoch 00008: val_loss did not improve from 0.02726\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0152 - accuracy: 0.7801 - val_loss: 0.0280 - val_accuracy: 0.6079\n",
      "Epoch 9/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.7896\n",
      "Epoch 00009: val_loss improved from 0.02726 to 0.02708, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi4\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi4/assets\n",
      "892/892 [==============================] - 20s 23ms/step - loss: 0.0146 - accuracy: 0.7896 - val_loss: 0.0271 - val_accuracy: 0.6030\n",
      "Epoch 10/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.8015\n",
      "Epoch 00010: val_loss did not improve from 0.02708\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0138 - accuracy: 0.8015 - val_loss: 0.0278 - val_accuracy: 0.5682\n",
      "Epoch 11/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.8089\n",
      "Epoch 00011: val_loss did not improve from 0.02708\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0133 - accuracy: 0.8089 - val_loss: 0.0288 - val_accuracy: 0.5595\n",
      "Epoch 12/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.8150\n",
      "Epoch 00012: val_loss improved from 0.02708 to 0.02570, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi4\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi4/assets\n",
      "892/892 [==============================] - 20s 23ms/step - loss: 0.0129 - accuracy: 0.8150 - val_loss: 0.0257 - val_accuracy: 0.6154\n",
      "Epoch 13/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.8222\n",
      "Epoch 00013: val_loss did not improve from 0.02570\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0124 - accuracy: 0.8222 - val_loss: 0.0278 - val_accuracy: 0.6049\n",
      "Epoch 14/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.8294\n",
      "Epoch 00014: val_loss did not improve from 0.02570\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0120 - accuracy: 0.8294 - val_loss: 0.0258 - val_accuracy: 0.6164\n",
      "Epoch 15/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.8354\n",
      "Epoch 00015: val_loss did not improve from 0.02570\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0116 - accuracy: 0.8354 - val_loss: 0.0279 - val_accuracy: 0.6305\n",
      "Epoch 16/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.8417\n",
      "Epoch 00016: val_loss did not improve from 0.02570\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0111 - accuracy: 0.8417 - val_loss: 0.0272 - val_accuracy: 0.5816\n",
      "Epoch 17/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.8460\n",
      "Epoch 00017: val_loss did not improve from 0.02570\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0108 - accuracy: 0.8460 - val_loss: 0.0265 - val_accuracy: 0.6359\n",
      "Epoch 18/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.8507\n",
      "Epoch 00018: val_loss did not improve from 0.02570\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0105 - accuracy: 0.8507 - val_loss: 0.0306 - val_accuracy: 0.5929\n",
      "Epoch 19/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.8548\n",
      "Epoch 00019: val_loss did not improve from 0.02570\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0102 - accuracy: 0.8548 - val_loss: 0.0279 - val_accuracy: 0.5814\n",
      "Epoch 20/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.8616\n",
      "Epoch 00020: val_loss improved from 0.02570 to 0.02514, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi4\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi4/assets\n",
      "892/892 [==============================] - 20s 23ms/step - loss: 0.0098 - accuracy: 0.8616 - val_loss: 0.0251 - val_accuracy: 0.6485\n",
      "Epoch 21/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.8643\n",
      "Epoch 00021: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0096 - accuracy: 0.8643 - val_loss: 0.0266 - val_accuracy: 0.6359\n",
      "Epoch 22/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.8685\n",
      "Epoch 00022: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0093 - accuracy: 0.8685 - val_loss: 0.0264 - val_accuracy: 0.6153\n",
      "Epoch 23/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.8710\n",
      "Epoch 00023: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0091 - accuracy: 0.8710 - val_loss: 0.0293 - val_accuracy: 0.5919\n",
      "Epoch 24/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.8759\n",
      "Epoch 00024: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0088 - accuracy: 0.8759 - val_loss: 0.0291 - val_accuracy: 0.5920\n",
      "Epoch 25/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.8790\n",
      "Epoch 00025: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0086 - accuracy: 0.8790 - val_loss: 0.0281 - val_accuracy: 0.5971\n",
      "Epoch 26/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.8810\n",
      "Epoch 00026: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0084 - accuracy: 0.8810 - val_loss: 0.0278 - val_accuracy: 0.6231\n",
      "Epoch 27/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.8852\n",
      "Epoch 00027: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0082 - accuracy: 0.8852 - val_loss: 0.0292 - val_accuracy: 0.6046\n",
      "Epoch 28/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.8866\n",
      "Epoch 00028: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0080 - accuracy: 0.8866 - val_loss: 0.0314 - val_accuracy: 0.5639\n",
      "Epoch 29/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.8898\n",
      "Epoch 00029: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0079 - accuracy: 0.8898 - val_loss: 0.0312 - val_accuracy: 0.5953\n",
      "Epoch 30/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.8915\n",
      "Epoch 00030: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0077 - accuracy: 0.8915 - val_loss: 0.0308 - val_accuracy: 0.5939\n",
      "Epoch 31/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.8939\n",
      "Epoch 00031: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0075 - accuracy: 0.8939 - val_loss: 0.0306 - val_accuracy: 0.5960\n",
      "Epoch 32/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.8976\n",
      "Epoch 00032: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0074 - accuracy: 0.8976 - val_loss: 0.0296 - val_accuracy: 0.5993\n",
      "Epoch 33/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.8979\n",
      "Epoch 00033: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0073 - accuracy: 0.8979 - val_loss: 0.0269 - val_accuracy: 0.6294\n",
      "Epoch 34/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9009\n",
      "Epoch 00034: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0071 - accuracy: 0.9009 - val_loss: 0.0305 - val_accuracy: 0.5903\n",
      "Epoch 35/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9032\n",
      "Epoch 00035: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0070 - accuracy: 0.9032 - val_loss: 0.0293 - val_accuracy: 0.6081\n",
      "Epoch 36/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9039\n",
      "Epoch 00036: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0068 - accuracy: 0.9039 - val_loss: 0.0307 - val_accuracy: 0.6079\n",
      "Epoch 37/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9062\n",
      "Epoch 00037: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0067 - accuracy: 0.9062 - val_loss: 0.0335 - val_accuracy: 0.5571\n",
      "Epoch 38/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9089\n",
      "Epoch 00038: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0065 - accuracy: 0.9089 - val_loss: 0.0321 - val_accuracy: 0.5862\n",
      "Epoch 39/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9113\n",
      "Epoch 00039: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0063 - accuracy: 0.9113 - val_loss: 0.0318 - val_accuracy: 0.5669\n",
      "Epoch 40/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9120\n",
      "Epoch 00040: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0063 - accuracy: 0.9120 - val_loss: 0.0302 - val_accuracy: 0.6083\n",
      "Epoch 41/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9139\n",
      "Epoch 00041: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0062 - accuracy: 0.9139 - val_loss: 0.0319 - val_accuracy: 0.5723\n",
      "Epoch 42/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9156\n",
      "Epoch 00042: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0060 - accuracy: 0.9156 - val_loss: 0.0329 - val_accuracy: 0.5727\n",
      "Epoch 43/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9166\n",
      "Epoch 00043: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0060 - accuracy: 0.9166 - val_loss: 0.0297 - val_accuracy: 0.6122\n",
      "Epoch 44/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9188\n",
      "Epoch 00044: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0058 - accuracy: 0.9188 - val_loss: 0.0346 - val_accuracy: 0.5608\n",
      "Epoch 45/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9195\n",
      "Epoch 00045: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0058 - accuracy: 0.9195 - val_loss: 0.0332 - val_accuracy: 0.5615\n",
      "Epoch 46/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9207\n",
      "Epoch 00046: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0056 - accuracy: 0.9207 - val_loss: 0.0294 - val_accuracy: 0.6099\n",
      "Epoch 47/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9233\n",
      "Epoch 00047: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0055 - accuracy: 0.9233 - val_loss: 0.0279 - val_accuracy: 0.6331\n",
      "Epoch 48/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9248\n",
      "Epoch 00048: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0054 - accuracy: 0.9248 - val_loss: 0.0350 - val_accuracy: 0.5485\n",
      "Epoch 49/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9250\n",
      "Epoch 00049: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0053 - accuracy: 0.9250 - val_loss: 0.0290 - val_accuracy: 0.6043\n",
      "Epoch 50/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9266\n",
      "Epoch 00050: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0053 - accuracy: 0.9266 - val_loss: 0.0326 - val_accuracy: 0.5708\n",
      "Epoch 51/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9288\n",
      "Epoch 00051: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0051 - accuracy: 0.9288 - val_loss: 0.0324 - val_accuracy: 0.5881\n",
      "Epoch 52/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9309\n",
      "Epoch 00052: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0050 - accuracy: 0.9309 - val_loss: 0.0290 - val_accuracy: 0.6339\n",
      "Epoch 53/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9289\n",
      "Epoch 00053: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0051 - accuracy: 0.9289 - val_loss: 0.0292 - val_accuracy: 0.6124\n",
      "Epoch 54/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9321\n",
      "Epoch 00054: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0049 - accuracy: 0.9321 - val_loss: 0.0271 - val_accuracy: 0.6528\n",
      "Epoch 55/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9333\n",
      "Epoch 00055: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0048 - accuracy: 0.9333 - val_loss: 0.0301 - val_accuracy: 0.6141\n",
      "Epoch 56/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9341\n",
      "Epoch 00056: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0047 - accuracy: 0.9341 - val_loss: 0.0361 - val_accuracy: 0.5560\n",
      "Epoch 57/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9341\n",
      "Epoch 00057: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0047 - accuracy: 0.9341 - val_loss: 0.0333 - val_accuracy: 0.5943\n",
      "Epoch 58/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9357\n",
      "Epoch 00058: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0046 - accuracy: 0.9357 - val_loss: 0.0285 - val_accuracy: 0.6395\n",
      "Epoch 59/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9374\n",
      "Epoch 00059: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0045 - accuracy: 0.9374 - val_loss: 0.0309 - val_accuracy: 0.6188\n",
      "Epoch 60/100\n",
      "890/892 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9373\n",
      "Epoch 00060: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0045 - accuracy: 0.9373 - val_loss: 0.0310 - val_accuracy: 0.6006\n",
      "Epoch 61/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9395\n",
      "Epoch 00061: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0044 - accuracy: 0.9395 - val_loss: 0.0352 - val_accuracy: 0.5436\n",
      "Epoch 62/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9402\n",
      "Epoch 00062: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0043 - accuracy: 0.9402 - val_loss: 0.0312 - val_accuracy: 0.6069\n",
      "Epoch 63/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9416\n",
      "Epoch 00063: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0042 - accuracy: 0.9416 - val_loss: 0.0325 - val_accuracy: 0.5901\n",
      "Epoch 64/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9409\n",
      "Epoch 00064: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0042 - accuracy: 0.9409 - val_loss: 0.0329 - val_accuracy: 0.5870\n",
      "Epoch 65/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9423\n",
      "Epoch 00065: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0042 - accuracy: 0.9423 - val_loss: 0.0330 - val_accuracy: 0.5863\n",
      "Epoch 66/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9428\n",
      "Epoch 00066: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0041 - accuracy: 0.9428 - val_loss: 0.0317 - val_accuracy: 0.5975\n",
      "Epoch 67/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9428\n",
      "Epoch 00067: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0041 - accuracy: 0.9428 - val_loss: 0.0313 - val_accuracy: 0.6116\n",
      "Epoch 68/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9442\n",
      "Epoch 00068: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0040 - accuracy: 0.9442 - val_loss: 0.0339 - val_accuracy: 0.5780\n",
      "Epoch 69/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9454\n",
      "Epoch 00069: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0039 - accuracy: 0.9454 - val_loss: 0.0316 - val_accuracy: 0.5943\n",
      "Epoch 70/100\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9448\n",
      "Epoch 00070: val_loss did not improve from 0.02514\n",
      "892/892 [==============================] - 18s 21ms/step - loss: 0.0040 - accuracy: 0.9448 - val_loss: 0.0318 - val_accuracy: 0.6027\n",
      "Epoch 00070: early stopping\n",
      "Starting loop with val_idx=5\n",
      "Epoch 1/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.4367\n",
      "Epoch 00001: val_loss improved from inf to 0.03555, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi5\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi5/assets\n",
      "903/903 [==============================] - 22s 23ms/step - loss: 0.0344 - accuracy: 0.4370 - val_loss: 0.0356 - val_accuracy: 0.4260\n",
      "Epoch 2/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.6182\n",
      "Epoch 00002: val_loss improved from 0.03555 to 0.03418, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi5\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi5/assets\n",
      "903/903 [==============================] - 20s 23ms/step - loss: 0.0252 - accuracy: 0.6182 - val_loss: 0.0342 - val_accuracy: 0.4862\n",
      "Epoch 3/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.6897\n",
      "Epoch 00003: val_loss did not improve from 0.03418\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0210 - accuracy: 0.6898 - val_loss: 0.0374 - val_accuracy: 0.4731\n",
      "Epoch 4/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.7271\n",
      "Epoch 00004: val_loss did not improve from 0.03418\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0187 - accuracy: 0.7272 - val_loss: 0.0355 - val_accuracy: 0.4749\n",
      "Epoch 5/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.7527\n",
      "Epoch 00005: val_loss did not improve from 0.03418\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0171 - accuracy: 0.7526 - val_loss: 0.0352 - val_accuracy: 0.4966\n",
      "Epoch 6/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.7696\n",
      "Epoch 00006: val_loss did not improve from 0.03418\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0160 - accuracy: 0.7695 - val_loss: 0.0357 - val_accuracy: 0.4927\n",
      "Epoch 7/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.7839\n",
      "Epoch 00007: val_loss improved from 0.03418 to 0.03363, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi5\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi5/assets\n",
      "903/903 [==============================] - 20s 22ms/step - loss: 0.0150 - accuracy: 0.7838 - val_loss: 0.0336 - val_accuracy: 0.5296\n",
      "Epoch 8/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.7939\n",
      "Epoch 00008: val_loss improved from 0.03363 to 0.03254, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi5\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi5/assets\n",
      "903/903 [==============================] - 20s 22ms/step - loss: 0.0143 - accuracy: 0.7940 - val_loss: 0.0325 - val_accuracy: 0.5276\n",
      "Epoch 9/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.8049\n",
      "Epoch 00009: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0136 - accuracy: 0.8049 - val_loss: 0.0353 - val_accuracy: 0.5162\n",
      "Epoch 10/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.8155\n",
      "Epoch 00010: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0130 - accuracy: 0.8154 - val_loss: 0.0329 - val_accuracy: 0.5337\n",
      "Epoch 11/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.8227\n",
      "Epoch 00011: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0125 - accuracy: 0.8226 - val_loss: 0.0335 - val_accuracy: 0.5432\n",
      "Epoch 12/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.8282\n",
      "Epoch 00012: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0121 - accuracy: 0.8282 - val_loss: 0.0356 - val_accuracy: 0.5226\n",
      "Epoch 13/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.8333\n",
      "Epoch 00013: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0116 - accuracy: 0.8333 - val_loss: 0.0338 - val_accuracy: 0.5396\n",
      "Epoch 14/100\n",
      "902/903 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.8386\n",
      "Epoch 00014: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 19s 21ms/step - loss: 0.0113 - accuracy: 0.8386 - val_loss: 0.0351 - val_accuracy: 0.5264\n",
      "Epoch 15/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.8451\n",
      "Epoch 00015: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0109 - accuracy: 0.8451 - val_loss: 0.0340 - val_accuracy: 0.5332\n",
      "Epoch 16/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.8506\n",
      "Epoch 00016: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0106 - accuracy: 0.8505 - val_loss: 0.0349 - val_accuracy: 0.5358\n",
      "Epoch 17/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.8566\n",
      "Epoch 00017: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0102 - accuracy: 0.8566 - val_loss: 0.0345 - val_accuracy: 0.5275\n",
      "Epoch 18/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.8605\n",
      "Epoch 00018: val_loss did not improve from 0.03254\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0099 - accuracy: 0.8606 - val_loss: 0.0346 - val_accuracy: 0.5321\n",
      "Epoch 19/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.8647\n",
      "Epoch 00019: val_loss improved from 0.03254 to 0.03132, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi5\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi5/assets\n",
      "903/903 [==============================] - 21s 23ms/step - loss: 0.0096 - accuracy: 0.8648 - val_loss: 0.0313 - val_accuracy: 0.5727\n",
      "Epoch 20/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.8688\n",
      "Epoch 00020: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0093 - accuracy: 0.8688 - val_loss: 0.0342 - val_accuracy: 0.5413\n",
      "Epoch 21/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.8741\n",
      "Epoch 00021: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0090 - accuracy: 0.8742 - val_loss: 0.0359 - val_accuracy: 0.5305\n",
      "Epoch 22/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.8765\n",
      "Epoch 00022: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0088 - accuracy: 0.8765 - val_loss: 0.0358 - val_accuracy: 0.5331\n",
      "Epoch 23/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.8808\n",
      "Epoch 00023: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0086 - accuracy: 0.8808 - val_loss: 0.0367 - val_accuracy: 0.5105\n",
      "Epoch 24/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.8840\n",
      "Epoch 00024: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0083 - accuracy: 0.8840 - val_loss: 0.0323 - val_accuracy: 0.5691\n",
      "Epoch 25/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.8888\n",
      "Epoch 00025: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0080 - accuracy: 0.8888 - val_loss: 0.0364 - val_accuracy: 0.5225\n",
      "Epoch 26/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.8901\n",
      "Epoch 00026: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0079 - accuracy: 0.8899 - val_loss: 0.0345 - val_accuracy: 0.5395\n",
      "Epoch 27/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8933\n",
      "Epoch 00027: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0076 - accuracy: 0.8933 - val_loss: 0.0336 - val_accuracy: 0.5551\n",
      "Epoch 28/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8944\n",
      "Epoch 00028: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0076 - accuracy: 0.8943 - val_loss: 0.0390 - val_accuracy: 0.5017\n",
      "Epoch 29/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.8973\n",
      "Epoch 00029: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0073 - accuracy: 0.8973 - val_loss: 0.0345 - val_accuracy: 0.5466\n",
      "Epoch 30/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.8990\n",
      "Epoch 00030: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0072 - accuracy: 0.8990 - val_loss: 0.0372 - val_accuracy: 0.5326\n",
      "Epoch 31/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9035\n",
      "Epoch 00031: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0069 - accuracy: 0.9034 - val_loss: 0.0357 - val_accuracy: 0.5294\n",
      "Epoch 32/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9040\n",
      "Epoch 00032: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0069 - accuracy: 0.9040 - val_loss: 0.0363 - val_accuracy: 0.5308\n",
      "Epoch 33/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9068\n",
      "Epoch 00033: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0067 - accuracy: 0.9069 - val_loss: 0.0363 - val_accuracy: 0.5463\n",
      "Epoch 34/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9082\n",
      "Epoch 00034: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0066 - accuracy: 0.9082 - val_loss: 0.0386 - val_accuracy: 0.5179\n",
      "Epoch 35/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9104\n",
      "Epoch 00035: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0064 - accuracy: 0.9104 - val_loss: 0.0381 - val_accuracy: 0.5164\n",
      "Epoch 36/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9132\n",
      "Epoch 00036: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0062 - accuracy: 0.9132 - val_loss: 0.0337 - val_accuracy: 0.5665\n",
      "Epoch 37/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9149\n",
      "Epoch 00037: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0061 - accuracy: 0.9149 - val_loss: 0.0385 - val_accuracy: 0.5110\n",
      "Epoch 38/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9169\n",
      "Epoch 00038: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0060 - accuracy: 0.9170 - val_loss: 0.0408 - val_accuracy: 0.5020\n",
      "Epoch 39/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9183\n",
      "Epoch 00039: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9184 - val_loss: 0.0405 - val_accuracy: 0.4887\n",
      "Epoch 40/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9191\n",
      "Epoch 00040: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0058 - accuracy: 0.9191 - val_loss: 0.0374 - val_accuracy: 0.5192\n",
      "Epoch 41/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9219\n",
      "Epoch 00041: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0056 - accuracy: 0.9219 - val_loss: 0.0430 - val_accuracy: 0.4812\n",
      "Epoch 42/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9227\n",
      "Epoch 00042: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0056 - accuracy: 0.9227 - val_loss: 0.0346 - val_accuracy: 0.5570\n",
      "Epoch 43/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9239\n",
      "Epoch 00043: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9239 - val_loss: 0.0363 - val_accuracy: 0.5323\n",
      "Epoch 44/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9257\n",
      "Epoch 00044: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0054 - accuracy: 0.9257 - val_loss: 0.0362 - val_accuracy: 0.5430\n",
      "Epoch 45/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9266\n",
      "Epoch 00045: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0053 - accuracy: 0.9266 - val_loss: 0.0376 - val_accuracy: 0.5260\n",
      "Epoch 46/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9283\n",
      "Epoch 00046: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0052 - accuracy: 0.9283 - val_loss: 0.0342 - val_accuracy: 0.5677\n",
      "Epoch 47/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9295\n",
      "Epoch 00047: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9295 - val_loss: 0.0373 - val_accuracy: 0.5351\n",
      "Epoch 48/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9319\n",
      "Epoch 00048: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0049 - accuracy: 0.9318 - val_loss: 0.0387 - val_accuracy: 0.5101\n",
      "Epoch 49/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9320\n",
      "Epoch 00049: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0049 - accuracy: 0.9320 - val_loss: 0.0361 - val_accuracy: 0.5415\n",
      "Epoch 50/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9339\n",
      "Epoch 00050: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9339 - val_loss: 0.0360 - val_accuracy: 0.5506\n",
      "Epoch 51/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9342\n",
      "Epoch 00051: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0047 - accuracy: 0.9342 - val_loss: 0.0382 - val_accuracy: 0.5265\n",
      "Epoch 52/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9347\n",
      "Epoch 00052: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0047 - accuracy: 0.9347 - val_loss: 0.0387 - val_accuracy: 0.5165\n",
      "Epoch 53/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9361\n",
      "Epoch 00053: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0046 - accuracy: 0.9361 - val_loss: 0.0398 - val_accuracy: 0.5089\n",
      "Epoch 54/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9361\n",
      "Epoch 00054: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0046 - accuracy: 0.9361 - val_loss: 0.0384 - val_accuracy: 0.5313\n",
      "Epoch 55/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9386\n",
      "Epoch 00055: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0044 - accuracy: 0.9386 - val_loss: 0.0374 - val_accuracy: 0.5375\n",
      "Epoch 56/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9388\n",
      "Epoch 00056: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0044 - accuracy: 0.9388 - val_loss: 0.0394 - val_accuracy: 0.5240\n",
      "Epoch 57/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9405\n",
      "Epoch 00057: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0043 - accuracy: 0.9404 - val_loss: 0.0405 - val_accuracy: 0.4991\n",
      "Epoch 58/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9416\n",
      "Epoch 00058: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0042 - accuracy: 0.9415 - val_loss: 0.0366 - val_accuracy: 0.5566\n",
      "Epoch 59/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9413\n",
      "Epoch 00059: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0043 - accuracy: 0.9413 - val_loss: 0.0413 - val_accuracy: 0.5082\n",
      "Epoch 60/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9432\n",
      "Epoch 00060: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0041 - accuracy: 0.9432 - val_loss: 0.0371 - val_accuracy: 0.5436\n",
      "Epoch 61/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9432\n",
      "Epoch 00061: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0041 - accuracy: 0.9432 - val_loss: 0.0386 - val_accuracy: 0.5298\n",
      "Epoch 62/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9432\n",
      "Epoch 00062: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0041 - accuracy: 0.9431 - val_loss: 0.0373 - val_accuracy: 0.5368\n",
      "Epoch 63/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9462\n",
      "Epoch 00063: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0039 - accuracy: 0.9462 - val_loss: 0.0372 - val_accuracy: 0.5394\n",
      "Epoch 64/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9471\n",
      "Epoch 00064: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0039 - accuracy: 0.9470 - val_loss: 0.0403 - val_accuracy: 0.5117\n",
      "Epoch 65/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9458\n",
      "Epoch 00065: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0039 - accuracy: 0.9459 - val_loss: 0.0421 - val_accuracy: 0.5072\n",
      "Epoch 66/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9470\n",
      "Epoch 00066: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0038 - accuracy: 0.9470 - val_loss: 0.0406 - val_accuracy: 0.5010\n",
      "Epoch 67/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9469\n",
      "Epoch 00067: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0038 - accuracy: 0.9469 - val_loss: 0.0435 - val_accuracy: 0.4868\n",
      "Epoch 68/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9474\n",
      "Epoch 00068: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0038 - accuracy: 0.9474 - val_loss: 0.0405 - val_accuracy: 0.5056\n",
      "Epoch 69/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9487\n",
      "Epoch 00069: val_loss did not improve from 0.03132\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0037 - accuracy: 0.9488 - val_loss: 0.0407 - val_accuracy: 0.5115\n",
      "Epoch 00069: early stopping\n",
      "Starting loop with val_idx=6\n",
      "Epoch 1/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.4058\n",
      "Epoch 00001: val_loss improved from inf to 0.03326, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi6\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi6/assets\n",
      "900/900 [==============================] - 22s 23ms/step - loss: 0.0360 - accuracy: 0.4059 - val_loss: 0.0333 - val_accuracy: 0.4568\n",
      "Epoch 2/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.5930\n",
      "Epoch 00002: val_loss improved from 0.03326 to 0.03186, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi6\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi6/assets\n",
      "900/900 [==============================] - 20s 23ms/step - loss: 0.0266 - accuracy: 0.5930 - val_loss: 0.0319 - val_accuracy: 0.5261\n",
      "Epoch 3/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.6667\n",
      "Epoch 00003: val_loss did not improve from 0.03186\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0224 - accuracy: 0.6667 - val_loss: 0.0330 - val_accuracy: 0.4987\n",
      "Epoch 4/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.7073\n",
      "Epoch 00004: val_loss improved from 0.03186 to 0.02944, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi6\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi6/assets\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 0.0200 - accuracy: 0.7073 - val_loss: 0.0294 - val_accuracy: 0.5552\n",
      "Epoch 5/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.7352\n",
      "Epoch 00005: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0182 - accuracy: 0.7352 - val_loss: 0.0323 - val_accuracy: 0.5146\n",
      "Epoch 6/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.7540\n",
      "Epoch 00006: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0170 - accuracy: 0.7539 - val_loss: 0.0316 - val_accuracy: 0.5260\n",
      "Epoch 7/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.7692\n",
      "Epoch 00007: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0159 - accuracy: 0.7692 - val_loss: 0.0320 - val_accuracy: 0.5179\n",
      "Epoch 8/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.7829\n",
      "Epoch 00008: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0151 - accuracy: 0.7829 - val_loss: 0.0313 - val_accuracy: 0.5465\n",
      "Epoch 9/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.7937\n",
      "Epoch 00009: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0143 - accuracy: 0.7937 - val_loss: 0.0311 - val_accuracy: 0.5461\n",
      "Epoch 10/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.8010\n",
      "Epoch 00010: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0138 - accuracy: 0.8010 - val_loss: 0.0351 - val_accuracy: 0.5170\n",
      "Epoch 11/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.8099\n",
      "Epoch 00011: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0133 - accuracy: 0.8100 - val_loss: 0.0324 - val_accuracy: 0.5287\n",
      "Epoch 12/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.8170\n",
      "Epoch 00012: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0128 - accuracy: 0.8170 - val_loss: 0.0329 - val_accuracy: 0.5320\n",
      "Epoch 13/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.8243\n",
      "Epoch 00013: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 21ms/step - loss: 0.0123 - accuracy: 0.8243 - val_loss: 0.0323 - val_accuracy: 0.5408\n",
      "Epoch 14/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.8297\n",
      "Epoch 00014: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0119 - accuracy: 0.8297 - val_loss: 0.0320 - val_accuracy: 0.5446\n",
      "Epoch 15/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.8354\n",
      "Epoch 00015: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0115 - accuracy: 0.8354 - val_loss: 0.0316 - val_accuracy: 0.5584\n",
      "Epoch 16/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.8402\n",
      "Epoch 00016: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0113 - accuracy: 0.8401 - val_loss: 0.0333 - val_accuracy: 0.5237\n",
      "Epoch 17/100\n",
      "899/900 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.8455\n",
      "Epoch 00017: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 21ms/step - loss: 0.0109 - accuracy: 0.8455 - val_loss: 0.0304 - val_accuracy: 0.5828\n",
      "Epoch 18/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.8520\n",
      "Epoch 00018: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0105 - accuracy: 0.8519 - val_loss: 0.0317 - val_accuracy: 0.5631\n",
      "Epoch 19/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.8546\n",
      "Epoch 00019: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0102 - accuracy: 0.8545 - val_loss: 0.0345 - val_accuracy: 0.5322\n",
      "Epoch 20/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.8593\n",
      "Epoch 00020: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0100 - accuracy: 0.8592 - val_loss: 0.0329 - val_accuracy: 0.5555\n",
      "Epoch 21/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.8638\n",
      "Epoch 00021: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0096 - accuracy: 0.8638 - val_loss: 0.0351 - val_accuracy: 0.5367\n",
      "Epoch 22/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.8682\n",
      "Epoch 00022: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0094 - accuracy: 0.8682 - val_loss: 0.0334 - val_accuracy: 0.5445\n",
      "Epoch 23/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.8712\n",
      "Epoch 00023: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0091 - accuracy: 0.8712 - val_loss: 0.0306 - val_accuracy: 0.5847\n",
      "Epoch 24/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.8750\n",
      "Epoch 00024: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0089 - accuracy: 0.8748 - val_loss: 0.0330 - val_accuracy: 0.5512\n",
      "Epoch 25/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.8787\n",
      "Epoch 00025: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0086 - accuracy: 0.8788 - val_loss: 0.0369 - val_accuracy: 0.5038\n",
      "Epoch 26/100\n",
      "899/900 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.8814\n",
      "Epoch 00026: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 21ms/step - loss: 0.0084 - accuracy: 0.8814 - val_loss: 0.0334 - val_accuracy: 0.5508\n",
      "Epoch 27/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.8848\n",
      "Epoch 00027: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0082 - accuracy: 0.8848 - val_loss: 0.0324 - val_accuracy: 0.5639\n",
      "Epoch 28/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.8872\n",
      "Epoch 00028: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0080 - accuracy: 0.8872 - val_loss: 0.0315 - val_accuracy: 0.5815\n",
      "Epoch 29/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.8912\n",
      "Epoch 00029: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0078 - accuracy: 0.8912 - val_loss: 0.0331 - val_accuracy: 0.5617\n",
      "Epoch 30/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.8920\n",
      "Epoch 00030: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0077 - accuracy: 0.8919 - val_loss: 0.0324 - val_accuracy: 0.5735\n",
      "Epoch 31/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.8962\n",
      "Epoch 00031: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0074 - accuracy: 0.8961 - val_loss: 0.0337 - val_accuracy: 0.5546\n",
      "Epoch 32/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.8999\n",
      "Epoch 00032: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0072 - accuracy: 0.8998 - val_loss: 0.0346 - val_accuracy: 0.5525\n",
      "Epoch 33/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.8988\n",
      "Epoch 00033: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0072 - accuracy: 0.8988 - val_loss: 0.0344 - val_accuracy: 0.5455\n",
      "Epoch 34/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9023\n",
      "Epoch 00034: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0070 - accuracy: 0.9023 - val_loss: 0.0341 - val_accuracy: 0.5671\n",
      "Epoch 35/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9054\n",
      "Epoch 00035: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0068 - accuracy: 0.9053 - val_loss: 0.0336 - val_accuracy: 0.5635\n",
      "Epoch 36/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9068\n",
      "Epoch 00036: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0067 - accuracy: 0.9067 - val_loss: 0.0375 - val_accuracy: 0.5209\n",
      "Epoch 37/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9088\n",
      "Epoch 00037: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0066 - accuracy: 0.9088 - val_loss: 0.0326 - val_accuracy: 0.5877\n",
      "Epoch 38/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9096\n",
      "Epoch 00038: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 21ms/step - loss: 0.0065 - accuracy: 0.9095 - val_loss: 0.0372 - val_accuracy: 0.5226\n",
      "Epoch 39/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9097\n",
      "Epoch 00039: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0065 - accuracy: 0.9096 - val_loss: 0.0319 - val_accuracy: 0.5916\n",
      "Epoch 40/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9138\n",
      "Epoch 00040: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0062 - accuracy: 0.9137 - val_loss: 0.0363 - val_accuracy: 0.5416\n",
      "Epoch 41/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9137\n",
      "Epoch 00041: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0062 - accuracy: 0.9137 - val_loss: 0.0367 - val_accuracy: 0.5308\n",
      "Epoch 42/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9160\n",
      "Epoch 00042: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0060 - accuracy: 0.9160 - val_loss: 0.0355 - val_accuracy: 0.5544\n",
      "Epoch 43/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9186\n",
      "Epoch 00043: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9185 - val_loss: 0.0348 - val_accuracy: 0.5597\n",
      "Epoch 44/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9201\n",
      "Epoch 00044: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0058 - accuracy: 0.9200 - val_loss: 0.0367 - val_accuracy: 0.5404\n",
      "Epoch 45/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9204\n",
      "Epoch 00045: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0057 - accuracy: 0.9203 - val_loss: 0.0337 - val_accuracy: 0.5734\n",
      "Epoch 46/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9200\n",
      "Epoch 00046: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 21ms/step - loss: 0.0058 - accuracy: 0.9199 - val_loss: 0.0360 - val_accuracy: 0.5509\n",
      "Epoch 47/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9230\n",
      "Epoch 00047: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9230 - val_loss: 0.0335 - val_accuracy: 0.5793\n",
      "Epoch 48/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9240\n",
      "Epoch 00048: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9240 - val_loss: 0.0316 - val_accuracy: 0.6014\n",
      "Epoch 49/100\n",
      "899/900 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9263\n",
      "Epoch 00049: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0053 - accuracy: 0.9262 - val_loss: 0.0380 - val_accuracy: 0.5143\n",
      "Epoch 50/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9273\n",
      "Epoch 00050: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0052 - accuracy: 0.9273 - val_loss: 0.0343 - val_accuracy: 0.5740\n",
      "Epoch 51/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9287\n",
      "Epoch 00051: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0052 - accuracy: 0.9287 - val_loss: 0.0391 - val_accuracy: 0.5148\n",
      "Epoch 52/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9303\n",
      "Epoch 00052: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9303 - val_loss: 0.0364 - val_accuracy: 0.5349\n",
      "Epoch 53/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9301\n",
      "Epoch 00053: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 0.0050 - accuracy: 0.9301 - val_loss: 0.0396 - val_accuracy: 0.5161\n",
      "Epoch 54/100\n",
      "898/900 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9312\n",
      "Epoch 00054: val_loss did not improve from 0.02944\n",
      "900/900 [==============================] - 18s 21ms/step - loss: 0.0050 - accuracy: 0.9312 - val_loss: 0.0359 - val_accuracy: 0.5456\n",
      "Epoch 00054: early stopping\n",
      "Starting loop with val_idx=7\n",
      "Epoch 1/100\n",
      "906/906 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.4378\n",
      "Epoch 00001: val_loss improved from inf to 0.03656, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi7\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi7/assets\n",
      "906/906 [==============================] - 22s 23ms/step - loss: 0.0344 - accuracy: 0.4378 - val_loss: 0.0366 - val_accuracy: 0.4580\n",
      "Epoch 2/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.6040\n",
      "Epoch 00002: val_loss did not improve from 0.03656\n",
      "906/906 [==============================] - 18s 20ms/step - loss: 0.0260 - accuracy: 0.6041 - val_loss: 0.0382 - val_accuracy: 0.4461\n",
      "Epoch 3/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.6703\n",
      "Epoch 00003: val_loss improved from 0.03656 to 0.03570, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi7\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi7/assets\n",
      "906/906 [==============================] - 20s 23ms/step - loss: 0.0221 - accuracy: 0.6703 - val_loss: 0.0357 - val_accuracy: 0.4953\n",
      "Epoch 4/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.7128\n",
      "Epoch 00004: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 18s 20ms/step - loss: 0.0196 - accuracy: 0.7128 - val_loss: 0.0383 - val_accuracy: 0.4668\n",
      "Epoch 5/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.7403\n",
      "Epoch 00005: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 18s 20ms/step - loss: 0.0179 - accuracy: 0.7403 - val_loss: 0.0370 - val_accuracy: 0.4752\n",
      "Epoch 6/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.7587\n",
      "Epoch 00006: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0167 - accuracy: 0.7587 - val_loss: 0.0384 - val_accuracy: 0.4800\n",
      "Epoch 7/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.7756\n",
      "Epoch 00007: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0156 - accuracy: 0.7756 - val_loss: 0.0400 - val_accuracy: 0.4523\n",
      "Epoch 8/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.7869\n",
      "Epoch 00008: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0148 - accuracy: 0.7869 - val_loss: 0.0425 - val_accuracy: 0.4197\n",
      "Epoch 9/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.7970\n",
      "Epoch 00009: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0142 - accuracy: 0.7971 - val_loss: 0.0391 - val_accuracy: 0.4924\n",
      "Epoch 10/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.8071\n",
      "Epoch 00010: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0135 - accuracy: 0.8071 - val_loss: 0.0390 - val_accuracy: 0.4722\n",
      "Epoch 11/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.8158\n",
      "Epoch 00011: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0129 - accuracy: 0.8160 - val_loss: 0.0403 - val_accuracy: 0.4511\n",
      "Epoch 12/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.8246\n",
      "Epoch 00012: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0124 - accuracy: 0.8245 - val_loss: 0.0392 - val_accuracy: 0.4802\n",
      "Epoch 13/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.8302\n",
      "Epoch 00013: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 21ms/step - loss: 0.0120 - accuracy: 0.8302 - val_loss: 0.0393 - val_accuracy: 0.4900\n",
      "Epoch 14/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.8367\n",
      "Epoch 00014: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0115 - accuracy: 0.8367 - val_loss: 0.0385 - val_accuracy: 0.4834\n",
      "Epoch 15/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.8421\n",
      "Epoch 00015: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0111 - accuracy: 0.8422 - val_loss: 0.0431 - val_accuracy: 0.4202\n",
      "Epoch 16/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.8473\n",
      "Epoch 00016: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0108 - accuracy: 0.8472 - val_loss: 0.0405 - val_accuracy: 0.4568\n",
      "Epoch 17/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.8526\n",
      "Epoch 00017: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0104 - accuracy: 0.8526 - val_loss: 0.0413 - val_accuracy: 0.4589\n",
      "Epoch 18/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.8566\n",
      "Epoch 00018: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0101 - accuracy: 0.8565 - val_loss: 0.0423 - val_accuracy: 0.4647\n",
      "Epoch 19/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.8622\n",
      "Epoch 00019: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0098 - accuracy: 0.8622 - val_loss: 0.0390 - val_accuracy: 0.5051\n",
      "Epoch 20/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.8667\n",
      "Epoch 00020: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0094 - accuracy: 0.8667 - val_loss: 0.0407 - val_accuracy: 0.4755\n",
      "Epoch 21/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.8708\n",
      "Epoch 00021: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0092 - accuracy: 0.8707 - val_loss: 0.0391 - val_accuracy: 0.4836\n",
      "Epoch 22/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.8762\n",
      "Epoch 00022: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0089 - accuracy: 0.8761 - val_loss: 0.0397 - val_accuracy: 0.4930\n",
      "Epoch 23/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.8781\n",
      "Epoch 00023: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0087 - accuracy: 0.8781 - val_loss: 0.0394 - val_accuracy: 0.4796\n",
      "Epoch 24/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.8804\n",
      "Epoch 00024: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0085 - accuracy: 0.8804 - val_loss: 0.0397 - val_accuracy: 0.5046\n",
      "Epoch 25/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.8851\n",
      "Epoch 00025: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0082 - accuracy: 0.8850 - val_loss: 0.0374 - val_accuracy: 0.5249\n",
      "Epoch 26/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.8878\n",
      "Epoch 00026: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0080 - accuracy: 0.8878 - val_loss: 0.0386 - val_accuracy: 0.5147\n",
      "Epoch 27/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.8910\n",
      "Epoch 00027: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0078 - accuracy: 0.8910 - val_loss: 0.0433 - val_accuracy: 0.4642\n",
      "Epoch 28/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8936\n",
      "Epoch 00028: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0076 - accuracy: 0.8936 - val_loss: 0.0410 - val_accuracy: 0.4977\n",
      "Epoch 29/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.8973\n",
      "Epoch 00029: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0074 - accuracy: 0.8973 - val_loss: 0.0416 - val_accuracy: 0.4830\n",
      "Epoch 30/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.8988\n",
      "Epoch 00030: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0073 - accuracy: 0.8988 - val_loss: 0.0410 - val_accuracy: 0.4798\n",
      "Epoch 31/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9007\n",
      "Epoch 00031: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0071 - accuracy: 0.9007 - val_loss: 0.0428 - val_accuracy: 0.4537\n",
      "Epoch 32/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9021\n",
      "Epoch 00032: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0070 - accuracy: 0.9021 - val_loss: 0.0408 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9044\n",
      "Epoch 00033: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 21ms/step - loss: 0.0068 - accuracy: 0.9043 - val_loss: 0.0404 - val_accuracy: 0.4811\n",
      "Epoch 34/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9089\n",
      "Epoch 00034: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0066 - accuracy: 0.9088 - val_loss: 0.0443 - val_accuracy: 0.4492\n",
      "Epoch 35/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9101\n",
      "Epoch 00035: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0065 - accuracy: 0.9101 - val_loss: 0.0387 - val_accuracy: 0.5325\n",
      "Epoch 36/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9116\n",
      "Epoch 00036: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0063 - accuracy: 0.9116 - val_loss: 0.0408 - val_accuracy: 0.4971\n",
      "Epoch 37/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9128\n",
      "Epoch 00037: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0062 - accuracy: 0.9128 - val_loss: 0.0390 - val_accuracy: 0.5116\n",
      "Epoch 38/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9152\n",
      "Epoch 00038: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0061 - accuracy: 0.9152 - val_loss: 0.0392 - val_accuracy: 0.5002\n",
      "Epoch 39/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9166\n",
      "Epoch 00039: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0060 - accuracy: 0.9166 - val_loss: 0.0405 - val_accuracy: 0.5074\n",
      "Epoch 40/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9182\n",
      "Epoch 00040: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0059 - accuracy: 0.9182 - val_loss: 0.0412 - val_accuracy: 0.5019\n",
      "Epoch 41/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9204\n",
      "Epoch 00041: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 18s 20ms/step - loss: 0.0057 - accuracy: 0.9204 - val_loss: 0.0402 - val_accuracy: 0.4942\n",
      "Epoch 42/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9214\n",
      "Epoch 00042: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0057 - accuracy: 0.9213 - val_loss: 0.0392 - val_accuracy: 0.5167\n",
      "Epoch 43/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9230\n",
      "Epoch 00043: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0055 - accuracy: 0.9230 - val_loss: 0.0396 - val_accuracy: 0.5181\n",
      "Epoch 44/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9241\n",
      "Epoch 00044: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0054 - accuracy: 0.9241 - val_loss: 0.0407 - val_accuracy: 0.4948\n",
      "Epoch 45/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9256\n",
      "Epoch 00045: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0053 - accuracy: 0.9255 - val_loss: 0.0389 - val_accuracy: 0.5414\n",
      "Epoch 46/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9277\n",
      "Epoch 00046: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0052 - accuracy: 0.9277 - val_loss: 0.0415 - val_accuracy: 0.5053\n",
      "Epoch 47/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9286\n",
      "Epoch 00047: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0051 - accuracy: 0.9285 - val_loss: 0.0411 - val_accuracy: 0.4990\n",
      "Epoch 48/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9286\n",
      "Epoch 00048: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0051 - accuracy: 0.9286 - val_loss: 0.0409 - val_accuracy: 0.5082\n",
      "Epoch 49/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9308\n",
      "Epoch 00049: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0050 - accuracy: 0.9308 - val_loss: 0.0394 - val_accuracy: 0.5212\n",
      "Epoch 50/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9320\n",
      "Epoch 00050: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0049 - accuracy: 0.9320 - val_loss: 0.0414 - val_accuracy: 0.5103\n",
      "Epoch 51/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9326\n",
      "Epoch 00051: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0048 - accuracy: 0.9326 - val_loss: 0.0402 - val_accuracy: 0.5160\n",
      "Epoch 52/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9339\n",
      "Epoch 00052: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9340 - val_loss: 0.0408 - val_accuracy: 0.4991\n",
      "Epoch 53/100\n",
      "904/906 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9348\n",
      "Epoch 00053: val_loss did not improve from 0.03570\n",
      "906/906 [==============================] - 19s 20ms/step - loss: 0.0047 - accuracy: 0.9348 - val_loss: 0.0399 - val_accuracy: 0.5216\n",
      "Epoch 00053: early stopping\n",
      "Starting loop with val_idx=8\n",
      "Epoch 1/100\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.4042\n",
      "Epoch 00001: val_loss improved from inf to 0.03152, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi8\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi8/assets\n",
      "903/903 [==============================] - 22s 23ms/step - loss: 0.0361 - accuracy: 0.4042 - val_loss: 0.0315 - val_accuracy: 0.5064\n",
      "Epoch 2/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.5907\n",
      "Epoch 00002: val_loss improved from 0.03152 to 0.03095, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi8\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi8/assets\n",
      "903/903 [==============================] - 20s 23ms/step - loss: 0.0268 - accuracy: 0.5908 - val_loss: 0.0309 - val_accuracy: 0.5460\n",
      "Epoch 3/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.6635\n",
      "Epoch 00003: val_loss improved from 0.03095 to 0.03084, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi8\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi8/assets\n",
      "903/903 [==============================] - 20s 22ms/step - loss: 0.0226 - accuracy: 0.6635 - val_loss: 0.0308 - val_accuracy: 0.5298\n",
      "Epoch 4/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.7067\n",
      "Epoch 00004: val_loss improved from 0.03084 to 0.02869, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi8\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi8/assets\n",
      "903/903 [==============================] - 20s 22ms/step - loss: 0.0201 - accuracy: 0.7066 - val_loss: 0.0287 - val_accuracy: 0.5827\n",
      "Epoch 5/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.7349\n",
      "Epoch 00005: val_loss did not improve from 0.02869\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0183 - accuracy: 0.7349 - val_loss: 0.0309 - val_accuracy: 0.5601\n",
      "Epoch 6/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.7556\n",
      "Epoch 00006: val_loss did not improve from 0.02869\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0170 - accuracy: 0.7556 - val_loss: 0.0293 - val_accuracy: 0.5796\n",
      "Epoch 7/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.7689\n",
      "Epoch 00007: val_loss did not improve from 0.02869\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0160 - accuracy: 0.7689 - val_loss: 0.0319 - val_accuracy: 0.5629\n",
      "Epoch 8/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.7823\n",
      "Epoch 00008: val_loss improved from 0.02869 to 0.02744, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi8\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi8/assets\n",
      "903/903 [==============================] - 21s 23ms/step - loss: 0.0151 - accuracy: 0.7822 - val_loss: 0.0274 - val_accuracy: 0.5979\n",
      "Epoch 9/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.7950\n",
      "Epoch 00009: val_loss did not improve from 0.02744\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0144 - accuracy: 0.7949 - val_loss: 0.0317 - val_accuracy: 0.5720\n",
      "Epoch 10/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.8058\n",
      "Epoch 00010: val_loss improved from 0.02744 to 0.02712, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi8\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi8/assets\n",
      "903/903 [==============================] - 20s 22ms/step - loss: 0.0137 - accuracy: 0.8058 - val_loss: 0.0271 - val_accuracy: 0.6194\n",
      "Epoch 11/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.8131\n",
      "Epoch 00011: val_loss did not improve from 0.02712\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0131 - accuracy: 0.8131 - val_loss: 0.0327 - val_accuracy: 0.5719\n",
      "Epoch 12/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.8206\n",
      "Epoch 00012: val_loss did not improve from 0.02712\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0127 - accuracy: 0.8205 - val_loss: 0.0285 - val_accuracy: 0.6025\n",
      "Epoch 13/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.8299\n",
      "Epoch 00013: val_loss improved from 0.02712 to 0.02633, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi8\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi8/assets\n",
      "903/903 [==============================] - 20s 23ms/step - loss: 0.0121 - accuracy: 0.8299 - val_loss: 0.0263 - val_accuracy: 0.6199\n",
      "Epoch 14/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.8341\n",
      "Epoch 00014: val_loss did not improve from 0.02633\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0118 - accuracy: 0.8340 - val_loss: 0.0292 - val_accuracy: 0.6120\n",
      "Epoch 15/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.8396\n",
      "Epoch 00015: val_loss did not improve from 0.02633\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0114 - accuracy: 0.8395 - val_loss: 0.0326 - val_accuracy: 0.5774\n",
      "Epoch 16/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.8446\n",
      "Epoch 00016: val_loss did not improve from 0.02633\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0110 - accuracy: 0.8445 - val_loss: 0.0269 - val_accuracy: 0.6380\n",
      "Epoch 17/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.8494\n",
      "Epoch 00017: val_loss did not improve from 0.02633\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0107 - accuracy: 0.8493 - val_loss: 0.0265 - val_accuracy: 0.6321\n",
      "Epoch 18/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.8545\n",
      "Epoch 00018: val_loss did not improve from 0.02633\n",
      "903/903 [==============================] - 19s 20ms/step - loss: 0.0103 - accuracy: 0.8546 - val_loss: 0.0295 - val_accuracy: 0.6071\n",
      "Epoch 19/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.8591\n",
      "Epoch 00019: val_loss did not improve from 0.02633\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0100 - accuracy: 0.8590 - val_loss: 0.0265 - val_accuracy: 0.6334\n",
      "Epoch 20/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.8614\n",
      "Epoch 00020: val_loss improved from 0.02633 to 0.02493, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi8\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi8/assets\n",
      "903/903 [==============================] - 20s 22ms/step - loss: 0.0098 - accuracy: 0.8613 - val_loss: 0.0249 - val_accuracy: 0.6548\n",
      "Epoch 21/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.8671\n",
      "Epoch 00021: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0095 - accuracy: 0.8671 - val_loss: 0.0289 - val_accuracy: 0.6151\n",
      "Epoch 22/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.8720\n",
      "Epoch 00022: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0092 - accuracy: 0.8720 - val_loss: 0.0296 - val_accuracy: 0.6060\n",
      "Epoch 23/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.8737\n",
      "Epoch 00023: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0090 - accuracy: 0.8737 - val_loss: 0.0273 - val_accuracy: 0.6325\n",
      "Epoch 24/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.8776\n",
      "Epoch 00024: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 19s 20ms/step - loss: 0.0088 - accuracy: 0.8777 - val_loss: 0.0258 - val_accuracy: 0.6514\n",
      "Epoch 25/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.8800\n",
      "Epoch 00025: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0086 - accuracy: 0.8800 - val_loss: 0.0310 - val_accuracy: 0.6119\n",
      "Epoch 26/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.8840\n",
      "Epoch 00026: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0083 - accuracy: 0.8840 - val_loss: 0.0313 - val_accuracy: 0.5876\n",
      "Epoch 27/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.8865\n",
      "Epoch 00027: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0081 - accuracy: 0.8865 - val_loss: 0.0257 - val_accuracy: 0.6715\n",
      "Epoch 28/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.8897\n",
      "Epoch 00028: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0079 - accuracy: 0.8897 - val_loss: 0.0296 - val_accuracy: 0.6073\n",
      "Epoch 29/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.8934\n",
      "Epoch 00029: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0077 - accuracy: 0.8934 - val_loss: 0.0302 - val_accuracy: 0.6183\n",
      "Epoch 30/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8936\n",
      "Epoch 00030: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 19s 20ms/step - loss: 0.0076 - accuracy: 0.8936 - val_loss: 0.0271 - val_accuracy: 0.6408\n",
      "Epoch 31/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.8972\n",
      "Epoch 00031: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0074 - accuracy: 0.8971 - val_loss: 0.0327 - val_accuracy: 0.5747\n",
      "Epoch 32/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.8984\n",
      "Epoch 00032: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0073 - accuracy: 0.8985 - val_loss: 0.0285 - val_accuracy: 0.6319\n",
      "Epoch 33/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9016\n",
      "Epoch 00033: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0071 - accuracy: 0.9016 - val_loss: 0.0313 - val_accuracy: 0.5845\n",
      "Epoch 34/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9037\n",
      "Epoch 00034: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0069 - accuracy: 0.9037 - val_loss: 0.0304 - val_accuracy: 0.6118\n",
      "Epoch 35/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9058\n",
      "Epoch 00035: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0068 - accuracy: 0.9057 - val_loss: 0.0282 - val_accuracy: 0.6380\n",
      "Epoch 36/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9092\n",
      "Epoch 00036: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0066 - accuracy: 0.9092 - val_loss: 0.0299 - val_accuracy: 0.6218\n",
      "Epoch 37/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9092\n",
      "Epoch 00037: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0065 - accuracy: 0.9093 - val_loss: 0.0307 - val_accuracy: 0.6028\n",
      "Epoch 38/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9113\n",
      "Epoch 00038: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0064 - accuracy: 0.9113 - val_loss: 0.0335 - val_accuracy: 0.5796\n",
      "Epoch 39/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9137\n",
      "Epoch 00039: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0063 - accuracy: 0.9137 - val_loss: 0.0280 - val_accuracy: 0.6312\n",
      "Epoch 40/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9145\n",
      "Epoch 00040: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0061 - accuracy: 0.9145 - val_loss: 0.0287 - val_accuracy: 0.6365\n",
      "Epoch 41/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9170\n",
      "Epoch 00041: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0060 - accuracy: 0.9170 - val_loss: 0.0281 - val_accuracy: 0.6330\n",
      "Epoch 42/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9181\n",
      "Epoch 00042: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0059 - accuracy: 0.9181 - val_loss: 0.0328 - val_accuracy: 0.5994\n",
      "Epoch 43/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9195\n",
      "Epoch 00043: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0058 - accuracy: 0.9195 - val_loss: 0.0282 - val_accuracy: 0.6443\n",
      "Epoch 44/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9205\n",
      "Epoch 00044: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 19s 21ms/step - loss: 0.0057 - accuracy: 0.9205 - val_loss: 0.0281 - val_accuracy: 0.6381\n",
      "Epoch 45/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9234\n",
      "Epoch 00045: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0056 - accuracy: 0.9233 - val_loss: 0.0361 - val_accuracy: 0.5589\n",
      "Epoch 46/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9243\n",
      "Epoch 00046: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9243 - val_loss: 0.0296 - val_accuracy: 0.6279\n",
      "Epoch 47/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9247\n",
      "Epoch 00047: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0054 - accuracy: 0.9247 - val_loss: 0.0321 - val_accuracy: 0.5986\n",
      "Epoch 48/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9266\n",
      "Epoch 00048: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0053 - accuracy: 0.9266 - val_loss: 0.0305 - val_accuracy: 0.6168\n",
      "Epoch 49/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9287\n",
      "Epoch 00049: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9287 - val_loss: 0.0301 - val_accuracy: 0.6141\n",
      "Epoch 50/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9291\n",
      "Epoch 00050: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9291 - val_loss: 0.0358 - val_accuracy: 0.5665\n",
      "Epoch 51/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9316\n",
      "Epoch 00051: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0050 - accuracy: 0.9316 - val_loss: 0.0312 - val_accuracy: 0.6112\n",
      "Epoch 52/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9314\n",
      "Epoch 00052: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 19s 21ms/step - loss: 0.0050 - accuracy: 0.9314 - val_loss: 0.0298 - val_accuracy: 0.6191\n",
      "Epoch 53/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9326\n",
      "Epoch 00053: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0049 - accuracy: 0.9325 - val_loss: 0.0317 - val_accuracy: 0.6009\n",
      "Epoch 54/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9343\n",
      "Epoch 00054: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9343 - val_loss: 0.0348 - val_accuracy: 0.5767\n",
      "Epoch 55/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9357\n",
      "Epoch 00055: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0047 - accuracy: 0.9356 - val_loss: 0.0291 - val_accuracy: 0.6384\n",
      "Epoch 56/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9372\n",
      "Epoch 00056: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0046 - accuracy: 0.9371 - val_loss: 0.0322 - val_accuracy: 0.5883\n",
      "Epoch 57/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9374\n",
      "Epoch 00057: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0046 - accuracy: 0.9373 - val_loss: 0.0308 - val_accuracy: 0.6200\n",
      "Epoch 58/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9383\n",
      "Epoch 00058: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0045 - accuracy: 0.9383 - val_loss: 0.0341 - val_accuracy: 0.5828\n",
      "Epoch 59/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9394\n",
      "Epoch 00059: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0044 - accuracy: 0.9395 - val_loss: 0.0339 - val_accuracy: 0.5858\n",
      "Epoch 60/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9403\n",
      "Epoch 00060: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0044 - accuracy: 0.9403 - val_loss: 0.0312 - val_accuracy: 0.6147\n",
      "Epoch 61/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9398\n",
      "Epoch 00061: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0044 - accuracy: 0.9398 - val_loss: 0.0322 - val_accuracy: 0.5957\n",
      "Epoch 62/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9422\n",
      "Epoch 00062: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0042 - accuracy: 0.9422 - val_loss: 0.0315 - val_accuracy: 0.6121\n",
      "Epoch 63/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9424\n",
      "Epoch 00063: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0042 - accuracy: 0.9424 - val_loss: 0.0349 - val_accuracy: 0.5672\n",
      "Epoch 64/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9425\n",
      "Epoch 00064: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0041 - accuracy: 0.9425 - val_loss: 0.0296 - val_accuracy: 0.6335\n",
      "Epoch 65/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9440\n",
      "Epoch 00065: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0041 - accuracy: 0.9440 - val_loss: 0.0343 - val_accuracy: 0.5883\n",
      "Epoch 66/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9450\n",
      "Epoch 00066: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0040 - accuracy: 0.9450 - val_loss: 0.0304 - val_accuracy: 0.6253\n",
      "Epoch 67/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9455\n",
      "Epoch 00067: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0040 - accuracy: 0.9455 - val_loss: 0.0321 - val_accuracy: 0.6029\n",
      "Epoch 68/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9462\n",
      "Epoch 00068: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0039 - accuracy: 0.9462 - val_loss: 0.0358 - val_accuracy: 0.5579\n",
      "Epoch 69/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9472\n",
      "Epoch 00069: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0038 - accuracy: 0.9472 - val_loss: 0.0286 - val_accuracy: 0.6430\n",
      "Epoch 70/100\n",
      "901/903 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9470\n",
      "Epoch 00070: val_loss did not improve from 0.02493\n",
      "903/903 [==============================] - 18s 20ms/step - loss: 0.0039 - accuracy: 0.9470 - val_loss: 0.0364 - val_accuracy: 0.5653\n",
      "Epoch 00070: early stopping\n",
      "Starting loop with val_idx=9\n",
      "Epoch 1/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.4254\n",
      "Epoch 00001: val_loss improved from inf to 0.03244, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi9\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi9/assets\n",
      "901/901 [==============================] - 22s 23ms/step - loss: 0.0351 - accuracy: 0.4254 - val_loss: 0.0324 - val_accuracy: 0.5179\n",
      "Epoch 2/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.6037\n",
      "Epoch 00002: val_loss improved from 0.03244 to 0.02850, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi9\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi9/assets\n",
      "901/901 [==============================] - 20s 23ms/step - loss: 0.0261 - accuracy: 0.6038 - val_loss: 0.0285 - val_accuracy: 0.5541\n",
      "Epoch 3/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.6736\n",
      "Epoch 00003: val_loss did not improve from 0.02850\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0220 - accuracy: 0.6737 - val_loss: 0.0315 - val_accuracy: 0.5352\n",
      "Epoch 4/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.7143\n",
      "Epoch 00004: val_loss improved from 0.02850 to 0.02657, saving model to data/saved_models/model.Sr16000Cs16000Ol75Vi9\n",
      "INFO:tensorflow:Assets written to: data/saved_models/model.Sr16000Cs16000Ol75Vi9/assets\n",
      "901/901 [==============================] - 20s 22ms/step - loss: 0.0195 - accuracy: 0.7142 - val_loss: 0.0266 - val_accuracy: 0.6015\n",
      "Epoch 5/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.7394\n",
      "Epoch 00005: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0178 - accuracy: 0.7394 - val_loss: 0.0268 - val_accuracy: 0.5925\n",
      "Epoch 6/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.7584\n",
      "Epoch 00006: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0166 - accuracy: 0.7584 - val_loss: 0.0270 - val_accuracy: 0.6028\n",
      "Epoch 7/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.7759\n",
      "Epoch 00007: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0155 - accuracy: 0.7759 - val_loss: 0.0270 - val_accuracy: 0.6066\n",
      "Epoch 8/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.7879\n",
      "Epoch 00008: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0146 - accuracy: 0.7880 - val_loss: 0.0292 - val_accuracy: 0.5818\n",
      "Epoch 9/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.8005\n",
      "Epoch 00009: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0139 - accuracy: 0.8003 - val_loss: 0.0269 - val_accuracy: 0.5993\n",
      "Epoch 10/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.8121\n",
      "Epoch 00010: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0132 - accuracy: 0.8121 - val_loss: 0.0318 - val_accuracy: 0.5336\n",
      "Epoch 11/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.8190\n",
      "Epoch 00011: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0127 - accuracy: 0.8190 - val_loss: 0.0313 - val_accuracy: 0.5463\n",
      "Epoch 12/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.8268\n",
      "Epoch 00012: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0122 - accuracy: 0.8268 - val_loss: 0.0283 - val_accuracy: 0.5912\n",
      "Epoch 13/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.8341\n",
      "Epoch 00013: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0117 - accuracy: 0.8342 - val_loss: 0.0302 - val_accuracy: 0.5650\n",
      "Epoch 14/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.8404\n",
      "Epoch 00014: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0113 - accuracy: 0.8404 - val_loss: 0.0308 - val_accuracy: 0.5645\n",
      "Epoch 15/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.8471\n",
      "Epoch 00015: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0108 - accuracy: 0.8472 - val_loss: 0.0289 - val_accuracy: 0.5795\n",
      "Epoch 16/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.8513\n",
      "Epoch 00016: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0105 - accuracy: 0.8512 - val_loss: 0.0288 - val_accuracy: 0.5850\n",
      "Epoch 17/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.8566\n",
      "Epoch 00017: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0102 - accuracy: 0.8567 - val_loss: 0.0351 - val_accuracy: 0.5373\n",
      "Epoch 18/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.8608\n",
      "Epoch 00018: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0099 - accuracy: 0.8607 - val_loss: 0.0300 - val_accuracy: 0.5758\n",
      "Epoch 19/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.8649\n",
      "Epoch 00019: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0096 - accuracy: 0.8649 - val_loss: 0.0324 - val_accuracy: 0.5511\n",
      "Epoch 20/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.8712\n",
      "Epoch 00020: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0092 - accuracy: 0.8712 - val_loss: 0.0307 - val_accuracy: 0.5731\n",
      "Epoch 21/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.8739\n",
      "Epoch 00021: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0090 - accuracy: 0.8739 - val_loss: 0.0300 - val_accuracy: 0.5832\n",
      "Epoch 22/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.8770\n",
      "Epoch 00022: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 19s 21ms/step - loss: 0.0088 - accuracy: 0.8769 - val_loss: 0.0312 - val_accuracy: 0.5738\n",
      "Epoch 23/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.8800\n",
      "Epoch 00023: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0086 - accuracy: 0.8799 - val_loss: 0.0311 - val_accuracy: 0.5682\n",
      "Epoch 24/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.8849\n",
      "Epoch 00024: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0083 - accuracy: 0.8849 - val_loss: 0.0332 - val_accuracy: 0.5573\n",
      "Epoch 25/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.8864\n",
      "Epoch 00025: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0081 - accuracy: 0.8864 - val_loss: 0.0313 - val_accuracy: 0.5855\n",
      "Epoch 26/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.8895\n",
      "Epoch 00026: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0079 - accuracy: 0.8895 - val_loss: 0.0339 - val_accuracy: 0.5364\n",
      "Epoch 27/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.8940\n",
      "Epoch 00027: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0076 - accuracy: 0.8940 - val_loss: 0.0315 - val_accuracy: 0.5756\n",
      "Epoch 28/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.8945\n",
      "Epoch 00028: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0076 - accuracy: 0.8945 - val_loss: 0.0306 - val_accuracy: 0.5937\n",
      "Epoch 29/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.8983\n",
      "Epoch 00029: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0074 - accuracy: 0.8983 - val_loss: 0.0320 - val_accuracy: 0.5679\n",
      "Epoch 30/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9006\n",
      "Epoch 00030: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0072 - accuracy: 0.9005 - val_loss: 0.0322 - val_accuracy: 0.5608\n",
      "Epoch 31/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9029\n",
      "Epoch 00031: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0070 - accuracy: 0.9029 - val_loss: 0.0320 - val_accuracy: 0.5801\n",
      "Epoch 32/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9045\n",
      "Epoch 00032: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0069 - accuracy: 0.9046 - val_loss: 0.0348 - val_accuracy: 0.5524\n",
      "Epoch 33/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9071\n",
      "Epoch 00033: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0067 - accuracy: 0.9071 - val_loss: 0.0342 - val_accuracy: 0.5502\n",
      "Epoch 34/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9100\n",
      "Epoch 00034: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0065 - accuracy: 0.9101 - val_loss: 0.0349 - val_accuracy: 0.5420\n",
      "Epoch 35/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9128\n",
      "Epoch 00035: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0063 - accuracy: 0.9128 - val_loss: 0.0382 - val_accuracy: 0.5057\n",
      "Epoch 36/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9140\n",
      "Epoch 00036: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0062 - accuracy: 0.9141 - val_loss: 0.0326 - val_accuracy: 0.5599\n",
      "Epoch 37/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9145\n",
      "Epoch 00037: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0062 - accuracy: 0.9145 - val_loss: 0.0314 - val_accuracy: 0.5932\n",
      "Epoch 38/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9167\n",
      "Epoch 00038: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0060 - accuracy: 0.9167 - val_loss: 0.0376 - val_accuracy: 0.5242\n",
      "Epoch 39/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9193\n",
      "Epoch 00039: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0058 - accuracy: 0.9192 - val_loss: 0.0341 - val_accuracy: 0.5640\n",
      "Epoch 40/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9210\n",
      "Epoch 00040: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0057 - accuracy: 0.9209 - val_loss: 0.0316 - val_accuracy: 0.5909\n",
      "Epoch 41/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9228\n",
      "Epoch 00041: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 19s 21ms/step - loss: 0.0056 - accuracy: 0.9227 - val_loss: 0.0338 - val_accuracy: 0.5681\n",
      "Epoch 42/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9239\n",
      "Epoch 00042: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9238 - val_loss: 0.0301 - val_accuracy: 0.5984\n",
      "Epoch 43/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9250\n",
      "Epoch 00043: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0055 - accuracy: 0.9250 - val_loss: 0.0327 - val_accuracy: 0.5744\n",
      "Epoch 44/100\n",
      "899/901 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9273\n",
      "Epoch 00044: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 19s 21ms/step - loss: 0.0053 - accuracy: 0.9274 - val_loss: 0.0325 - val_accuracy: 0.5689\n",
      "Epoch 45/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9280\n",
      "Epoch 00045: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 21ms/step - loss: 0.0052 - accuracy: 0.9278 - val_loss: 0.0341 - val_accuracy: 0.5712\n",
      "Epoch 46/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9296\n",
      "Epoch 00046: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9296 - val_loss: 0.0334 - val_accuracy: 0.5621\n",
      "Epoch 47/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9299\n",
      "Epoch 00047: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0051 - accuracy: 0.9300 - val_loss: 0.0326 - val_accuracy: 0.5743\n",
      "Epoch 48/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9320\n",
      "Epoch 00048: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0049 - accuracy: 0.9320 - val_loss: 0.0314 - val_accuracy: 0.5913\n",
      "Epoch 49/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9341\n",
      "Epoch 00049: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9341 - val_loss: 0.0355 - val_accuracy: 0.5454\n",
      "Epoch 50/100\n",
      "901/901 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9343\n",
      "Epoch 00050: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0048 - accuracy: 0.9343 - val_loss: 0.0347 - val_accuracy: 0.5616\n",
      "Epoch 51/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9354\n",
      "Epoch 00051: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0047 - accuracy: 0.9354 - val_loss: 0.0387 - val_accuracy: 0.5309\n",
      "Epoch 52/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9366\n",
      "Epoch 00052: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0047 - accuracy: 0.9366 - val_loss: 0.0326 - val_accuracy: 0.5734\n",
      "Epoch 53/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9369\n",
      "Epoch 00053: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0046 - accuracy: 0.9369 - val_loss: 0.0325 - val_accuracy: 0.5750\n",
      "Epoch 54/100\n",
      "898/901 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9386\n",
      "Epoch 00054: val_loss did not improve from 0.02657\n",
      "901/901 [==============================] - 18s 20ms/step - loss: 0.0045 - accuracy: 0.9386 - val_loss: 0.0333 - val_accuracy: 0.5759\n",
      "Epoch 00054: early stopping\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "for val_idx in range(10):\n",
    "    print(f\"Starting loop with val_idx={val_idx}\")\n",
    "    fold_Xs, fold_ys, fold_chunk_lens = read_chunks()\n",
    "    X_test, y_test = fold_Xs[val_idx], fold_ys[val_idx]\n",
    "    X_train = np.concatenate([fold_Xs[i] for i in range(10) if i != val_idx])\n",
    "    y_train = np.concatenate([fold_ys[i] for i in range(10) if i != val_idx])\n",
    "    del fold_Xs, fold_ys\n",
    "    gc.collect()\n",
    "\n",
    "    model = create_model_from_paper(X_train.shape[1:])\n",
    "    cpcallback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        filepath=f\"{MODEL_FILE}Vi{val_idx}\",\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "    callbacks[0] = cpcallback\n",
    "    hist = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        # validation_split=1 / 9,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # load the model with the best weights\n",
    "    # model = load_model(MODEL_FILE)\n",
    "    model = load_model(f\"{MODEL_FILE}Vi{val_idx}\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_agg = sum_rule_agg(y_pred, fold_chunk_lens[val_idx])\n",
    "    y_test_agg = sum_rule_agg(y_test, fold_chunk_lens[val_idx])\n",
    "\n",
    "    acc = accuracy_score(y_test_agg, y_pred_agg)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    cm = confusion_matrix(y_test_agg, y_pred_agg, num_classes=NUM_CLASSES)\n",
    "    confusion_matrices.append(cm)\n",
    "    # del X_test, y_test, X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5cb25",
   "metadata": {
    "id": "20b5cb25",
    "outputId": "3483787a-02fd-4e33-cd92-0e9393c400c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.623642943305187,\n",
       "  0.6048780487804878,\n",
       "  0.45084745762711864,\n",
       "  0.6374207188160677,\n",
       "  0.7081447963800905,\n",
       "  0.6201550387596899,\n",
       "  0.6084788029925187,\n",
       "  0.5212765957446809,\n",
       "  0.6948717948717948,\n",
       "  0.6288916562889165],\n",
       " [<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[19,  0,  6, 10,  0,  2,  0, 26,  0, 37],\n",
       "         [ 0, 15,  0,  1,  0,  0,  0,  0,  1,  0],\n",
       "         [ 4,  0, 74,  9,  4,  0,  0,  0,  5,  4],\n",
       "         [ 1,  1, 11, 64,  0,  6,  0,  0,  0,  3],\n",
       "         [ 5,  0,  2,  0, 75,  0,  0,  2,  1,  7],\n",
       "         [ 5,  0,  1,  0,  8, 44,  0, 13, 23,  2],\n",
       "         [ 2,  0,  0, 12,  9,  0, 10,  0,  0,  0],\n",
       "         [ 3,  0,  0,  0, 35,  0,  0, 79,  2,  0],\n",
       "         [ 1,  6,  5,  2,  1,  0,  0,  0, 71,  0],\n",
       "         [ 8,  0, 11,  0,  4,  2,  0,  3,  6, 66]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[43,  0, 25,  0,  0, 28,  0,  1,  0,  3],\n",
       "         [ 2,  9, 12,  0,  0,  0,  0,  0,  3,  2],\n",
       "         [ 2,  0, 82,  1,  0,  0,  0,  0,  5, 10],\n",
       "         [ 3,  0,  8, 61,  0,  0,  0,  0,  5,  4],\n",
       "         [ 0,  0,  6,  0, 56,  0,  0, 13,  0,  6],\n",
       "         [13,  0, 15,  2,  1, 51,  0,  5,  5,  8],\n",
       "         [ 1,  0,  0,  1,  1,  0,  3,  0, 16,  0],\n",
       "         [12,  0,  0,  0,  0,  2,  0, 37, 56, 10],\n",
       "         [ 1,  0,  5,  1,  1,  0,  0,  0, 76,  7],\n",
       "         [ 4,  0, 12,  2,  0,  2,  0,  0,  2, 78]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[31,  0, 15,  9, 14, 13,  0,  2,  2, 14],\n",
       "         [ 0, 13,  3,  0,  2,  4,  0,  0,  3,  0],\n",
       "         [ 7,  0, 74,  5,  1,  0,  0,  0,  2, 11],\n",
       "         [ 0,  0, 17, 54,  0,  0,  0,  0,  7, 10],\n",
       "         [ 1,  2,  4,  0, 60, 13,  0,  4, 13,  3],\n",
       "         [ 8,  0, 14,  0, 34, 12,  0, 33,  1,  4],\n",
       "         [ 0,  0,  2,  9,  0,  0,  0,  0,  0, 19],\n",
       "         [24,  0,  2,  0, 39,  2,  0, 15,  0, 35],\n",
       "         [ 0,  0,  2,  0,  0,  3,  0,  6, 97, 11],\n",
       "         [ 3,  0, 45,  5,  1,  1,  0,  1,  1, 43]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[ 59,   0,  11,   1,   2,   6,   0,  17,   1,   3],\n",
       "         [  2,   9,   8,   0,   7,   9,   0,   4,   6,   5],\n",
       "         [  4,   0,  59,  14,   3,   0,   0,   2,   4,  14],\n",
       "         [  0,   0,   9,  58,   3,   3,   0,   0,  11,   7],\n",
       "         [  3,   3,   1,   0,  71,   8,   0,   9,   0,   5],\n",
       "         [  4,   0,  32,   2,   0,  56,   0,   1,   7,   5],\n",
       "         [  4,   0,   2,   5,  11,   0,   0,   1,   2,   4],\n",
       "         [ 14,   0,   4,   0,   2,   0,   0,  77,   8,   5],\n",
       "         [  1,   0,   1,   0,   0,   2,   0,   0, 155,   0],\n",
       "         [  6,   0,  14,   2,   1,   4,   0,   1,  13,  59]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[ 67,   0,   0,   2,  31,   0,   0,   0,   0,   0],\n",
       "         [  1,  49,   4,   2,  18,   5,   1,   0,   0,   5],\n",
       "         [  2,   0,  49,  22,  15,   4,   0,   0,   0,   8],\n",
       "         [  3,   3,  10,  58,   2,   3,   3,   1,   0,   2],\n",
       "         [  4,   0,   1,   0,  61,   9,   0,   1,   5,   5],\n",
       "         [ 30,   0,   4,   6,   4,  58,   0,   3,   1,   1],\n",
       "         [  0,   0,   2,   2,   0,   0,  29,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0, 118,   0,   0],\n",
       "         [  3,   1,   6,   1,   0,   1,   0,   0,  57,   0],\n",
       "         [  6,   0,   7,   1,   4,   0,   0,   1,   1,  80]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[44,  0,  4,  2,  7, 38,  1,  0,  1,  3],\n",
       "         [ 1, 12,  1,  0,  0,  0,  0,  1,  0,  1],\n",
       "         [ 3,  0, 62,  3,  1,  4,  0,  0, 11, 16],\n",
       "         [ 3,  1, 13, 54,  3,  3,  0,  0,  1,  7],\n",
       "         [ 3,  1,  0,  3, 70,  0,  8,  1,  3,  8],\n",
       "         [13,  2, 13,  0,  0, 40,  2, 21,  4, 12],\n",
       "         [ 1,  0,  1,  2,  2,  0, 21,  1,  0,  0],\n",
       "         [15,  0,  0,  0,  2,  5,  0, 46,  0,  0],\n",
       "         [ 6,  0,  4,  0,  0,  0,  0,  4, 59,  0],\n",
       "         [ 5,  0, 12,  1,  0,  7,  0,  0,  3, 72]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[90,  0,  3,  0,  0,  5,  0,  2,  0,  0],\n",
       "         [ 0,  7, 10,  0,  1,  0,  0,  0,  0,  2],\n",
       "         [ 8,  0, 62,  5,  4,  9,  0,  0,  1, 11],\n",
       "         [ 1,  0, 11, 69,  0,  1,  0,  0,  4,  4],\n",
       "         [ 1,  3,  3,  0, 46,  5,  0,  6, 12, 23],\n",
       "         [ 9,  2,  8,  0,  0, 70,  0,  8,  4,  5],\n",
       "         [ 2,  0,  3,  9,  3,  0,  1,  0,  0, 20],\n",
       "         [ 1,  0,  0,  0,  7,  0,  0, 31,  0, 37],\n",
       "         [ 1,  0,  9,  0,  0, 12,  0,  9, 42,  0],\n",
       "         [ 5,  0, 10,  1,  7,  0,  0,  0,  7, 70]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[34,  0,  0,  0,  6,  0,  0,  9, 20, 31],\n",
       "         [ 0,  9,  2,  1,  2,  0,  0,  0,  0,  1],\n",
       "         [10,  0, 47, 12,  0, 15,  0,  0,  7,  9],\n",
       "         [ 5,  0, 16, 46,  0,  3,  0,  0,  6,  8],\n",
       "         [ 1,  0,  9,  1, 67,  0,  0,  0, 12,  9],\n",
       "         [58,  0,  9,  0,  5, 11,  0,  1,  0,  1],\n",
       "         [ 0,  0,  7,  1,  0,  1,  3,  0,  1,  1],\n",
       "         [ 0,  0,  0,  0, 45,  7,  0, 23,  0,  0],\n",
       "         [ 0,  0,  1,  0,  0,  4,  0,  0, 75,  0],\n",
       "         [ 8,  0,  3,  0,  2,  1,  0,  1,  8, 77]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[11,  0,  7, 25, 24,  3,  0,  0,  0, 30],\n",
       "         [ 1, 11,  1,  1,  0,  0,  0,  0,  0,  0],\n",
       "         [ 4,  0, 86,  8,  0,  2,  0,  0,  0,  0],\n",
       "         [ 8,  0, 14, 60,  6,  0,  0,  0,  0,  4],\n",
       "         [ 0,  3,  1,  3, 71,  0,  0, 16,  0,  0],\n",
       "         [ 6,  0,  3,  1,  1, 78,  0,  0,  0,  0],\n",
       "         [ 0,  0,  7,  6,  0,  0, 12,  0,  0,  2],\n",
       "         [ 0,  0,  0,  0,  7,  0,  0, 75,  0,  0],\n",
       "         [ 0,  0,  8,  7,  0,  0,  0,  0, 67,  0],\n",
       "         [ 2,  1, 20,  0,  0,  3,  0,  0,  3, 71]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "  array([[60,  0, 21,  0,  0,  0,  0, 12,  4,  3],\n",
       "         [ 0, 20,  0,  1,  0,  2,  0,  0,  1,  2],\n",
       "         [ 0,  3, 71,  4,  0,  4,  0,  0,  9,  9],\n",
       "         [ 0,  0, 14, 51,  3,  4,  0,  1,  3,  7],\n",
       "         [ 0,  1, 23,  0, 47,  0,  0, 17,  3,  5],\n",
       "         [ 5,  0,  5,  0,  0, 74,  0,  5,  1,  3],\n",
       "         [ 0,  0,  4, 21,  0,  0,  1,  0,  1,  0],\n",
       "         [ 0,  0,  7,  0, 16,  1,  0, 71,  0,  0],\n",
       "         [ 0,  6, 33,  0,  3,  0,  0,  0, 41,  0],\n",
       "         [ 2,  1, 17,  0,  9,  0,  0,  0,  2, 69]], dtype=int32)>])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies, confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9141f",
   "metadata": {
    "id": "f3c9141f",
    "outputId": "901096a8-029b-40dd-8ab0-3c71966832f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop with val_idx=0\n",
      "Starting loop with val_idx=1\n",
      "Starting loop with val_idx=2\n",
      "Starting loop with val_idx=3\n",
      "Starting loop with val_idx=4\n",
      "Starting loop with val_idx=5\n",
      "Starting loop with val_idx=6\n",
      "Starting loop with val_idx=7\n",
      "Starting loop with val_idx=8\n",
      "Starting loop with val_idx=9\n"
     ]
    }
   ],
   "source": [
    "# testing 1d model\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "for val_idx in range(10):\n",
    "    print(f\"Starting loop with val_idx={val_idx}\")\n",
    "    X_test, y_test = fold_Xs[val_idx], fold_ys[val_idx]\n",
    "\n",
    "    # load the model with the best weights\n",
    "    model = load_model(f\"{MODEL_FILE}Vi{val_idx}\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_agg = sum_rule_agg(y_pred, fold_chunk_lens[val_idx])\n",
    "    y_test_agg = sum_rule_agg(y_test, fold_chunk_lens[val_idx])\n",
    "\n",
    "    acc = (y_pred_agg == y_test_agg).sum() / len(y_pred_agg)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    cm = confusion_matrix(y_test_agg, y_pred_agg, num_classes=NUM_CLASSES)\n",
    "    confusion_matrices.append(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ec6bd",
   "metadata": {
    "id": "934ec6bd",
    "outputId": "ecd62272-cd9f-43b7-d3fe-a14466f8ea6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.623642943305187,\n",
       " 0.6048780487804878,\n",
       " 0.45084745762711864,\n",
       " 0.6374207188160677,\n",
       " 0.7081447963800905,\n",
       " 0.6201550387596899,\n",
       " 0.6084788029925187,\n",
       " 0.5212765957446809,\n",
       " 0.6948717948717948,\n",
       " 0.6288916562889165]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a7e3f",
   "metadata": {
    "id": "8c5a7e3f",
    "outputId": "75a79f63-7861-436e-915c-fd385a1238c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[458,   0,  92,  49,  84,  95,   1,  69,  28, 124],\n",
       "       [  7, 154,  41,   6,  30,  20,   1,   5,  14,  18],\n",
       "       [ 44,   3, 666,  83,  28,  38,   0,   2,  44,  92],\n",
       "       [ 24,   5, 123, 575,  17,  23,   3,   2,  37,  56],\n",
       "       [ 18,  13,  50,   7, 624,  35,   8,  69,  49,  71],\n",
       "       [151,   4, 104,  11,  53, 494,   2,  90,  46,  41],\n",
       "       [ 10,   0,  28,  68,  26,   1,  80,   2,  20,  46],\n",
       "       [ 70,   0,  13,   0, 153,  17,   0, 572,  66,  87],\n",
       "       [ 13,  13,  74,  11,   5,  22,   0,  19, 740,  18],\n",
       "       [ 49,   2, 151,  12,  28,  20,   0,   7,  46, 685]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrices\n",
    "cm = confusion_matrices[0]\n",
    "for i in range(1, 10):\n",
    "    cm += confusion_matrices[i]\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "532f7bec-dc2b-4bc8-867a-4eabfe7b5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "862db71e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "862db71e",
    "outputId": "17ed831a-a135-4c5c-f03b-deaff86067f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop with val_idx=0\n",
      "Found 10047 images belonging to 10 classes.\n",
      "ensemble=0.7129071170084439, 1d=0.623642943305187, 2d=0.7008443908323281\n",
      "Starting loop with val_idx=1\n",
      "Found 9936 images belonging to 10 classes.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "ensemble=0.7109756097560975, 1d=0.6048780487804878, 2d=0.723170731707317\n",
      "Starting loop with val_idx=2\n",
      "Found 10809 images belonging to 10 classes.\n",
      "ensemble=0.5548022598870056, 1d=0.45084745762711864, 2d=0.5649717514124294\n",
      "Starting loop with val_idx=3\n",
      "Found 11131 images belonging to 10 classes.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "ensemble=0.7547568710359408, 1d=0.6374207188160677, 2d=0.6670190274841438\n",
      "Starting loop with val_idx=4\n",
      "Found 10468 images belonging to 10 classes.\n",
      "ensemble=0.7997737556561086, 1d=0.7081447963800905, 2d=0.7601809954751131\n",
      "Starting loop with val_idx=5\n",
      "Found 9368 images belonging to 10 classes.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "ensemble=0.748062015503876, 1d=0.6201550387596899, 2d=0.7235142118863049\n",
      "Starting loop with val_idx=6\n",
      "Found 9738 images belonging to 10 classes.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "ensemble=0.6945137157107232, 1d=0.6084788029925187, 2d=0.6508728179551122\n",
      "Starting loop with val_idx=7\n",
      "Found 9106 images belonging to 10 classes.\n",
      "ensemble=0.7273936170212766, 1d=0.5212765957446809, 2d=0.7194148936170213\n",
      "Starting loop with val_idx=8\n",
      "Found 9427 images belonging to 10 classes.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "ensemble=0.7474358974358974, 1d=0.6948717948717948, 2d=0.7435897435897436\n",
      "Starting loop with val_idx=9\n",
      "Found 9612 images belonging to 10 classes.\n",
      "ensemble=0.7870485678704857, 1d=0.6288916562889165, 2d=0.7210460772104608\n"
     ]
    }
   ],
   "source": [
    "# testing ensemble model (1d+hand made 2d)\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "predictions = []\n",
    "tests = []\n",
    "for val_idx in range(10):\n",
    "    print(f\"Starting loop with val_idx={val_idx}\")\n",
    "    X_test, y_test, cl = fold_Xs[val_idx], fold_ys[val_idx], fold_chunk_lens[val_idx]\n",
    "\n",
    "    copy_to_train_test_dir(test_fold=val_idx + 1, test_only=True)\n",
    "    val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        # target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        # target_size=(224, 224),\n",
    "        target_size=(72, 72),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    idxarr = np.array(\n",
    "        [\n",
    "            int(fn.split(\"/fold\")[1].split(\".jpg\")[0].split(\"-\")[1])\n",
    "            for fn in validation_generator.filenames\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # load the model with the best weights\n",
    "    model1 = load_model(f\"{MODEL_FILE}Vi{val_idx}\")\n",
    "    model2 = load_model(f\"{MODEL_FILE_2D}Vi{val_idx}\")\n",
    "\n",
    "    y_pred1 = model1.predict(X_test)\n",
    "    y_pred2 = model2.predict(validation_generator)\n",
    "    y_pred2 = reorder_2d_results(y_pred2, idxarr, cl)\n",
    "\n",
    "    predictions.append((y_pred1, y_pred2))\n",
    "    tests.append(y_test)\n",
    "    y_pred = y_pred1 + y_pred2\n",
    "\n",
    "    y_test_gen = to_categorical(validation_generator.classes, num_classes=NUM_CLASSES)\n",
    "    y_test_reorder = reorder_2d_results(y_test_gen, idxarr, cl)\n",
    "\n",
    "    y_pred_agg1 = sum_rule_agg(y_pred1, cl)\n",
    "    y_pred_agg2 = sum_rule_agg(y_pred2, cl)\n",
    "\n",
    "    y_pred_agg = sum_rule_agg(y_pred, cl)\n",
    "    y_test_agg = sum_rule_agg(y_test_reorder, cl)\n",
    "\n",
    "    acc1 = (y_pred_agg1 == y_test_agg).sum() / len(y_pred_agg)\n",
    "    acc2 = (y_pred_agg2 == y_test_agg).sum() / len(y_pred_agg)\n",
    "\n",
    "    acc = (y_pred_agg == y_test_agg).sum() / len(y_pred_agg)\n",
    "\n",
    "    accuracies.append((acc, acc1, acc2))\n",
    "    print(f\"ensemble={acc}, 1d={acc1}, 2d={acc2}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test_agg, y_pred_agg, num_classes=NUM_CLASSES)\n",
    "    confusion_matrices.append(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86bacf23-918d-4045-93bd-0459336ee8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7129071170084439, 0.623642943305187, 0.7008443908323281),\n",
       " (0.7109756097560975, 0.6048780487804878, 0.723170731707317),\n",
       " (0.5548022598870056, 0.45084745762711864, 0.5649717514124294),\n",
       " (0.7547568710359408, 0.6374207188160677, 0.6670190274841438),\n",
       " (0.7997737556561086, 0.7081447963800905, 0.7601809954751131),\n",
       " (0.748062015503876, 0.6201550387596899, 0.7235142118863049),\n",
       " (0.6945137157107232, 0.6084788029925187, 0.6508728179551122),\n",
       " (0.7273936170212766, 0.5212765957446809, 0.7194148936170213),\n",
       " (0.7474358974358974, 0.6948717948717948, 0.7435897435897436),\n",
       " (0.7870485678704857, 0.6288916562889165, 0.7210460772104608)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fMz3x5UY-9R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fMz3x5UY-9R",
    "outputId": "d355d8e0-5252-4b60-9754-698eb5d4bb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0, max_w1=0.4, max_acc=0.7189384800965019\n",
      "fold=1, max_w1=0.30000000000000004, max_acc=0.7317073170731707\n",
      "fold=2, max_w1=0.1, max_acc=0.5683615819209039\n",
      "fold=3, max_w1=0.5, max_acc=0.7547568710359408\n",
      "fold=4, max_w1=0.4, max_acc=0.8031674208144797\n",
      "fold=5, max_w1=0.4, max_acc=0.748062015503876\n",
      "fold=6, max_w1=0.6, max_acc=0.699501246882793\n",
      "fold=7, max_w1=0.4, max_acc=0.7579787234042553\n",
      "fold=8, max_w1=0.4, max_acc=0.7538461538461538\n",
      "fold=9, max_w1=0.5, max_acc=0.7870485678704857\n"
     ]
    }
   ],
   "source": [
    "# finding best value of w1\n",
    "w_acc = {w1: [] for w1 in np.linspace(0.1, 0.9, 9)}\n",
    "for val_idx, ((y_pred1, y_pred2), y_test) in enumerate(zip(predictions, tests)):\n",
    "    max_acc, max_w1 = -1, -1\n",
    "    for w1 in np.linspace(0.1, 0.9, 9):\n",
    "        y_pred = (w1 * y_pred1) + ((1 - w1) * y_pred2)\n",
    "\n",
    "        cl = fold_chunk_lens[val_idx]\n",
    "        y_pred_agg = sum_rule_agg(y_pred, cl)\n",
    "        y_test_agg = sum_rule_agg(y_test, cl)\n",
    "\n",
    "        acc = (y_pred_agg == y_test_agg).sum() / len(y_pred_agg)\n",
    "        w_acc[w1].append(acc)\n",
    "        if acc > max_acc:\n",
    "            max_acc, max_w1 = acc, w1\n",
    "    print(f\"fold={val_idx}, max_w1={max_w1}, max_acc={max_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "QoAN_rrWvUQC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "QoAN_rrWvUQC",
    "outputId": "b5fa84c7-a9da-4e9f-c814-535e3c63d394"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAHwCAYAAABtz0NOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU9fn+8fvJnkBICAkJgbCvYRfEBXEXRGVxrUv9VWur1Wq1tqiodV+LdtHaalvbb921ChhXwF3cQQiBsCciSQh7wpaQ7fP7IwONEGCATE5m5v26rlyXc2Ymc6dVuDk85znmnBMAAACAwxfhdQAAAAAgVFCuAQAAgCZCuQYAAACaCOUaAAAAaCKUawAAAKCJUK4BAACAJkK5BgAAAJoI5RoAAABoIpRrAECTM7NIrzMAgBco1wAQAGZ2uZm90eDxcjP7b4PHq81sSCPve8fMrt3jWK6ZnWP1/mhm68xsi5nlmdmA/Xz+YjPbamYFZnbVHs9PMLP5vu+z0sxO9x1PMbN/m1mJmW02s+m+45eZ2ew9voczs56+f/4/M/ubmb1tZtslnWRmZ5rZPN9nrDazu/Z4/3Fm9rmZlfmev8zMjjSztQ3Lue9nzz3Q/+YA0BJQrgEgMD6WNMrMIswsU1KMpGMkycy6S2otaUEj73tR0kW7HphZtqQukt6SNFrS8ZJ6S0qSdIGkjfv4/HWSzpLURtLlkv5oZkf4vucISc9ImiQp2fc9v/O971lJCZL6S2ov6Y8H8TNfLOl+SYmSZkvaLun/+T7jTElXm9lEX4Yukt6R9LikNElDJM13zn3j+5lGN/i+l/ryAkCLR7kGgABwzhVI2qr60ni8pBmSSsysr6QTJH3qnKtr5K3TJA3xlU9JukTSVOfcTknVqi+ufSWZc26xc27NPj7/LefcSlfvY0kzJY3yPX2FpH8552Y55+qcc8XOuSVm1kHSWEm/cM5tds5V+97rr9edc5/5vmelc+4j51ye7/EC1f/B4QTfay+W9J5z7kXf52x0zs33PfcfST+W6s+kSxoj6YWDyAEAnqFcA0DgfCzpRNWX648lfaT6cnmC7/FenHNbVX+W+kLfoYskPe977gNJf5H0hKR1ZvZ3M2vT2Pcxs7Fm9qWZbTKzMklnSEr1PZ0laWUjb8uStMk5t/ngfszdVu+R4Sgz+9DM1ptZuaRf+JFBkp6TNM7MWqn+7Pyn+/pDBAC0NJRrAAicXeV6lO+fP9YByrXPi5IuMrNjJMVJ+nDXE865x5xzwyRlq348ZNKebzazWEmvSXpEUrpzLlnS25LM95LVkno08rmrJaWYWXIjz21X/bjIrs/IaOQ1bo/HL0jKkZTlnEuS9KQfGeScK5b0haRzVD8S8mxjrwOAlohyDQCB87GkkyTFO+eKJH0q6XRJ7STN28/73lb9nPU9kl7eNT7iu9jvKDOLVn3ZrZTU2GhJjKRYSesl1ZjZWP1whvlpSZeb2Sm+mfCOZtbXd3b4HUl/NbO2ZhZtZsf73pMrqb+ZDTGzOEl3+fHzJ6r+THilb8774gbPPS/pVDO7wMyizKzdHhd4PiPpJkkDJU3147MAoEWgXANAgDjnlknapvpSLefcFkkFkj5zztXu5307VV8oT9UPZ43bSPqHpM2SVqn+wr8pjbx/q6RfSXrF99qLVX8GedfzX8t3kaOkctX/IWDXjPelqp/tXqL6iyJvaPCz3CPpPUnLVX/B4oFcI+keM9sq6Q5fnl0Zvlf9qMpvJG2SNF/S4AbvnebLNM05t8OPzwKAFsGc2/Nv8QAA8J6ZrZR0lXPuPa+zAIC/OHMNAGhxzOxc1c9wf+B1FgA4GFFeBwAAoCEz+0j1F2xeuo91hQDQYjEWAgAAADQRxkIAAACAJkK5BgAAAJpIyMxcp6amuq5du3odAwAAACFu7ty5G5xzaY09FzLlumvXrpozZ47XMQAAABDizGzVvp5jLAQAAABoIpRrAAAAoIlQrgEAAIAmQrkGAAAAmgjlGgAAAGgilGsAAACgiVCuAQAAgCZCuQYAAACaCOUaAAAAaCKUawAAAKCJUK4BAACAJkK5BgAAAJoI5RoAAABoIpRrAAAAoIlQrgEAAIAmEuV1AABoCtPnFWvKjKUqKatQZnK8Jo3po4lDO3odCwAQZijXAILe9HnFmjw1TxXVtZKk4rIKTZ6aJ0kUbABAs6JcAwh6v393ye5ivUtFda1uenWB3l1YqtTEGKW1jlNqYoxSW8cqtXWs0lrHKjUxRgkx/DIIAGg6/K4CIGit21qpZ79YpZLyykafr6qt04r12/Rl4U6V7ahu9DWtYiKVmhjrK9315Ttt9+NYpTUo5K1i+SUTALB//E4BIOjkl2zR07ML9UZuiarr6hQXFaHKmrq9XtcxOV7v3XiCJKmqpk6btldpw7adWr91p9Zv26kN23Zqw9b/HStYv11fF27S5n0U8YSYyB+U8NTEXWfAY5XWusFZ8USKOACEK371BxAU6uqcPlq2Tk/PLtRnKzYqPjpSF47I0uUjuyl3ddkPZq4lKT46UpPG9Nn9OCYqQhlJccpIijvgZ1XX1hfx3SV8605t2FZfwncV8e82btecVZu1eUeVnNv7e8RHR/5gDGVX6U5rUMx3F/GYSJlZk/zvBADwFuUaQItWUVWrqfOK9PTsQhWs366MNnG6+fS+umhElpITYiRJ3VJbSVKTbQuJjoxQeps4pbc5cBGv2VXEfaV7dwnf6ivi23bq+4079O2qzdq0jyIeFx2xRwmP2X1G/H/HY5SWGKvWsVEUcQBowcw19it9EBo+fLibM2eO1zEANJF1Wyr1zBer9PxXq7R5R7UGdGyjn4/qrjMGdlB0ZHCu6K+prdOmHVXasLWqwRnxXV9VvnJe/7Vxe+NFPDYqosFIyt4z4qmtY+qfS4xV4n6KOKsLAeDQmdlc59zwxp7jzDWAFmXXPHVObrFq6pxO7Zeunx3XTSO6pQT9GduoyAi1T4xT+8QDnxGvrXM/mBFvWMI3+MZVijZXaP7qcm3avlN1jRTxmKiI+jPge8yDl5Tt0BsL1qi6tv5NrC4EgKZDuQbguV3z1P/8tFCfr6yfp754RGddPrKbuvpGPsJNZITVz2gnxqpfh/2/trbOafOOPYr4rgs1fcdKyiu1oLhcm7ZXqbaRJl5RXaspM5ZSrgHgMFGuAXimoqpWr31bpH999sN56otHdFZSQrTX8YJGZITtPjPdN2P/r62rc+px69tqbCCwpKwiIPkAIJxQrgE0u13z1M99tUplO6o1sGOS/nzhkKCepw4WERGmzOR4FTdSpJ2kf80u1GXHdlVERHCP4ACAVyjXAJrNopLy3fupa+qcTuuXrp+N6q4ju7YN+nnqYDJpTJ+9VhfGRUWoe1or3fNmvmbml2rKeYOVlZLgYUoACE6UawABVVfn9OHS+v3Un6/cqIQY5qm9tmuues9tIROGZOq/c4p0z5v5Ov1Pn+h3Z2XrR0dm8QcfADgIrOIDEBC756lnF6pgQ/089WUju+qiI5mnbulWb9qhm15doC8KNuqkPml66NxBfu38BoBwsb9VfJRrAE1q7ZZKPfPFd3r+q+93z1P/bFQ35qmDTF2d03+++E4PvbNEcdGRunfiAI0b1IGz2AAg9lwDaAbMU4eWiAjT5SO76fjeafrNK7n61YvzNGNhqe6dOEAprWK8jgcALRblGsAh2zVP/c9PC/VFQf089SVHddFlx3ZlnjpE9EhrrVd/cYye+qRAf3pvmb4q3KSHzhmoU7PTvY4GAC0SYyEADlpFVa1e/bZI//bNU3dIitNlx3bVhcxTh7T8ki268ZX5WlK6VecN66Q7xmWrTRz/fwMIP8xcA2gSe85TD+qUpCuOY546nFTV1Omx95frrx+tUIekeP3+vEEa2TPV61gA0Kwo1wAOy57z1KOz6+eph3dhnjpczft+s37zSq4KNmzXT47polvG9lN8TKTXsQCgWXh2QaOZnS7pz5IiJf3TOffQHs//UdJJvocJkto755LNbIikv0lqI6lW0v3OuZcDmRXAD9XVOX2wpH4/dcN56stHdlWXdsxTh7uhndvqrV+N0u9nLNG/P/tOnyzfoEfOH6xhXdp6HQ0APBWwM9dmFilpmaTTJBVJ+kbSRc65/H28/jpJQ51zPzWz3pKcc265mWVKmiupn3OubF+fx5lroGnsqKrRa98W7z1PPaKzkuKZr8XePl+5QZP+u0Bryit01Qk9dMOpvRQbxVlsAKHLqzPXIyStcM4V+EK8JGmCpEbLtaSLJN0pSc65ZbsOOudKzGydpDRJ+yzXAA5PY/PUf75wCPPUOKBje6Tq3RtG6b43F+tvH63Uh0vW6dELBqt/ZpLX0QCg2QWyXHeUtLrB4yJJRzX2QjPrIqmbpA8aeW6EpBhJKwOQEQh7C4vL9a/ZhXpjAfPUOHSJcdF6+LxBGjMgXTe/lqcJf/lM15/SS1ef2ENR/OEMQBhpKXuuL5T0qnOutuFBM+sg6VlJP3HO1e35JjO7UtKVktS5c+fmyAmEhF3z1P+cXaAvCzYxT40mc3LfdM28oa3uyFmkR2ct03uL1+rRC4aoZ/vWXkcDgGYRyJnrYyTd5Zwb43s8WZKccw828tp5kn7pnPu8wbE2kj6S9IBz7tUDfR4z18CB7Zqn/tfsQhUyT40Ae3NBiX43faF2VNXqptP76vJjuyoigr8NARD8vJq5/kZSLzPrJqlY9WenL24kXF9JbSV90eBYjKRpkp7xp1gD2L+1Wyr1n8/r56nLK6o1uFOSHrtoqMYOyGCeGgFz1qBMjeiWosmv5eneN/M1c1GpHjl/sLJSEryOBgABE7By7ZyrMbNrJc1Q/Sq+fznnFpnZPZLmOOdyfC+9UNJL7oen0C+QdLykdmZ2me/YZc65+YHKC4SiPeepx2Rn6GejumkY89RoJu0T4/TPnwzXf+cW6Z438nX6nz7R7Wdl68Ijs/h3EEBI4iYyQIjZc566VUykzh+exTw1PFe0eYduenWBPl+5USf2SdPD5w5Seps4r2MBwEHjDo1AGNhRVaPX5hbpX599p8IN25WZFKfLRnbVj45knhotR12d07NfrtKD7yxWbFSk7pnQX+MHZ3IWG0BQoVwDIay0/H/7qXfNU18xqjvz1GjRCtZv02/+m6t535fpjIEZum/iQKW0ivE6FgD4xbPbnwMInIXF5Xp6dqHeyC1RnXMazTw1gkj3tNZ69RfH6qlPVuqPs5bp68JNevCcQTotO93raABwWDhzDbRQ0+cVa8qMpSopq1Bmcrwmjemj8YMz9f6SdfrnpwX6qrB+nvqCI7N0+bHd1LkdGxgQnBav2aIbX8nV4jVbdN6wTrpjXLbaxDHKBKDlYiwECDLT5xVr8tQ8VVT/775K0ZGmpPhobdhWxTw1Qk5VTZ0e/2C5/vrRSqUnxmrK+YM1smeq17EAoFGUayDIjHzoAxWXVex1PDrS9IcLhmjsgAxuKY2QNH91mW58Zb4K1m/X/zumi24Z21cJMUwwAmhZ9leu+d0ZaEGcc1pYXN5osZakmlqncYMzKdYIWUOykvX2r0bppyO76ZkvVumMP3+quas2eR0LAPzG6QDAY9W1dfq6cJNmLirVe4vX7bNYS1JmcnwzJgO8ERcdqTvGZeu07HRNejVX5z/5ha48vod+fVovxUZFeh0PAPaLcg14YNvOGn28dL1m5pfqwyXrtKWyRrFRERrVK03Xn9pLVTW1uv+tJT+YuY6PjtSkMX08TA00r2N6tNO7Nxyv+9/K15Mfr9SHS9bp0QsGa0DHJK+jAcA+Ua6BZrJuS6VmLV6rWflr9fmKjaqqrVPbhGiN7p+h07LTNapX6g9mS1vHRu+1LWTi0I4e/gRA82sdG6UHzxmk0dkZuvm1BZr4xGf61Sm9dM2JPRiPAtAicUEjECDOOa1cv00zFtUX6vmryyRJnVMSNDo7Xadlp2tYl7YUBMBPZTuqdMfri5STW6LBnZL06AWD1bN9otexAIQhtoUAzaS2zmne95s1M7++UBdu2C5JGtQpyVeoM9Q7vTU3eQEOw1sL1uj26XnaUVWrSWP66Kcjuykigv+mADQf7tAIBFBlda1mL9+gWflr9d7itdq4vUrRkaaju7fTT0d21anZ6eqQxIWIQFM5c1AHjeiWoslT83TfW4s1M3+tHj1/sLJSuJESAO9x5ho4BJu3V+n9Jes0K79UnyzboIrqWiXGRunEvu11Wna6TuyTxh3mgABzzum1b4t1d84i1Tqn28/M1kUjsvibIQABx5lroAl8v3GHZuaXalb+Wn3z3SbVOSmjTZzOG9ZJp2Wn6+ju7RQTxfw00FzMTOcN66RjerTTTa/m6tZpeZqxqFQPnztIGUlxXscDEKY4cw3sQ/0NXbZoVn6pZuav1ZLSrZKkPumJOi07XaP7p2tgxyTOkgEtQF2d03NfrdIDby9WTGSE7p04QOMHZ/LfJ4CA4IJGwE9VNXX6qnCjZvkuSFxTXqkIk4Z3Tdm94aNLu1ZexwSwD4Ubtus3r8zXt9+XaeyADN03cYDatY71OhaAEEO5BvZja2W1Plq6XrPy1+rDpeu0tbJGcdEROr5Xmk7LTtcp/dKV0irG65gA/FRb5/SPTwv0h5nL1CY+Sg+cPVCj+2d4HQtACKFcA3soLf/fDV2+WLlB1bVOKa1idGq/9jotO0PH9UxVfAy3WQaC2ZLSLbrx5Vzlr9mic4/opDvGZSspnguNARw+yjXCnnNOy9dt06z8tZq5qFS5ReWSpK7tEnzz0xk6onNbRbIrFwgpVTV1+ssHy/XERyvVPjFWU84brON6pXodC0CQo1wjLNXWOc1dtXn3BYmrNu6QJA3OStbo7HSNzk5Xz/bc0AUIB7mry3TjK/O1cv12/b9juuiWsX2VEMPCLACHhnKNsFFRVatPl9fPT3+wZN3uG7oc2yNVp/kuSExvw4ouIBxVVtfqkRlL9fRnheqckqBHzx+s4V1TvI4FIAhRrhHSNm2v0vuL12pm/lp9uny9KqvrlBgXpZN9N3Q5oXeaErmhCwCfLws2atKruSraXKErj++uX5/aW3HRXGMBwH+Ua4ScVRu3++an12rOqvobunRIiqufn87O0IhuKdzQBcA+bdtZo/vfWqwXv/5evdNb6w8XDNGAjklexwIQJCjXCHrOOS0oKt+9f3rp2vobuvTNSKyfn+6fof6ZbZifBnBQPlq6Tje/tkAbt1XpupN76ZqTeig6kj+YA9g/yjWCUlVNnb4o2KhZ+aV6L3+dSrfU39BlRLcUnZadodHZ6cpKSfA6JoAgV76jWnfmLNT0+SUa1ClJj54/WL3SE72OBaAFo1wjaGzx3dBl5qJSfbx0vbburFF8dKSO752q0dkZOrlve7Xlhi4AAuDtvDW6ffpCbdtZo5vG9NFPR3ZTBOs5ATRif+WaPURoNtPnFWvKjKUqKatQZnK8Jo3po4lDO2pNeYXey6+/IPHLgo2qrnVKbR2jMwZ20Oj+6RrZM5WLjQAE3BkDO+jIrim6dVqe7ntrsWbmr9Uj5w1W53b8DRkA/3HmGs1i+rxiTZ6ap4rq2t3HoiJMHZLitHpzhSSpW2or3/x0uoZkcUMXAN5wzmnqt8W6K2eRap3TbWf2U0J0pB6ZuWyvkwMAwhNnruG5KTOW/KBYS1JNnVPplkrddHofjc5OV480bugCwHtmpnOHddIxPdrpplcX6LZpCxVhUp3vXFRxWYUmT82TJAo2gL1wSTQCqmD9Nv3pvWUqLqts9PmaWqdrTuypnu0TKdYAWpTM5Hg9e8UIJcVH7y7Wu1RU12rKjKXeBAPQonHmGk2utLxSby4o0evzS5RXXC4zKSYqQlU1dXu9NjM53oOEAOAfM9OWiupGnyspq2jmNACCAeUaTaJsR5XezitVTm6xvircJOekgR2TdPuZ/XTWoEx9WbBxr5nr+OhITRrTx8PUAHBgmcnxKm6kSHNyAEBjKNc4ZDuqajQrf61y5pfok+XrVV3r1D2tla4/pZfGD85U97TWu1+7ay6xsW0hANCSTRrTZ6+TAybplyf18C4UgBaLco2DUlVTp0+WrVdObolm5a9VRXWtMtrE6fKR3TR+cOZ+75I4cWhHyjSAoLPnyYF2rWO1aftOzcxfqwuP7MwubAA/QLnGAdXWOX1duEk5ucV6O69U5RXVSk6I1tlHdNSEwZk6smsKv7kACGl7nhx47stVun36Qv3pvWW6cTTjbQD+h3KNRjnnlFdcrpz5JXpjQYnWbtmphJhIjc5O1/ghmTquZ5piolg2AyA8XXJUZ+WuLtNjH6zQwE7JOi073etIAFoIyjV+YMW6bcrJLdEbuSUq3LBd0ZGmE3q31+1nZuqUfu2VEMO/MgBgZrp34gAtXbtVN748X69fO/IH15kACF/coREqKavYvTpvUckWmUnHdG+n8YMzNXZAByUlRHsdEQBapOKyCo17fLbatYrRtF+OVOtYTkAA4YA7NGIvm7ZX6e28NcrJLdHXhZskSYM7Jel3Z2XrrEEdlN4mzuOEANDydUyO118uGqofP/2Vbno1V09cfAQ3xALCHOU6jGzbWaNZ+aXKmV+iT5dvUE2dU4+0VrrxtN4aPzhTXVNbeR0RAILOsT1TdcvYvnrg7SV66pMC/eIEVvQB4YxyHeJ21tTq46Xr9Xpuid5fvFaV1XXKTIrTFaPqV+dld9j36jwAgH9+Pqq7covK9ft3l2hAZpKO65XqdSQAHqFch6DaOqevCjbq9fklemfhGm2prFFKqxidN6yTJgzpqGGd27I6DwCakJnp9+cO0vK1W3Xdi98q59rjlJWS4HUsAB6gXIcI55xyi8r1+vxivbVgjdZt3alWMZEa0z9D44dkamTPVEVHsjoPAAKlVWyUnrp0uMb/Zbaufn6uXv3FsYqLjvQ6FoBmRrkOcsvXblVObolycku0auMOxURG6MQ+aZowpKNO7tte8TH8wg4AzaVbaiv96UdDdMV/5ui2aQv1yPmDGL0DwgzlOggVbd6hN3LrN30sXrNFESYd2yNVvzyxp8YMyFBSPKvzAMArp/RL1/Wn9NKf31+uIVlJuvSYrl5HAtCMKNdBYuO2nXo7b41en1+iOas2S5KGdk7WneOydeagDmqfyOo8AGgprj+llxYWl+vuN/LVr0MbDe+a4nUkAM2Em8i0YFsrqzVz0Vrl5JZo9ooNqq1z6tW+tSYO7ahxgzLVuR0XywBAS1VeUa0Jf5mt7VW1euu649Se+wcAIYObyASRyupafbR0vXJyi/X+4nXaWVOnjsnxuvL47ho/OFN9MxKZ3wOAIJAUH62nLh2uiU98pquf/1Yv/vxoxURxYTkQ6ijXLUBNbZ2+KNionPklendhqbburFG7VjH60ZFZmjAkU0d0bkuhBoAg1CcjUVPOH6RrX5in+97K1z0TBngdCUCAUa494pzTvNVlyplfojcXrNGGbTvVOjZKY/pnaMKQTB3bo52iWJ0HAEHvrEGZWlBUrr9/UqBBnZJ13rBOXkcCEECU62a2tHSrcnKLlZNbotWbKhQTFaGT+7TXhCGZOqlve3aiAkAIumlMHy0sLtdt0/LUNyNRAzomeR0JQIBwQWMzWL1ph3JyS/RGbomWlG5VhEkje6Zq/OBMjRmQoTZxrM4DgFC3cdtOjXt8tsxMb1x3nFJaxXgdCcAh2t8FjZTrAFm/ddfqvGJ9+32ZJGlYl7YaPzhTZwzsoLTEWI8TAgCa24KiMp335Bca0TVF/3f5kYz/AUGKbSEBMn1esabMWKqSsgplJsfr2pN7KCoiQjm5JfpsxQbVOalvRqJuOr2Pxg3KVFYKq/MAIJwN6pSs+yYO0E2vLtAjM5fplrF9vY4EoIlRrg/R9HnFmjw1TxXVtZKk4rIKTZ66UJLUqW28rj6xh8YP7qg+GYlexgQAtDAXDM9S7uoyPfnxSg3qlKQzBnbwOhKAJkS5PkRTZizdXawbSmsdq09vOonVeQCAfbpjXLby12zRb/+bq17tW6tXOidigFDBsNchKimraPT4hm07KdYAgP2KjYrU3y4ZpoSYKF357Fxtqaz2OhKAJkK5PkSZyfEHdRwAgIYykuL010uO0OpNO3Tjy7mqqwuNBQNAuKNcH6JJY/oofo+d1PHRkZo0po9HiQAAwWZEtxTdfmY/vbd4rf7y4Qqv4wBoAsxcH6KJQztK0g+2hUwa02f3cQAA/PGTY7sqt6hcf3xvmQZ2TNJJfdt7HQnAYWDPNQAAHquoqtW5f/tcRZt3KOfa49Q1tZXXkQDsx/72XDMWAgCAx+JjIvXUpcMUEWH6xXNztaOqxutIAA4R5RoAgBYgKyVBj104VEvXbtUtr+UpVP5mGQg3lGsAAFqI43un6bej+ygnt0RPzy70Og6AQ0C5BgCgBbnmxB4a0z9dD76zRF+s3Oh1HAAHiXINAEALYmZ65PzB6touQde+8O0+b1oGoGWiXAMA0MIkxkXrqUuHa2dNna5+bq4qq2u9jgTAT5RrAABaoJ7tW+uR8wcrt6hcd+Us8joOAD9RrgEAaKFOH5ChX57UQy99s1ovfv2913EA+IFyDQBAC3bjaX10fO803fn6Is37frPXcQAcAOUaAIAWLDLC9NiFQ5SeFKurn/tW67fu9DoSgP2gXAMA0MIlJ8ToqR8PV1lFlX75wreqrq3zOhKAfQhouTaz081sqZmtMLNbGnn+j2Y23/e1zMzKGjz3EzNb7vv6SSBzAgDQ0mVnttFD5wzS14Wb9ODbS7yOA2AfogL1jc0sUtITkk6TVCTpGzPLcc7l73qNc+7XDV5/naShvn9OkXSnpOGSnKS5vvcybAYACFsTh3ZUblGZ/vVZoQZnJWnCkI5eRwKwh0CeuR4haYVzrsA5VyXpJUkT9vP6iyS96PvnMZJmOec2+Qr1LEmnBzArAABB4dYz+mlEtxTd/NoC5Zds8ToOgD0Eslx3lLS6weMi37G9mFkXSd0kfXCw7wUAIJxER0boiYuPUFJ8tK56bo7KdlR5HQlAAy3lgsYLJb3qnDuoW1CZ2ZVmNsfM5qxfvz5A0QAAaFnSEmP1tx8PU2l5pa5/ab5q65zXkQD4BLJcF0vKavC4k+9YYy7U/9DjKbEAACAASURBVEZC/H6vc+7vzrnhzrnhaWlphxkXAIDgcUTntrp7/AB9vGy9/vTeMq/jAPAJZLn+RlIvM+tmZjGqL9A5e77IzPpKaivpiwaHZ0gabWZtzaytpNG+YwAAwOeiEVn60fAsPf7BCs1YVOp1HAAKYLl2ztVIulb1pXixpFecc4vM7B4zG9/gpRdKesk55xq8d5Oke1Vf0L+RdI/vGAAA8DEz3T2hvwZ3StJvXsnVyvXbvI4EhD1r0GmD2vDhw92cOXO8jgEAQLMrKavQuMdnq22rGE3/5Ui1jg3Ypl0AksxsrnNueGPPtZQLGgEAwCHKTI7X4xcPVeGG7frtK7kKlRNnQDCiXAMAEAKO7ZGqyWP76t1Fpfrbxyu9jgOELco1AAAh4orjumnc4Ew9MmOpPlnGilrAC5RrAABChJnp4XMHqlf7RP3qpXlavWmH15GAsEO5BgAghCTEROmpS4eprs7pqmfnqqLqoO7PBuAwUa4BAAgxXVNb6c8XDtXi0i26bVoeFzgCzYhyDQBACDqpb3vdcEpvTZ1XrGe+WOV1HCBsUK4BAAhR153cU6f2a69738zXN99xLzagOVCuAQAIURERpj/8aIiyUhJ0zfPfau2WSq8jASGPcg0AQAhrExetpy4dpu07a3T1c3NVVVPndSQgpFGuAQAIcb3TEzXlvMH69vsy3fPmIq/jACGNcg0AQBg4c1AHXXVCdz335fd6Zc5qr+MAIYtyDQBAmJg0uo9G9myn26cv1IKiMq/jACGJcg0AQJiIiozQ4xcdobTWsfrFs3O1cdtOryMBIYdyDQBAGElpFaMnfzxMG7ZX6boX56mmlgscgaZEuQYAIMwM7JSk+ycO0OcrN2rKjKVexwFCSpTXAQAAQPM7f3iWFhSV66lPCjSwU5LOGpTpdSQgJHDmGgCAMPW7s7I1rEtb3fTqAi0t3ep1HCAkUK4BAAhTMVER+uslR6hVbJSuenaOyiuqvY4EBD3KNQAAYSy9TZz+eskRKtpcoRtfnq+6Oud1JCCoUa4BAAhzR3ZN0R3jsvX+knV6/IMVXscBghrlGgAA6NKju+icIzrqT+8v0wdL1nodBwhalGsAACAz0wNnD1R2hza6/qX5+m7Ddq8jAUGJcg0AACRJcdGRevLHwxQVYbrq2bnavrPG60hA0KFcAwCA3bJSEvTYRUO1fN1W3fzaAjnHBY7AwaBcAwCAHxjVK02TxvTVmwvW6J+fFnodBwgqlGsAALCXX5zQXWMHZOjBdxbr8xUbvI4DBA3KNQAA2IuZacr5g9UjrbWufXGeissqvI4EBAXKNQAAaFTr2Cg9eekwVdfU6ern5qqyutbrSECLR7kGAAD71COttR69YLAWFJXrjtcXcoEjcACUawAAsF+j+2foupN76pU5RXrh6++9jgO0aJRrAABwQDec2lsn9knTXTmLNHfVZq/jAC0W5RoAABxQZITpzz8aqg5J8brm+blat7XS60hAi0S5BgAAfklKiNZTlw5TeUW1rn1+nqpr67yOBLQ4lGsAAOC3fh3a6OFzB+nr7zbp/rcWex0HaHGivA4AAACCy4QhHbWgqFxPzy7U4KwknT20k9eRgBaDM9cAAOCg3TK2r47qlqLJU/O0qKTc6zhAi0G5BgAABy06MkJPXHKEkuNjdNWzc1W2o8rrSECLQLkGAACHJLV1rJ68dJjWbdmp616cp9o6bjADUK4BAMAhG5KVrHsm9NenyzfoD7OWeh0H8BzlGgAAHJYLR3TWRSOy9MSHK/XuwlKv4wCeolwDAIDDdtf4/hqclazfvDJfK9Zt8zoO4BnKNQAAOGyxUZF68sdHKC46Ulc+O0dbK6u9jgR4gnINAACaRIekeD1xyREqXL9dR973nrrd8pZGPvSBps8r9joa0Gy4iQwAAGgypeWVioo0VdbU3xq9uKxCk6fmSZImDu3oZTSgWXDmGgAANJkpM5aquvaHK/kqqms1ZQabRBAeKNcAAKDJlJRVHNRxINRQrgEAQJPJTI4/qONAqKFcAwCAJjNpTB/FR0fudfzykV2bPwzgAco1AABoMhOHdtSD5wxUx+R4maSMNnGKjTR9vGy9nOP26Ah9bAsBAABNauLQjj/YDPKfz7/TnTmLlJNboglD2BiC0MaZawAAEFA/PrqLBmcl694381W+g5vLILRRrgEAQEBFRpgeOHuANu+o1kPvLvY6DhBQlGsAABBw/TOTdMVx3fTi16v1zXebvI4DBAzlGgAANIsbTu2ljsnxunVqnqp8d3AEQg3lGgAANIuEmCjdO7G/lq/bpn98WuB1HCAgKNcAAKDZnNw3XWcO7KDH3l+u7zZs9zoO0OQo1wAAoFndMS5bMZERun36QnZfI+RQrgEAQLNKbxOnm07vo9krNuj1+SVexwGaFOUaAAA0u4uP6qIhvt3XZTuqvI4DNBnKNQAAaHaREaYHzxmosopqPfTOEq/jAE2Gcg0AADzRr0Mb/WxUN730zWp9Xcjua4QGyjUAAPDM9af0Uqe28bp1Wp521tR6HQc4bJRrAADgmfrd1wO0Yt02/f1jdl8j+FGuAQCAp07q015nDuqgxz9coUJ2XyPIUa4BAIDn7jwrW7FREbp9eh67rxHUKNcAAMBz7dvE6ebT++qzFRs1bV6x13GAQ0a5BgAALcLFIzpraOdk3ffWYm3ezu5rBCe/yrWZTTWzM82MMg4AAAIiwrf7ektFtR58Z7HXcYBD4m9Z/qukiyUtN7OHzKxPADMBAIAw1TejjX42qrtemVOkLws2eh0HOGh+lWvn3HvOuUskHSHpO0nvmdnnZna5mUUHMiAAAAgv15/SS1kp8bqN3dcIQn6PeZhZO0mXSfqZpHmS/qz6sj0rIMkAAEBYio+J1L0TBmjl+u168iN2XyO4+DtzPU3Sp5ISJI1zzo13zr3snLtOUutABgQAAOHnxD7tNW5wpp74cIUK1m/zOg7gN3/PXD/mnMt2zj3onFvT8Ann3PB9vcnMTjezpWa2wsxu2cdrLjCzfDNbZGYvNDj+e9+xxWb2mJmZn1kBAEAI+N1Z/RQbHaHbpi1k9zWChr/lOtvMknc9MLO2ZnbN/t5gZpGSnpA0VlK2pIvMLHuP1/SSNFnSSOdcf0k3+I4fK2mkpEGSBkg6UtIJfmYFAAAhoH1inG4Z21dfFGzU1G/ZfY3g4G+5/rlzrmzXA+fcZkk/P8B7Rkha4ZwrcM5VSXpJ0oQ9v6+kJ3zfT865dbs+QlKcpBhJsZKiJa31MysAAAgRFx3ZWcO6tNV9b+VrE7uvEQT8LdeRDccyfGelYw7wno6SVjd4XOQ71lBvSb3N7DMz+9LMTpck59wXkj6UtMb3NcM5t9fCSzO70szmmNmc9evX+/mjAACAYBERYXrg7IHaWlmjB95m9zVaPn/L9buSXjazU8zsFEkv+o4drihJvSSdKOkiSf8ws2Qz6ympn6ROqi/kJ5vZqD3f7Jz7u3NuuHNueFpaWhPEAQAALU2fjERdeXx3vTq3SF+sZPc1WjZ/y/XNqj+TfLXv631JNx3gPcWSsho87uQ71lCRpBznXLVzrlDSMtWX7bMlfemc2+ac2ybpHUnH+JkVAACEmOtO7qXOKQnsvkaL5+9NZOqcc39zzp3n+3rKOXegf7O/kdTLzLqZWYykCyXl7PGa6ao/ay0zS1X9mEiBpO8lnWBmUb6b1Jwgib8LAgAgTMXHROq+iQNUsGG7/vbRSq/jAPvk757rXmb2qm9lXsGur/29xzlXI+laSTNUX4xfcc4tMrN7zGy872UzJG00s3zVnxmf5JzbKOlVSSsl5UnKlZTrnHvjkH5CAAAQEo7vnaYJQzL11w9XaiW7r9FCmT97I81stqQ7Jf1R0jhJl0uKcM7dEdh4/hs+fLibM2eO1zEAAEAArd+6U6c8+pGyM9voxZ8fLW6DAS+Y2dx93evF35nreOfc+6ov46ucc3dJOrOpAgIAAPgjLTFWk8/opy8LNunVuUVexwH24m+53mlmEZKWm9m1Zna2uO05AADwwI+GZ2l4l7Z64O3F7L5Gi+Nvub5eUoKkX0kaJunHkn4SqFAAAAD7EhFhevCcgdq2s0b3v8W+A7QsByzXvhvG/Mi3Fq/IOXe5c+5c59yXzZAPAABgL73SE3XV8T302rdF+nzFBq/jALsdsFz7Vu4d1wxZAAAA/HbtyT3VpV2Cbpu+UJXV7L5Gy+DvWMg8M8sxs0vN7JxdXwFNBgAAsB9x0fW7rws3bNdf2X2NFsLfch0naaOkk1W/im+cpLMCFQoAAMAfo3qlaeKQTP3toxVasY7d1/BelD8vcs5dHuggAAAAh+L2s7L14dL1unVanl6+kt3X8JZf5drM/i1pr7vNOOd+2uSJAAAADkJq61jdekZf3fxanv47p0gXHJnldSSEMX/HQt6U9Jbv631JbSTxdy8AAKBFOH9YlkZ0TdH9by/Whm07vY6DMOZXuXbOvdbg63lJF0hq9JaPAAAAzS0iwvTAOQO0o6pGD7D7Gh7y98z1nnpJat+UQQAAAA5Hz/aJuvqEHpo6r1ifsfsaHvGrXJvZVjPbsutL0huSbg5sNAAAgINzzUk91bVdgm6blsfua3jC37GQROdcmwZfvZ1zrwU6HAAAwMGIi47U/WcP1Hcbd+iJD1d4HQdhyN8z12ebWVKDx8lmNjFwsQAAAA7NyJ6pOmdoRz358UotX7vV6zgIM/7OXN/pnCvf9cA5VybpzsBEAgAAODy3ndlPrWKjdOu0PNXV7bVNGAgYf8t1Y6/za0c2AABAc2vXOla3ntFP33y3Wf+du9rrOAgj/pbrOWb2BzPr4fv6g6S5gQwGAABwOM4f1kkjuqXogbeXsPsazcbfcn2dpCpJL0t6SVKlpF8GKhQAAMDhMjM9cPZA7aiq0X1v5nsdB2HCr9EO59x2SbcEOAsAAECT6tm+ta4+sacee3+5zh3WSaN6pXkdCSHO320hs8wsucHjtmY2I3CxAAAAmsY1J/ZQ99RWun36QnZfI+D8HQtJ9W0IkSQ55zaLOzQCAIAgEBcdqfvOHqBVG3foLx+w+xqB5W+5rjOzzrsemFlXSey1AQAAQeHYHqk694hOevLjlVrG7msEkL/l+jZJs83sWTN7TtLHkiYHLhYAAEDTuu3MfkqMi9KtU9l9jcDx9/bn70oaLmmppBcl/UZSRQBzAQAANKmUVjG69Yx+mrNqs16ew+5rBIa/FzT+TNL7qi/Vv5X0rKS7AhcLAACg6Z03rJOO7p6iB99erPVb2X2NpufvWMj1ko6UtMo5d5KkoZLK9v8WAACAlsXMdP/ZA1VZXaf73mL3NZqev+W60jlXKUlmFuucWyKpT+BiAQAABEaPtNa65qQeen1+iT5ett7rOAgx/pbrIt+e6+mSZpnZ65JWBS4WAABA4Fy9e/d1niqq2H2NpuPvBY1nO+fKnHN3SfqdpKclTQxkMAAAgECJjYrU/WcP1OpNFXr8g+Vex0EI8ffM9W7OuY+dcznOuapABAIAAGgOx/Rop/OHddLfPynQ0lJ2X6NpHHS5BgAACBW3ntFPbeKjdes0dl+jaVCuAQBA2GrbKka3ndFPc1dt1ovffO91HIQAyjUAAAhr5xzRUcd0b6eH3lmidVsrvY6DIEe5BgAAYa1+9/UA7ayp071vLvY6DoIc5RoAAIS97mmtde1JPfVGbok+WrrO6zgIYpRrAAAASVed0F090lrpd68vZPc1DhnlGgAAQPW7rx/w7b7+8/vsvsahoVwDAAD4HNW9nS4Y3kn//LRAS0q3eB0HQYhyDQAA0MCtZ/RTUny0Jk9l9zUOHuUaAACggeSEGN1+Vj/N+75ML3zN7mscHMo1AADAHiYO6aiRPdvp4XeXaN0Wdl/Df5RrAACAPZiZ7ps4UDtr6nT3m/lex0EQoVwDAAA0oltqK113Uk+9tWCNPlzC7mv4h3INAACwD1ed0EM927fW7dMXakdVjddxEAQo1wAAAPsQExWhB84eqOIydl/DP5RrAACA/RjRLUUXHpmlf35aqPwSdl9j/yjXAAAAB3DL2L5Kjo/WrdPyVMvua+wH5RoAAOAAkhNi9LuzsjV/dZle+GqV13HQglGuAQAA/DBhSKZG9UrV799dqrXsvsY+UK4BAAD8UL/7eoCqaut09xuLvI6DFopyDQAA4Kcu7VrpV6f00tt5pXp/8Vqv46AFolwDAAAchJ+P6q7e6a11x+uL2H2NvVCuAQAADkLD3dd/eo/d1/ghyjUAAMBBGt41RReN6KynZxdqUUm513HQglCuAQAADsEtp/dV24Ro3TqV3df4H8o1AADAIUhKiNbvzspWblG5nvuS3deoR7kGAAA4ROMH1+++njJjqUrL2X0NyjUAAMAhMzPdP3Ggqtl9DR/KNQAAwGHo3C5B15/aS+8sLNV7+ey+DneUawAAgMP081Hd1Sc9UXfmLNL2ney+DmeUawAAgMMUHRmhB84ZoOKyCv1x1jKv48BDlGsAAIAmMKxLii45qrP+9VmhFhaz+zpcUa4BAACayE2n91VKq1jdOo3d1+GKcg0AANBEkuKjdee4bC0oKtczX3zndRx4gHINAADQhM4a1EEn9E7TIzOWak15hddx0Mwo1wAAAE3IzHTfxAGqdU535bD7OtxQrgEAAJpYVkqCbji1t2YsWquZi0q9joNmRLkGAAAIgCuO66a+GfW7r7ex+zpsUK4BAAACIDoyQvefPVClWyr1h5nsvg4XlGsAAIAAGdalrS45qrP+7/NC5RWx+zocUK4BAAACaNKYvmrXOlaTpy1QTW2d13EQYAEt12Z2upktNbMVZnbLPl5zgZnlm9kiM3uhwfHOZjbTzBb7nu8ayKwAAACBkBQfrbvG9dfC4i165otVXsdBgAWsXJtZpKQnJI2VlC3pIjPL3uM1vSRNljTSOddf0g0Nnn5G0hTnXD9JIyStC1RWAACAQDpjYIZO6pOmR2cuVUkZu69DWSDPXI+QtMI5V+Ccq5L0kqQJe7zm55KecM5tliTn3DpJ8pXwKOfcLN/xbc65HQHMCgAAEDBmpnsm1O++vpPd1yEtkOW6o6TVDR4X+Y411FtSbzP7zMy+NLPTGxwvM7OpZjbPzKb4zoQDAAAEpayUBP361N6alb9WM9h9HbK8vqAxSlIvSSdKukjSP8ws2Xd8lKTfSjpSUndJl+35ZjO70szmmNmc9evXN1dmAACAQ/LT47qpX4c2uvN1dl+HqkCW62JJWQ0ed/Ida6hIUo5zrto5VyhpmerLdpGk+b6RkhpJ0yUdsecHOOf+7pwb7pwbnpaWFpAfAgAAoKlER0bogbMHaO3WSj06c6nXcRAAgSzX30jqZWbdzCxG0oWScvZ4zXTVn7WWmaWqfhykwPfeZDPb1ZhPlpQfwKwAAADNYmjntrr06C76z+ffaUFRmddx0MQCVq59Z5yvlTRD0mJJrzjnFpnZPWY23veyGZI2mlm+pA8lTXLObXTO1ap+JOR9M8uTZJL+EaisAAAAzem3Y/ootXWsJk/NY/d1iDHnnNcZmsTw4cPdnDlzvI4BAADgl7fz1uia57/V7Wf2089Gdfc6Dg6Cmc11zg1v7DmvL2gEAAAIS2MHZOiUvu31h1nLVMzu65AR5XUAAACAcGRmuntCf532h0905TPfqGxHtUrKKpWZHK9JY/po4tA9NxgjGHDmGgAAwCOd2iZodHa6FpVsVXFZpZyk4rIKTZ6ap+nz9lyyhmBAuQYAAPDQN6s27XWsorpWU2awqi8YUa4BAAA8tKasstHjJcxhByXKNQAAgIcyk+MP6jhaNso1AACAhyaN6aP46MgfHIuLjtCkMX08SoTDwbYQAAAAD+3aCjJlxtLdK/lO6JXGtpAgRbkGAADw2MShHXeX6V+/PF9vLijRsrVb1Ts90eNkOFiMhQAAALQgvzsrW4lx0br5tQWqrQuNO2mHE8o1AABAC5LSKkZ3nJWted+X6bkvV3kdBweJcg0AANDCTBiSqRN6p+n37y7h1uhBhnINAADQwpiZ7j97gJyk26flyTnGQ4IF5RoAAKAF6tQ2Qb8d3UcfLl2vNxas8ToO/ES5BgAAaKF+cmxXDc5K1t05i7R5e5XXceAHyjUAAEALFRlhevjcgSqvqNZ9by32Og78QLkGAABowfpmtNHVJ/bQa98W6dPl672OgwOgXAMAALRwvzypp7qntdKt0/K0o6rG6zjYD8o1AABACxcXHamHzhmk1Zsq9MdZy7yOg/2gXAMAAASBEd1SdMlRnfX07EItKCrzOg72gXINAAAQJG4e21dpibG6+bU8VdfWeR0HjaBcAwAABIk2cdG6Z8IALV6zRf/4tMDrOGgE5RoAACCIjOmfobEDMvSn95arcMN2r+NgD5RrAACAIHP3+P6KjYrQLa8tUF0dt0ZvSSjXAAAAQaZ9mzjddkY/fVW4Sa/MWe11HDRAuQYAAAhCPzoyS0d3T9H9by/Wui2VXseBD+UaAAAgCJmZHjxnkHbW1OnOnEVex4EP5RoAACBIdUttpRtO7aV3Fpbq3YWlXseBKNcAAABB7eejuqtfhza64/WFKq+o9jpO2KNcAwAABLHoyAg9fO5Abdi2Uw+/u8TrOGGPcg0AABDkBnVK1hXHddMLX32vrwo2eh0nrFGuAQAAQsCvT+utrJR4TZ6ap8rqWq/jhC3KNQAAQAhIiInSA2cPVMGG7frLByu8jhO2KNcAAAAhYlSvNJ17RCc9+fFKLSnd4nWcsES5BgAACCG3n9lPSfHRuvm1PNVya/RmR7kGAAAIIW1bxejO8f2Vu7pM//n8O6/jhB3KNQAAQIgZN6iDTu7bXo/MXKrVm3Z4HSesUK4BAABCjJnp3okDZJJum75QzjEe0lwo1wAAACGoY3K8bjq9rz5Ztl6vzy/xOk7YoFwDAACEqB8f3UVHdE7W3W8s0sZtO72OExYo1wAAACEqMsL00LmDtG1nje57a7HXccIC5RoAACCE9U5P1DUn9tS0ecX6aOk6r+OEPMo1AABAiLvmpB7q2b61bpu2UNt31ngdJ6RRrgEAAEJcbFSkHj53oErKK/TozGVexwlplGsAAIAwMKxLii49uov+/Xmh5n2/2es4IYtyDQAAECYmjemjjDZxmjw1T1U1dV7HCUmUawAAgDCRGBet+yYO0JLSrfr7Jyu9jhOSKNcAAABh5JR+6TprUAc99v4KrVi3zes4IYdyDQAAEGbuHNdf8TGRunVqnurquDV6U6JcAwAAhJm0xFjdfmY/ff3dJr34zfdexwkplGsAAIAwdN6wThrZs50eenuJSssrvY4TMijXAAAAYcjM9MDZA1VVW6ffvb5QzjEe0hQo1wAAAGGqS7tWuvG03pqVv1bvLiz1Ok5IoFwDAACEsSuO66b+mW10R84ile+o9jpO0KNcAwAAhLGoyAg9fO4gbdpepQffWex1nKBHuQYAAAhzAzom6Wejuumlb1br85UbvI4T1CjXAAAA0A2n9FaXdgm6dWqeKqtrvY4TtCjXAAAAUHxMpB48e6C+27hDf35/uddxghblGgAAAJKkY3um6oLhnfT3Twq0qKTc6zhBiXINAACA3W49o5/aJsToltfyVFNb53WcoEO5BgAAwG7JCTG6e3x/5RWX69+ffed1nP/f3p0HyVnXeRx/f2eSkEDCmXAmkIAkEEgADShrgaiUnJsA8YDCUiy8RWWFLEFRWUDl8FirYF1hl1VcAUUOY6GJilCAFVjDkRMSIARIAhIC4ZDc+e4f0+oQB9INPf17hnm/qlLV/TzP9Hzmm57uT578urvHsVxLkiTpFY4esyOH770D3/ndfB5f/nLpOD2K5VqSJEmvEBGcf9w+9Glr48s3zvaj0RtguZYkSdI/2GmrAZx11F7c+fAzXH/vktJxegzLtSRJkrp08kG7Mm63bbjg5nk889Lq0nF6BMu1JEmSutTWFlw4cQwvr17Peb+aVzpOj2C5liRJ0qt6y/aDOO09b2HKzKX84cE/l45TeZZrSZIkvaZPv2sPRu4wkHNunMNLq9eVjlNplmtJkiS9pn592rhw4liefGEV3542v3ScSrNcS5IkaZPeuus2fPTg4fx4+iLueey50nEqy3ItSZKkupx5xCh23moAk6+fxZp1fjR6VyzXkiRJqsvAzfpwwfH78tDTL/GD2x4pHaeSLNeSJEmq27tHbc+E/Xfm0lsf4qE/v1g6TuV0a7mOiCMjYn5EPBwRk1/lmA9GxLyImBsRV2+0b8uIWBwRl3ZnTkmSJNXva8eOZuBmfZh8w2w2bPCj0TvrtnIdEe3AZcBRwGjgpIgYvdExewJnA+/MzH2A0ze6mfOB27sroyRJkhq33cDN+Oqxo7nnsef46d2PlY5TKd155vog4OHMXJiZa4BrgQkbHfMJ4LLMfA4gM5/+646IeBuwA/DbbswoSZKk1+H4A3bhkD0Hc9HU+SxdsbJ0nMroznK9C/BEp+uLa9s6GwmMjIg/RsRdEXEkQES0Ad8BzuzGfJIkSXqdIoJvHj+G9RuSr940h0yXh0D5FzT2AfYEDgNOAq6IiK2BzwK/zszFr/XFEfHJiJgRETOWLVvW7WElSZL0d8O23Zwz3jeSWx58mptnP1k6TiV0Z7leAgzrdH1obVtni4Epmbk2Mx8FFtBRtg8GTouIRcC3gY9ExIUbf4PMvDwzx2XmuCFDhnTHzyBJkqTX8LF3jmC/oVtx7pS5rHh5Tek4xXVnuf4TsGdEjIiIfsCJwJSNjrmJjrPWRMRgOpaJLMzMkzNz18wcTsfSkKsys8t3G5EkSVI57W3Bt04Yy3Mvr+UbNz9QOk5x3VauM3MdcBowDXgA+Hlmzo2I8yJifO2wacDyiJgH3ApMyszl3ZVJkiRJzTd65y351KG7c909i7nzoWdKxykq3iyLz8eNG5czZswoHUOSJKlXWrV2PUd9/w7WrS23cAAADKZJREFUb0imnX4oA/q1l47UbSLinswc19W+0i9olCRJ0ptA/77tfOuEMTz+7Mv8++8XlI5TjOVakiRJTfGO3bfjpIOGccUdC5mz5PnScYqwXEuSJKlpJh+1N9sN3Ix//cUs1q7fUDpOy1muJUmS1DRbDejL+RP2Yd6TL/Dfdz5aOk7LWa4lSZLUVEfuuxNH7LMD3/vdAhY985fScVrKci1JkqSmO2/CvvRrb+PsG2b3qo9Gt1xLkiSp6XbYsj9nH7030xcu57oZi0vHaRnLtSRJkrrFiQcO46AR23LBzfN4+sVVpeO0hOVakiRJ3aKtLfjWCWNYtW4D/zZlXuk4LWG5liRJUrfZY8hAvvjePbl59pP8du5TpeN0O8u1JEmSutUnD92dvXYcxFd/OYcXVq0tHadbWa4lSZLUrfq2t3HhxLEse3E1F099sHScbmW5liRJUrfbf9jWfOydI/jfux7nT4ueLR2n21iuJUmS1BJnvG8kQ7cZwOTrZ7F63frScbqF5VqSJEktsXm/Pnzj+DE8suwvXHbrI6XjdAvLtSRJklrmXSOHcMIBu/CD2x5m/lMvlo7TdJZrSZIktdQ5x45mUP++nHX9LNZveHN9NLrlWpIkSS217Rb9+Po/j+b+J1bwk+mLSsdpKsu1JEmSWm78fjtz2KghXDxtPktWrCwdp2ks15IkSWq5iOCC4/YF4JwbZ5P55lgeYrmWJElSEUO32ZxJR4zi1vnLmDJzaek4TWG5liRJUjEfOXg4+w/bmn/71Tye/cua0nHeMMu1JEmSimlvCy6aOJYXVq7lgpvnlY7zhlmuJUmSVNSoHQfx2cP24IZ7l3D7gmWl47whlmtJkiQV97n3vIU9hmzBl2+czctr1pWO87pZriVJklTcZn3auXDiWBY/t5Lv/nZB6Tivm+VakiRJlXDg8G05+e27cuUfH2XmEytKx3ldLNeSJEmqjLOO2oshgzbjrOtnsXb9htJxGma5liRJUmVs2b8v50/YlwefepHLb19YOk7DLNeSJEmqlPftsyNHj9mR79/yEAuXvVQ6TkMs15IkSaqcc8fvQ/8+bZx9w2w2bOg5H41uuZYkSVLlbD+oP185Zm/ufvRZfjbjidJx6ma5liRJUiV9cNwwDt59O7756wf48wurSsepi+VakiRJlRQRfPOEMaxZt4Gv/3Ju6Th1sVxLkiSpskYM3oLTDx/J1LlPMXXOk6XjbJLlWpIkSZX28UNGMHqnLfnaL+fy/Mq1peO8Jsu1JEmSKq1vexsXTRzLMy+t5sLfPFg6zmuyXEuSJKnyxgzdio8fsjvX/N/j3LVweek4r6pP6QCSJElSPf7l8JFMnfMUp119L/3a23jy+VXsvPUAJh0xiuMO2KV0PMAz15IkSeohBvRr55gxO/HMS2tY+vwqEliyYiVn3zCbm+5bUjoeYLmWJElSDzJl5tJ/2LZy7XoumTa/QJp/ZLmWJElSj7F0xcqGtrea5VqSJEk9xs5bD2hoe6tZriVJktRjTDpiFAP6tr9i24C+7Uw6YlShRK/ku4VIkiSpx/jru4JcMm0+S1esrNy7hViuJUmS1KMcd8AulSnTG3NZiCRJktQklmtJkiSpSSzXkiRJUpNYriVJkqQmsVxLkiRJTWK5liRJkprEci1JkiQ1ieVakiRJahLLtSRJktQklmtJkiSpSSzXkiRJUpNYriVJkqQmsVxLkiRJTWK5liRJkprEci1JkiQ1SWRm6QxNERHLgMcKffvBwDOFvndP5Lwa47wa47wa47wa47wa47wa58waU2peu2XmkK52vGnKdUkRMSMzx5XO0VM4r8Y4r8Y4r8Y4r8Y4r8Y4r8Y5s8ZUcV4uC5EkSZKaxHItSZIkNYnlujkuLx2gh3FejXFejXFejXFejXFejXFejXNmjancvFxzLUmSJDWJZ64lSZKkJrFcNyAijoyI+RHxcERM7mL/oRFxb0Ssi4j3l8hYJXXM60sRMS8iZkXELRGxW4mcVVHHvD4dEbMj4v6IuDMiRpfIWRWbmlen4yZGREZEpV5N3mp13L9OiYhltfvX/RHx8RI5q6Ke+1dEfLD2GDY3Iq5udcYqqeP+9b1O960FEbGiRM6qqGNeu0bErRFxX+058ugSOauijnntVusRsyLitogYWiLn32Smf+r4A7QDjwC7A/2AmcDojY4ZDowFrgLeXzpzD5jXu4HNa5c/A/ysdO6Kz2vLTpfHA1NL567yvGrHDQJuB+4CxpXOXeV5AacAl5bOWoU/dc5rT+A+YJva9e1L567yvDY6/vPAlaVzV3ledKwj/kzt8mhgUencFZ/XdcBHa5ffA/ykZGbPXNfvIODhzFyYmWuAa4EJnQ/IzEWZOQvYUCJgxdQzr1sz8+Xa1buAsv/SLKueeb3Q6eoWQG9+wcQm51VzPnARsKqV4Sqo3nmpQz3z+gRwWWY+B5CZT7c4Y5U0ev86CbimJcmqqZ55JbBl7fJWwNIW5quaeuY1GvhD7fKtXexvKct1/XYBnuh0fXFtm7rW6LxOBX7TrYmqra55RcTnIuIR4GLgCy3KVkWbnFdEvBUYlpk3tzJYRdX7+zix9t+qv4iIYa2JVkn1zGskMDIi/hgRd0XEkS1LVz11P97Xlv+N4O9FqDeqZ17nAh+OiMXAr+k4299b1TOvmcAJtcvHA4MiYrsWZOuS5VrFRcSHgXHAJaWzVF1mXpaZewBnAeeUzlNVEdEGfBc4o3SWHuRXwPDMHAv8Dvhx4TxV14eOpSGH0XEm9oqI2Lpoop7hROAXmbm+dJCKOwn4UWYOBY4GflJ7XFPXzgTeFRH3Ae8ClgDF7mP+RdVvCdD5TM7Q2jZ1ra55RcThwFeA8Zm5ukXZqqjR+9e1wHHdmqjaNjWvQcC+wG0RsQh4BzClF7+ocZP3r8xc3ul38L+At7UoWxXV8/u4GJiSmWsz81FgAR1luzdq5PHrRHr3khCob16nAj8HyMzpQH9gcEvSVU89j19LM/OEzDyAjk5BZhZ70azlun5/AvaMiBER0Y+OB4gphTNV2SbnFREHAD+ko1j35vWKUN+8Oj9xHwM81MJ8VfOa88rM5zNzcGYOz8zhdKzpH5+ZM8rELa6e+9dOna6OBx5oYb6qqefx/iY6zloTEYPpWCaysJUhK6Su58eI2AvYBpje4nxVU8+8HgfeCxARe9NRrpe1NGV11PP4NbjTmf2zgStbnPEVLNd1ysx1wGnANDqedH6emXMj4ryIGA8QEQfW1kd9APhhRMwtl7iseuZFxzKQgcB1tbdn6rX/WKlzXqfV3vLrfuBLwEcLxS2uznmpps55faF2/5pJx3r+U8qkLa/OeU0DlkfEPDpeQDUpM5eXSVxWA7+PJwLXZu0tHXqrOud1BvCJ2u/jNcApvXVudc7rMGB+RCwAdgC+USRsjZ/QKEmSJDWJZ64lSZKkJrFcS5IkSU1iuZYkSZKaxHItSZIkNYnlWpIkSWoSy7UkVVhEXBkRT0fEnI22/ygiHo2ImRGxICKuioihTf7en46Ij2zimFMi4tJX2fflZuaRpJ7Aci1J1fYj4MhX2TcpM/cDRgH3AX+ofchCU2Tmf2bmVW/gJizXknody7UkVVhm3g48u4ljMjO/BzwFHNV5X+3DrW6oXZ4QESsjol9E9I+IhbXte0TE1Ii4JyLuqH2SHhFxbkSc2el2ZtU+8OmSjc6k71z7+oci4uLa8RcCA2rH/7RJ45CkyrNcS9Kbx73AXhttuw/Yv3b5EGAOcCDwduDu2vbLgc9n5tuAM4H/6OK2/wf4VGbuD6zfaN/+wIeAMcCHImJYZk4GVmbm/pl58hv7sSSp5+hTOoAkqWli4w2ZuS4iHomIvYGDgO8ChwLtwB0RMRD4J+C6iL99+WavuNGIrYFBmTm9tulq4NhOh9ySmc/Xjp0H7AY80bSfSpJ6EMu1JL15HADc0sX22+lYLrIW+D0d67jbgUl0/A/mitoZ6ddrdafL6/G5RVIv5rIQSerhosMXgJ2AqV0ccgdwOjA9M5cB29HxIsg5mfkC8GhEfKDTbe3X+YszcwXwYkS8vbbpxDqjrY2Ivo3/RJLUc1muJanCIuIaYDowKiIWR8SpnXZfEhEzgQV0rKN+d2au6eJm7gZ2oOMMNsAsYHZmZu36ycCptduaC0zo4jZOBa6IiPuBLYDn64h/OTDLFzRK6k3i74+tkiR1LSIGZuZLtcuTgZ0y84uFY0lS5bguTpJUj2Mi4mw6njceA04pG0eSqskz15IkSVKTuOZakiRJahLLtSRJktQklmtJkiSpSSzXkiRJUpNYriVJkqQmsVxLkiRJTfL/ExYcQ+RVTkQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# w vs accuracy\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)  # defaults: [6.0, 4.0]\n",
    "plt.plot(list(w_acc.keys()), [np.mean(a) for a in w_acc.values()], marker=\"o\")\n",
    "plt.xlabel(\"1D weight\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"w vs accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "z8ZRXW0UZvdy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8ZRXW0UZvdy",
    "outputId": "019a7a3a-9f37-4dcc-972f-df3a23254b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0, acc=0.7189384800965019\n",
      "fold=1, acc=0.7304878048780488\n",
      "fold=2, acc=0.5661016949152542\n",
      "fold=3, acc=0.7367864693446089\n",
      "fold=4, acc=0.8031674208144797\n",
      "fold=5, acc=0.748062015503876\n",
      "fold=6, acc=0.6571072319201995\n",
      "fold=7, acc=0.7579787234042553\n",
      "fold=8, acc=0.7538461538461538\n",
      "fold=9, acc=0.7820672478206725\n"
     ]
    }
   ],
   "source": [
    "# final ensemble accuracies with chosen w1 value\n",
    "w1 = 0.4\n",
    "fa = []\n",
    "for val_idx, ((y_pred1, y_pred2), y_test) in enumerate(zip(predictions, tests)):\n",
    "    y_pred = (w1 * y_pred1) + ((1 - w1) * y_pred2)\n",
    "\n",
    "    cl = fold_chunk_lens[val_idx]\n",
    "    y_pred_agg = sum_rule_agg(y_pred, cl)\n",
    "    y_test_agg = sum_rule_agg(y_test, cl)\n",
    "\n",
    "    acc = (y_pred_agg == y_test_agg).sum() / len(y_pred_agg)\n",
    "    print(f\"fold={val_idx}, acc={acc}\")\n",
    "    fa.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "K_9hmqPtkdfW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_9hmqPtkdfW",
    "outputId": "bea9120a-f993-49eb-a078-0aa3ff35edc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.725454324254405, 0.06471490083079626)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average accuracy and stddev\n",
    "np.mean(fa), np.std(fa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9da83974-7fea-4802-bfd9-852f8de32711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop with val_idx=0\n",
      "Found 10047 images belonging to 10 classes.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "ensemble=0.7141133896260555, 1d=0.623642943305187, 2d=0.6803377563329313\n",
      "Starting loop with val_idx=1\n",
      "Found 9936 images belonging to 10 classes.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-9.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-11.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.__call__\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.call_and_return_all_conditional_losses\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "ensemble=0.7024390243902439, 1d=0.6048780487804878, 2d=0.7182926829268292\n",
      "Starting loop with val_idx=2\n",
      "Found 10809 images belonging to 10 classes.\n",
      "ensemble=0.6282485875706215, 1d=0.45084745762711864, 2d=0.63954802259887\n",
      "Starting loop with val_idx=3\n",
      "Found 11131 images belonging to 10 classes.\n",
      "ensemble=0.7610993657505285, 1d=0.6374207188160677, 2d=0.6966173361522199\n",
      "Starting loop with val_idx=4\n",
      "Found 10468 images belonging to 10 classes.\n",
      "ensemble=0.8393665158371041, 1d=0.7081447963800905, 2d=0.8042986425339367\n",
      "Starting loop with val_idx=5\n",
      "Found 9368 images belonging to 10 classes.\n",
      "ensemble=0.7558139534883721, 1d=0.6201550387596899, 2d=0.7299741602067183\n",
      "Starting loop with val_idx=6\n",
      "Found 9738 images belonging to 10 classes.\n",
      "ensemble=0.71571072319202, 1d=0.6084788029925187, 2d=0.7182044887780549\n",
      "Starting loop with val_idx=7\n",
      "Found 9106 images belonging to 10 classes.\n",
      "ensemble=0.660904255319149, 1d=0.5212765957446809, 2d=0.7433510638297872\n",
      "Starting loop with val_idx=8\n",
      "Found 9427 images belonging to 10 classes.\n",
      "ensemble=0.7987179487179488, 1d=0.6948717948717948, 2d=0.767948717948718\n",
      "Starting loop with val_idx=9\n",
      "Found 9612 images belonging to 10 classes.\n",
      "ensemble=0.8194271481942715, 1d=0.6288916562889165, 2d=0.8244084682440846\n"
     ]
    }
   ],
   "source": [
    "# testing ensemble model (1d+VGG-fine-tuned 2d)\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "predictions = []\n",
    "tests = []\n",
    "for val_idx in range(10):\n",
    "    print(f\"Starting loop with val_idx={val_idx}\")\n",
    "    X_test, y_test, cl = fold_Xs[val_idx], fold_ys[val_idx], fold_chunk_lens[val_idx]\n",
    "\n",
    "    copy_to_train_test_dir(test_fold=val_idx + 1, test_only=True)\n",
    "    val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        # target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        # target_size=(224, 224),\n",
    "        target_size=(72, 72),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    idxarr = np.array(\n",
    "        [\n",
    "            int(fn.split(\"/fold\")[1].split(\".jpg\")[0].split(\"-\")[1])\n",
    "            for fn in validation_generator.filenames\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # load the model with the best weights\n",
    "    model1 = load_model(f\"{MODEL_FILE}Vi{val_idx}\")\n",
    "    model2 = load_model(f\"{VGG_MODEL_FILE}Vi{val_idx}\")\n",
    "\n",
    "    y_pred1 = model1.predict(X_test)\n",
    "    y_pred2 = model2.predict(validation_generator)\n",
    "    y_pred2 = reorder_2d_results(y_pred2, idxarr, cl)\n",
    "\n",
    "    predictions.append((y_pred1, y_pred2))\n",
    "    tests.append(y_test)\n",
    "    y_pred = y_pred1 + y_pred2\n",
    "\n",
    "    y_test_gen = to_categorical(validation_generator.classes, num_classes=NUM_CLASSES)\n",
    "    y_test_reorder = reorder_2d_results(y_test_gen, idxarr, cl)\n",
    "\n",
    "    y_pred_agg1 = sum_rule_agg(y_pred1, cl)\n",
    "    y_pred_agg2 = sum_rule_agg(y_pred2, cl)\n",
    "\n",
    "    y_pred_agg = sum_rule_agg(y_pred, cl)\n",
    "    y_test_agg = sum_rule_agg(y_test_reorder, cl)\n",
    "\n",
    "    acc1 = (y_pred_agg1 == y_test_agg).sum() / len(y_pred_agg)\n",
    "    acc2 = (y_pred_agg2 == y_test_agg).sum() / len(y_pred_agg)\n",
    "\n",
    "    acc = (y_pred_agg == y_test_agg).sum() / len(y_pred_agg)\n",
    "\n",
    "    accuracies.append((acc, acc1, acc2))\n",
    "    print(f\"ensemble={acc}, 1d={acc1}, 2d={acc2}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test_agg, y_pred_agg, num_classes=NUM_CLASSES)\n",
    "    confusion_matrices.append(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1990a8bb-9296-4a27-9a75-199db6c5b229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7141133896260555, 0.623642943305187, 0.6803377563329313),\n",
       " (0.7024390243902439, 0.6048780487804878, 0.7182926829268292),\n",
       " (0.6282485875706215, 0.45084745762711864, 0.63954802259887),\n",
       " (0.7610993657505285, 0.6374207188160677, 0.6966173361522199),\n",
       " (0.8393665158371041, 0.7081447963800905, 0.8042986425339367),\n",
       " (0.7558139534883721, 0.6201550387596899, 0.7299741602067183),\n",
       " (0.71571072319202, 0.6084788029925187, 0.7182044887780549),\n",
       " (0.660904255319149, 0.5212765957446809, 0.7433510638297872),\n",
       " (0.7987179487179488, 0.6948717948717948, 0.767948717948718),\n",
       " (0.8194271481942715, 0.6288916562889165, 0.8244084682440846)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62182565-64e2-4e94-83ba-15dc640094e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0, max_w1=0.4, max_acc=0.7165259348612787\n",
      "fold=1, max_w1=0.2, max_acc=0.7317073170731707\n",
      "fold=2, max_w1=0.1, max_acc=0.6474576271186441\n",
      "fold=3, max_w1=0.6, max_acc=0.7632135306553911\n",
      "fold=4, max_w1=0.4, max_acc=0.8427601809954751\n",
      "fold=5, max_w1=0.4, max_acc=0.7609819121447028\n",
      "fold=6, max_w1=0.30000000000000004, max_acc=0.7381546134663342\n",
      "fold=7, max_w1=0.1, max_acc=0.7446808510638298\n",
      "fold=8, max_w1=0.4, max_acc=0.8076923076923077\n",
      "fold=9, max_w1=0.4, max_acc=0.8268991282689913\n"
     ]
    }
   ],
   "source": [
    "# finding best value of w1\n",
    "w_acc = {w1: [] for w1 in np.linspace(0.1, 0.9, 9)}\n",
    "for val_idx, ((y_pred1, y_pred2), y_test) in enumerate(zip(predictions, tests)):\n",
    "    max_acc, max_w1 = -1, -1\n",
    "    for w1 in np.linspace(0.1, 0.9, 9):\n",
    "        y_pred = (w1 * y_pred1) + ((1 - w1) * y_pred2)\n",
    "\n",
    "        cl = fold_chunk_lens[val_idx]\n",
    "        y_pred_agg = sum_rule_agg(y_pred, cl)\n",
    "        y_test_agg = sum_rule_agg(y_test, cl)\n",
    "\n",
    "        acc = (y_pred_agg == y_test_agg).sum() / len(y_pred_agg)\n",
    "        w_acc[w1].append(acc)\n",
    "        if acc > max_acc:\n",
    "            max_acc, max_w1 = acc, w1\n",
    "    print(f\"fold={val_idx}, max_w1={max_w1}, max_acc={max_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7474a23-373e-4b56-b259-7e0f44a79156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# w vs accuracy\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)  # defaults: [6.0, 4.0]\n",
    "plt.plot(list(w_acc.keys()), [np.mean(a) for a in w_acc.values()], marker=\"o\")\n",
    "plt.xlabel(\"1D weight\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"w vs accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69d316cf-723d-4c4e-adfe-76f9086eb2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0, acc=0.7165259348612787\n",
      "fold=1, acc=0.7219512195121951\n",
      "fold=2, acc=0.6463276836158192\n",
      "fold=3, acc=0.7452431289640592\n",
      "fold=4, acc=0.8427601809954751\n",
      "fold=5, acc=0.7609819121447028\n",
      "fold=6, acc=0.729426433915212\n",
      "fold=7, acc=0.7167553191489362\n",
      "fold=8, acc=0.8076923076923077\n",
      "fold=9, acc=0.8268991282689913\n"
     ]
    }
   ],
   "source": [
    "# final ensemble accuracies with chosen w1 value\n",
    "w1 = 0.4\n",
    "fa = []\n",
    "for val_idx, ((y_pred1, y_pred2), y_test) in enumerate(zip(predictions, tests)):\n",
    "    y_pred = (w1 * y_pred1) + ((1 - w1) * y_pred2)\n",
    "\n",
    "    cl = fold_chunk_lens[val_idx]\n",
    "    y_pred_agg = sum_rule_agg(y_pred, cl)\n",
    "    y_test_agg = sum_rule_agg(y_test, cl)\n",
    "\n",
    "    acc = (y_pred_agg == y_test_agg).sum() / len(y_pred_agg)\n",
    "    print(f\"fold={val_idx}, acc={acc}\")\n",
    "    fa.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28fb13b4-b6d6-4257-a0aa-715f0c7fdf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7514563249118976, 0.05670275795954261)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average accuracy and stddev\n",
    "np.mean(fa), np.std(fa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f31a12-96cb-479e-b0f8-b828bad66791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
